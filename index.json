[{"content":"这个博客的诞生于 2021-10-16，原站点在 blog-hexo，因为静态文件都已经编译好了，就没有再进行修改了，后面的迁移应该会陆续完成。\n原因是我 sb 操作了，原 npm 环境配不回来了，正好之前装了 Hugo，这个博客的部署就是由 Hugo + GitHub Action 完成的了\n大概还会继续沿用我之前的博文分类方式，除了这个没有分类的 readme，主要就 2 个分类吧.\n环境相关的配置还有一些基础的笔记会放在我的 知识库 中，而一些被我理成体系的总结性文章会放在这。 因此之后的博客更新频率会比较低，当知识库建立到一定程度的时候，可以进行归档整理时会以博客的形式出现，博客所承担的大部分内容其实是日常内容更新 - -。\nblog：主要放一些自己 稍微正经 写的，主要做知识分享，包括一些项目的诞生和计划 misc：主要放一些自己 xj8 写的杂文，看看就好，偏日常 然后继续使用了 MathJax 而非 KaTeX 进行公式渲染，一个是方便读者导出公式，一个是我使用 KaTeX 的时候行内矩阵渲染会有问题，我解决不了\u0026hellip;所以现在其实是 MathJax + short code 的形式。\n另外，这个博客经过我一番折腾，除了有些颜色上的优化，多了友链页面，甚至还支持了 sass 和 scss\u0026hellip;\n下面就是测试一下 hint 的 short code\ninfo\nThis is a test for hint info note\nThis is a test for hint note important\nThis is a test for hint important warning\nThis is a test for hint warning danger\nThis is a test for hint danger tip\nThis is a test for hint tip example\nThis is a test for hint example ","permalink":"https://blog.bj-yan.top/p/readme/","summary":"\u003cp\u003e这个博客的诞生于 2021-10-16，原站点在 \u003ca href=\"https://blog-hexo.bj-yan.top/\"\u003eblog-hexo\u003c/a\u003e，因为静态文件都已经编译好了，就没有再进行修改了，\u003cdel\u003e后面的迁移应该会陆续完成。\u003c/del\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e原因是我 sb 操作了，原 \u003ccode\u003enpm\u003c/code\u003e 环境配不回来了，正好之前装了 \u003ccode\u003eHugo\u003c/code\u003e，这个博客的部署就是由 \u003ccode\u003eHugo + GitHub Action\u003c/code\u003e 完成的了\u003c/p\u003e","title":"README"},{"content":"善与恶，美与丑，短暂与永恒，虚无与现实，生存与毁灭。好像这个故事中的所有事都是非黑即白的，都有着一个明确的界线。三岛由纪夫的描写，更让这些对立的东西更加具象，这种强烈的对比，让金阁美的更彻底，毁灭的更悲怆。\n“自卑和嫉妒”：沟口和柏木起初都认为别人忽视了残疾缺陷就好像，忽视了存在于世的意义，沟口去寻找平等的对话，柏木选择认可他的人，认为有人就是喜欢他那“存在于世的意义”的东西，却忽视了自己身上其他真正美的地方。\n金阁寺也是沟口的束缚，不是因为沟口的对金阁强烈的欲望，而是因为沟口的欲望太小，只认为从小时起虚无的金阁的美就是终点，欲望也局限在金阁，成为了沟口的束缚，之所以一直认为金阁是美的，也是没有去寻找更美的东西，哪怕见过现实中的金阁，在沟口心里那种虚无的金阁的美依然存在。自然而言，金阁的美最终成为了沟口罪恶的催化剂。\n我到现在也不能理解沟口完整的动机是什么，是觉得金阁是他的束缚，还是嫉妒金阁的美，自己得不到的认同，还是在平静时产生的恶的“杀意”。他几次想到金阁其实并没有真正的看到金阁，那么所谓的毁灭也变得没有意义，金阁的美是永恒存在的，是无法通过烧毁来消除的。烧毁金阁也只是在物理上让金阁消逝，却让这种金阁的美变得更加永恒，所以看起来对沟口反而是没有意义的行动。\n我也不喜欢金阁寺的结局，可能是想依据事实，毕竟是是根据实事改编，三岛由纪夫只是进行了简单的想象，但是也不错。以自私的毁灭作为结尾让沟口重新回到了普通人，让金阁的美重新回到了虚无，就像故事刚开始的那样。我想如果是我，我可能会跟着金阁一起变成虚无的幻象。\n","permalink":"https://blog.bj-yan.top/p/note-jin-ge-si/","summary":"\u003cp\u003e善与恶，美与丑，短暂与永恒，虚无与现实，生存与毁灭。好像这个故事中的所有事都是非黑即白的，都有着一个明确的界线。三岛由纪夫的描写，更让这些对立的东西更加具象，这种强烈的对比，让金阁美的更彻底，毁灭的更悲怆。\u003c/p\u003e","title":"善恶美丑与虚无"},{"content":"0x00 写在前面 难道今年我可以按时发年度总结？\n如果去年的关键词是“扫街”和“首映”，那么我想今年的关键词就是“酒精”，“自由”和“焦虑”。\n0x01 酒精 今年开始，可能是 3-5 月吧，开始喝酒，喝了很多酒，在酒上的支出也不小，从在工位喝点 whiskey，到自己买了 tequila，然后去鸡尾酒吧、精酿酒吧\u0026hellip;最后还是觉得精酿酒吧，因为一个是精酿的口感风味比较丰富，而鸡尾酒很多店都是那种常见的，特调往往也不一定符合口感，也不能试饮，所以还是会更喜欢精酿一些。而且鸡尾酒的度数吧，一言难尽，有几次很明显感觉就是在喝饮料，甚至感觉跟在喝水啤差不多\u0026hellip;这基酒加多少纯看良心了，精酿都是自进的酒厂的酒桶，掺不了假。另外一点，我觉得主要的区别是，鸡尾酒吧大多都是几个人约好去聊天，然后几个人做一个桌，而精酿酒吧的氛围就稍微轻松一些，座位比较近，然后度数也不高，可以搭话聊天，就比较不错。\n今年倒是也喝多过几次，但确实对自己酒量也有了更清晰的认识，基本我能知道我喝多少是会处于放松的状态，喝多少会兴奋，喝多少会有感觉，喝多少会第二天头疼，喝多少会吐，喝多少可能会断片\u0026hellip;不过这个酒量也是动态的，得看当时的状态咯。\n我自己也买了套调酒的工具，但其实用的不多，我大部分时间不是为了喝酒而喝酒，我也很少自己喝酒，大多都是找朋友一起，想聊聊天，吸收一下他们的“能量”。\n0x02 朋友 这就到了这个话题，今年交的很好的朋友都是酒吧认识的，宇宙中心的宇宙还是可以遇到很多高质量朋友的！AI4Life 群组都是在这里认识的，我真的很喜欢你们！\n0x03 焦虑 说到这个问题，我又有点焦虑了，主要原因就是由于申请的问题吧。不过 5 月份真的是我焦虑的巅峰期，也是经常去酒吧的一个原因，如果不采取点措施可能我会天天等太阳升起才睡着。后面为什么不焦虑了呢，可能有点开摆了\u0026hellip;\n0x04 电影 \u0026amp; 首映 今年倒是补了很多经典电影，院线没怎么看了，主要因为没怎么去抽首映，唯一去的一场就是《误杀3》，正好还是不散观影团 24 年最后一期，也是第 500 期，但遗憾的是没有主创到场。\n对了，还有就是电影解说，我曾有段时间疯狂看电影解说，就是觉得一个看完不够劲儿，再来一个，然后就没完了\u0026hellip;一个电影解说的时长也不短，可能也得有个 20 min 吧，很快时间就没了。后面又看起了电影，就越来越觉得解说没意思了，大多都是看看解说解说的是什么电影，然后自己去看，或者说自己哪里没看懂，看完再看看解说。\n0x05 书 今年可能是我最近读书最多了一年了，大功臣就是 @Yannan。Yannan 给我推荐了很多非常有意思的书，我喜欢纸质书上特殊的香气，我喜欢翻页时的声音，我喜欢在地铁上带耳机看书的感觉\u0026hellip;\n我还喜欢思考书上的观点，批判一下作者的主观意见，批判一下作者的偏见，今年看的一些书有一些都是观点性的。\n0x06 音乐 向去年一样，我没有国内音乐平台的会员，因此我也看不了什么听歌年终总结了，我的听歌软件一直是 Bilibili 和 YouTube。后面换了 Mac 以后，就开始用 Apple Music 了，但我依然喜欢去 Bilibili 和 YouTube 上找一些 Playlist 来听。\n0x07 游戏 看了看 steam 的 2024 年度回顾，我 75% 的时间再使用手柄 hhh，已经是手把狗的形状了。前 5 个月，我的 Apex 强度还是很高的，后面 9-10 月 又玩了一阵，到最后我甚至直接戒断了游戏了\u0026hellip;可能一个月玩上几局游戏这样子\n0x08 星空 想了一下，自从搬出来住以后，由于位置比较偏，所以光污染相对较少，有一次深夜回去，忽然发现头顶上居然有这么多星星，随后就把原先宿舍里的三脚架，镜头都拿了过来，开始了星空摄影。APSC 画幅虽然差了那么一点点，但是作为娱乐还是够了的，拍过金星冲月、猎户座、北斗七星、双子座流星雨（我拍到了足足3颗！！）后面，也用 Siril 做了一下堆栈，但只能说再后期方面我还有很大的提升空间 hhh。\n渐渐的，我喜欢上了仰望星空，冬季星空中的猎户座永远是最容易看到的，肉眼能看到火星闪烁的红光，喜欢观星，因为星星它就在那里，喜欢拍星星是为了看到在那里我肉眼看不到的一些星星、星云和它们特殊的光芒和色彩。\n0x09 我的 月付/年付 项目 其实这一块很早就想写了，但一直拖着没写，趁这次写年终总结就简单来盘点一下我的月付或年付项目吧。\n首先就是阿里云盘的会员(168/y)，虽然阿里云盘很蛋疼，比如分享不了 zip，他的备份功能很容易做出冗余备份，浪费了很多空间，但是只是把他作为一个备份云盘，这个空间和文件同步以及速度我是满意的，包括在线播放的功能，和一些可能的扩展性。我已经好几次在阿里云盘找到我在自己电脑都很难找到的文件了，还真的谢谢他的备份功能。\n再者就是 Apple Music，3 个月免费，后面是 11/mo，我觉得还可以，几乎所有音乐都能搜到，不太有因为某种纠纷不存在的音乐，当然小众的音乐还是没太有的。\n丰巢会员\u0026hellip;搬出来以后经常用丰巢了，但是免费存储只有 18 小时，他甚至不是 24 小时，因此如果上午早上刚出门他到了，我晚上又出去玩了或者忘拿了，那大概率就要超时交钱了。有一次快递比较多，就一口气超时了 3 个快递，当时觉得没啥事，就直接付了钱，后面又超时了，算了算超时的钱都够买一个月会员了，那干脆买了吧，也不用担心有没有忘取快递了。\n食贫道的充电倒是断断续续的，主要是他的更新频率跟不上，如果每个月充电 10 块只看一期充电视频，那还不如攒上 3 个月看 3 个充电视频呢。\n移动电话卡，是的，我办了一张卡，改成了 9 元保号套餐，至于用途嘛，大概就是能多开几个号了。\n总的来看，我每个月的固定支出就有了 168/12 + 11 + 5 + 10 + 9 = 49，我一开始没算的时候还觉得挺多，现在看来好像还行？\n0x0A 自由 “自由”和“焦虑”是不是看起来还有点矛盾？说说自由吧，这个关键词我放在了今年的关键词，却一直没有提及。没有什么真正的自由，只有自己心和灵魂的自由，我觉得我此刻是自由的。我做我想做的，我还年轻，我愿意尝试任何我想做、我喜欢做的事。如果说让我说人一生中做的一件事，我想不是“活着”，而是活出我自己的人生。\n我曾有段时间想知道，我生命的意义，后来发现，生命的意义很简单，就是“活着”，你作为一个生命，“活着”就已经很伟大了，这就是你在这个生命的意义。所以，我一直在寻找的其实不是“生命的意义“，而是我“人生的意义”或者说是“生活的意义”，活出自己才是最重要，这可能是我今年得到的最大感悟了 :)\n0x0B 2025 没有什么特别的新年愿望，我很不喜欢“愿望”这个词，仿佛它们只能是“憧憬”和“幻想”。就让我希望一下 2025 身体健康，一切顺利吧。\n祝，新年快乐！\n","permalink":"https://blog.bj-yan.top/p/journey-annual-summary-2024/","summary":"\u003ch2 id=\"0x00-写在前面\"\u003e0x00 写在前面\u003c/h2\u003e\n\u003cp\u003e难道今年我可以按时发年度总结？\u003c/p\u003e\n\u003cp\u003e如果去年的关键词是“扫街”和“首映”，那么我想今年的关键词就是“酒精”，“自由”和“焦虑”。\u003c/p\u003e\n\u003ch2 id=\"0x01-酒精\"\u003e0x01 酒精\u003c/h2\u003e\n\u003cp\u003e今年开始，可能是 3-5 月吧，开始喝酒，喝了很多酒，在酒上的支出也不小，从在工位喝点 whiskey，到自己买了 tequila，然后去鸡尾酒吧、精酿酒吧\u0026hellip;最后还是觉得精酿酒吧，因为一个是精酿的口感风味比较丰富，而鸡尾酒很多店都是那种常见的，特调往往也不一定符合口感，也不能试饮，所以还是会更喜欢精酿一些。而且鸡尾酒的度数吧，一言难尽，有几次很明显感觉就是在喝饮料，甚至感觉跟在喝水啤差不多\u0026hellip;这基酒加多少纯看良心了，精酿都是自进的酒厂的酒桶，掺不了假。另外一点，我觉得主要的区别是，鸡尾酒吧大多都是几个人约好去聊天，然后几个人做一个桌，而精酿酒吧的氛围就稍微轻松一些，座位比较近，然后度数也不高，可以搭话聊天，就比较不错。\u003c/p\u003e","title":"或许是 2024 年终总结"},{"content":"书评发在豆瓣了，不过再在这里发一下吧，也好久没更新博客了。\n整本书由于是采访内容，所以观点非常主观，倒也没什么不好，内容稍微有些宽泛了，但我很喜欢，就像是单元剧，每一节定一个主题，剩下的就是自由发挥了，没有任何形式上、方向上的约束。当然因为是采访稿，所以还是有一定引导性的。\n我觉得前面关于身体论和亲密关系的部分讲的很好，算是一种小 review，很多观点对我来说是比较新的，我很喜欢前三章的内容。\n但话说回来，这本书就像是一个标题党，其实只有一节讲到了亲密关系的核心是友谊，或者说只有 Part 1 是相关的。但这部分内容我倒是很认同，任何关系都可以看作是一种友谊，友谊是万能的，大家只是在这段友谊中保持和扮演了不同的角色，让友谊以不同的形式连接和维系。\n后面关于AI那部分太肤浅，目前的ChatGPT不会是AGI的最终形态，说的一些内容甚至都不需要像他“这样的哲学工作者”来探讨和总结，研究过程中早有研究工作把问题描述的更加具体，然后来尝试解决这种问题，比如说他提到的“复写”，其实就是“合成数据有害性”的体现，换种语言描述看起来更像是在“复写”，难道这章是GPT写的？再说点别的，为什么我觉得目前 ChatGPT 不会是 AGI 的最终形态，主要原因是基于概率的回归问题其实并不合理，RAG 的方式让内容生成更加可靠了，CoT 又让 LLM 提取出来了更多的信息，但是他们都不是一种大道至简的形式，因此我认为还会有一次巨大的技术演化，来实现 AGI，在此之前就让我们拭目以待吧，可能这个 AGI 不会是 OpenAI 做出来的。\n再补充两点，一个是所有ChatGPT统治世界的言论都是除非不是AI领域研究人员的嘴中，而真正做这个领域研究的人员不会认为目前的AI能统治地球，因为大家清楚现在AI model并没有改变世界的能力，这些人的恐惧来自于技术革新速度之快和未知。目前人们还没有赋予它这样的能力，如果真有一天直接赋予了它影响物理世界的能力，那才是真的危险（比如具身智能？）\n另外一点是，我们确实需要对创作品中的AI使用警惕，有种阴谋论，如果在某天实现了AGI，AI必然有一个逐步获得操纵物理世界能力，慢慢控制部分人类为其效力，再逐步发起大规模统治举措。其创作品如果被广泛使用和阅读必然会影响到人类的认知和思想，从某种阴谋论来看，说不定已经是进行时了？\n关于法国那部分太无聊，没怎么认真看\n关于电影纪录片哪一个部分的观点是错误的，“回到电影的起点，它就是最直接单纯简单和朴素的记录” 不如说这是纪录片的起点。我认为电影对于观影人来说是品味一段故事感受一段人生，对于导演来说是通过电影来表达自己的一种观点，镜头语言和美学手法是一种表达方式，剪辑也是一样的，都是为了更好的表达导演自己的观点和描述故事，纪录片或者纯对话的当然不需要什么太多的艺术形式了，引导是最重要的，不能漫无目的谈话。\n可以看一下饼叔的采访，会引导被采访者思考，然后让他们说出内心的话，也可能就是饼叔想对观众说的。\n“论文电影”这个很有意思，像论文一样的拍摄电影，是论文的另一种呈现形式。\n关于收藏品，我忽然我也有一个想法，我想在我这一生中，寻找一组一生的藏品，作为我的一种表达，我所追求的。生命的意义？活着难道不就是生命的意义了吗？生命的意义不在于你自己，我们寻找的也不是生命的意义，而是自己人生的意义和价值。\n关于艺术品，说是一种消耗金钱的方式，但是那些无病呻吟的东西本不应被称为“艺术品”，艺术品应当是有表达的，无论是思想上还是形式上，亦或是反映一个时代（当然这是后人才发现的），这就有点矛盾了。\n我很喜欢尼采关于火与酒的观点，生命正是围绕火和酒而展开的：在火中，活力、强健、蓬勃、狂热、欢欣在一起跳跃；借助于酒，一个混沌、自主和充满快感的身体翩翩起舞。……火和酒一旦相遇，二者互相催生和激发，它们各自的能量更加饱满，醉被醉所滋养，光被光所照耀。……酒和火遭到了驱逐，理性、逻辑和知识冲淡了狂欢之酒，节制、禁欲和克己扑灭了放肆之火。\n虽然不知道为什么，但我就是想起来了斗破苍穹的炼药师，记得成为炼药师的条件就是火属性+一点微弱的木属性，因为有木属性才能探到或者感应到，因而那一丝看似被火所侵蚀克制看似杂质却存在于火之中的木属性才是灵魂，才是造成炼药师万里挑一原因。这是如此，这个木属性像是火与酒之中的一丝理智，哪怕烂醉哪怕放肆，都应当有最基本的底线，这个是难得可贵的，也是能让你享受在火与酒之中的关键因素。\n说点别的，读完这本书的在地铁上有看到深绿色的爱心座位，如果一个人真心想让座，无论他坐在哪都会让的，爱心座位的设计是不是会让一些本想让座的人失去的让座的心思呢？我觉得爱心座椅的设计是一种提醒，但是可能只会让让座的人更少，而不会变多。有没有可能坐在爱心座椅上的，都是已经疲倦的人，他们本来就很累，想找个地方靠着歇息，他们也需要被“让座”，无论他们是是不是老弱病残幼，我们不都是需要“座位”的人吗？书中曾有一部分提到资本让人不会说我不能我不行，放到这怎么感觉也是类似。\n","permalink":"https://blog.bj-yan.top/p/note-qin-mi-guan-xi-de-he-xin-shi-you-yi/","summary":"\u003cp\u003e书评发在豆瓣了，不过再在这里发一下吧，也好久没更新博客了。\u003c/p\u003e\n\u003cp\u003e整本书由于是采访内容，所以观点非常主观，倒也没什么不好，内容稍微有些宽泛了，但我很喜欢，就像是单元剧，每一节定一个主题，剩下的就是自由发挥了，没有任何形式上、方向上的约束。当然因为是采访稿，所以还是有一定引导性的。\u003c/p\u003e","title":"亲密关系的核心是友谊"},{"content":"0. 没想到今天居然也还挺开心的呀！\n简单记一下吧，一会还想工作一下，毕竟现在还一点都不困呢。\n1. 今早起来就看到 哈哈 让华裔给她投票，那只能 哈哈 了，她认识到的时间有点晚，已经没人信了，哈哈。\n然后在发财群简单探讨了一下 PhD 规划，解锁了更多有意思的方向，感觉后续可以尝试调研一下。下周申请要推动一下了。\n2. 然后和 shubai 去了国家大剧院看了一个话剧，也是此生第一次看话剧吧，《嫌疑人福尔摩斯》，华生的演技是真顶啊，这个角色切换难度还是很高的感觉，福尔摩斯反而感觉一般般（但是人家是导演），整体还是非常赞的，足足有135分钟，后面有一部分是和观众互动的。我觉得有所缺憾的可能是前面内容太多（不知道是不是原剧的内容重现，可能是致敬之类的吧），其实很多角色刻画可以更简单一点，而且我觉得后面福尔摩斯的言语谈吐有点太多了，反而和一开始刻画的角色相差有点远。至于剧情方面，其实看多悬疑的在福尔摩斯倒下的时候就能猜到肯定会再起来，基本就是在测试华生而已。再结合一下国内的“结尾”，肯定是 happy ending，黑化的福尔摩斯是不可能的，悬疑感一般般啦。最后，比较特殊的是我们是最后一场，最后还有一个大合影环节，很开心！！另外，就是除了警司的麦克风都在脑门上，感觉很神奇，甚至有点出戏，我一开始就一直盯着华生的麦克风看。\n3. 晚上看完话剧回宿舍就感觉一股闷闷的潮气，还是受不太了不通风的感觉，太潮了，有用一种闷热，只能说很适合养微生物。所以受不了还是决定回来睡了，结果回来路上打车的时候和司机聊了一路，最后到了以后还跟我聊了快半小时。司机是个 80 后，说我关于人生的一些想法和他当时比较像，某些阶段觉得自己输了很多。虽然他的所谓“输赢”不是那么合理，但是还是能基本 get 到他的意思，而且一些话，想想，说的也在理\u0026hellip;确实和不同人能 get 到不同的想法，还是要多交流交流。不过他说的一句话我觉得还不错，就是“就算输在赢得路上，也比一直输要好”，还说我“整天浑浑噩噩”，emmm，居然感觉被说到了\u0026hellip;还有点啥来着，就是人生走向不随大众的岔路，拐歪了是很难拐回来的，嗯，大概也能懂他这意思。简单记录一下吧 haha\n","permalink":"https://blog.bj-yan.top/p/misc-20241104/","summary":"\u003ch2 id=\"0\"\u003e0.\u003c/h2\u003e\n\u003cp\u003e没想到今天居然也还挺开心的呀！\u003c/p\u003e\n\u003cp\u003e简单记一下吧，一会还想工作一下，毕竟现在还一点都不困呢。\u003c/p\u003e\n\u003ch2 id=\"1\"\u003e1.\u003c/h2\u003e\n\u003cp\u003e今早起来就看到 哈哈 让华裔给她投票，那只能 哈哈 了，她认识到的时间有点晚，已经没人信了，哈哈。\u003c/p\u003e","title":"杂记：20241104"},{"content":"1. 终于把 hugo 版本升级到了最新的版本，之前一直觉得麻烦，现在看来好像并不是，随便改改几个变量就好了。\n我也把 GitHub 主页的 douban 和 blog 最近动态去掉了，最近可能就在 blog 发发牢骚了。不喜欢在国内的平台，douban 啊 weibo 啊 xiaohongshu 啊 zhihu 啊，都有自己的群体。一些国际的社交软件反而找不到朋友，那不如自己的数据都自己管，或许 blog 还是我目前最喜欢的方式了。\n虽然也有想运营一下自媒体之类的想法，但是我觉得目前不是这个契机，我的时间、精力、经历和话题都不足以支撑一个自媒体账号长期的运营，希望能找到自己的 style。\n2. 终于感觉稍微轻松了一些先是解决了开题，还有申请上的一些困惑，然后是找房子的事情。虽然列一些 To Do List，还是有很多事，但总归感觉能一项一项去做了。\n3. 前两天也喜提了单间，嗯，我搬出来住了，不想被太拘束，自己也不会找其他方面的理由了，自己出来住，可以独处，也可以享受自己整理东西的感觉，更重要的是感觉时间可以完全由自己掌握了，这种感觉还是不错的。\n希望能够找到自己的节奏吧。\n4. 再往前一段时间，认识了几个新朋友，一些巧合和默契让我们居然聚在了一起。\n从未体验过这种“无话不说”朋友的感觉，后面越来越发现，其实走到一起是有原因的，不光是性格、态度、价值观等等。\n而这种相处的时候轻松快乐的氛围让我感觉“又活了一次”。\n5. 我一直不是一个果断的人，但我希望，能够以自己的认知快速做出一些决策，哪怕自己后面“可能”会后悔。但我希望它不是盲目的，或是被动的。\n6. 关于北京 北京越来越冷了，秋天也到了，看到师弟发的朋友圈让我想起了一年前的自己，当时我有这自己的节奏，工作日去所里，周末就出去看看风景散散步，真的是我喜欢的节奏。后面搬到环保园这边以后，一切都乱了。原先可以去所里干活，累了就拿上相机拍照，现在已经好久没有再拿起相机，拿起相机也没有那时的心境，能够享受这份乐趣了。\n最近的北京全是雾霾，但我翻了一下自己的朋友圈，原来去年我也在差不多同一时刻吐槽过，只不过是今年稍早了一些。好像一切都是那样，井然有序地进行着。\n北京，就是这样，他总会自己运作着，像一个庞然大物，而我，像是找不到栖身之所。\n7. 发发牢骚，日子还得继续过啊，加油吧，尽力而为。\n累了就歇歇，但也别歇太久～\n","permalink":"https://blog.bj-yan.top/p/misc-20241102/","summary":"\u003ch2 id=\"1\"\u003e1.\u003c/h2\u003e\n\u003cp\u003e终于把 hugo 版本升级到了最新的版本，之前一直觉得麻烦，现在看来好像并不是，随便改改几个变量就好了。\u003c/p\u003e\n\u003cp\u003e我也把 GitHub 主页的 douban 和 blog 最近动态去掉了，最近可能就在 blog 发发牢骚了。不喜欢在国内的平台，douban 啊 weibo 啊 xiaohongshu 啊 zhihu 啊，都有自己的群体。一些国际的社交软件反而找不到朋友，那不如自己的数据都自己管，或许 blog 还是我目前最喜欢的方式了。\u003c/p\u003e","title":"杂记：20241102"},{"content":"写在前面 众所周知，TikTok 会锁区，在国内是无法正常使用的，好早前就想上 TikTok 耍耍，一直也没成功。\n今天逛 GitHub 的时候看到这个方法，但是项目 README 写的很不全，所以笔者就写了这篇文章来记录一下。\n准备工作 首先需要准备一个美区 Apple ID，以及一个科学上网软件 Shadowrocket / Quantumult X / Surge 等。\n另外需要安装的软件有：\niTunes v12.6.5.3（需要低版本，64 位 | 32 位） 爱思助手（同时需要 USB 线连接手机） iOS 任意版本号APP下载 v6.0：52pojie 帖 配置代理 基本可以 Follow 这个 GitHub 的仓库 README，不过他写的有点乱，笔者这里还是稍微整理一下，因为笔者只有 Shadowrocket，所以只能以 Shadowrocket 为例。\ninfo\n注意如果你之前安装过 TikTok 请卸载再配置代理！！！ 打开 Shadowrocket\n点击下方的 配置，点击自己使用的配置后面的 i -\u0026gt; HTTPS 解密 -\u0026gt; 开启 HTTPS 解密 -\u0026gt; 生成新的CA证书 -\u0026gt; 安装证书\n打开手机设置，前几行就会显示 已下载描述文件，点击 安装，输入密码，点击 安装，再点击 安装，最后点击 完成\n打开手机设置 -\u0026gt; 通用 -\u0026gt; 关于本机 -\u0026gt; 证书信任设置 -\u0026gt; 找到 Shadowrocket，开启信任\n打开 Shadowrocket，点击下方的 配置 -\u0026gt; 模块 -\u0026gt; 添加和解锁想看的地区 Japan\n1 https://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKTok-JP.conf Korea\n1 https://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKTok-KR.conf United States\n1 https://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKTok-US.conf Taiwan\n1 https://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TiKTok-TW.conf 点击下方的 配置，点击自己使用的配置后面的 i -\u0026gt; 规则 -\u0026gt; 右上角+号 -\u0026gt; 类型 -\u0026gt; 选择RULE-SET -\u0026gt; 策略 -\u0026gt; 选择PROXY或者其他你想使用的策略（一般是对应地区的代理服务器节点） -\u0026gt; 规则集URL文本框内填写\n1 https://raw.githubusercontent.com/Semporia/TikTok-Unlock/master/Shadowrocket/TikTok.list 这样就完成了代理的配置。\n下载旧版本 TikTok 首先下载和安装 iTunes，在 iTunes 登录美区账号。\n打开 iOS 任意版本号APP下载 v6.0，选择美国，搜索 TikTok，右键查看历史版本。\n搜索 TikTok 历史版本\n往下滑找到 21.1.0 版本，右键下载。\n找到 TikTok 21.1.0 版本\n会进入拦截页面，此时再在 iTunes 搜索 TikTok，找到对应的 APP，点击下载。\n下载 TikTok\n这时候可能会下载不成功，但软件已经拦截成功了，所以可以暂停下载，停止拦截，再重新开始下载即可。\niTunes 下载的默认路径在 C:\\Users\\用户名\\Music\\iTunes\\iTunes Media\\Mobile Applications，找到下载好的 TikTok 21.1.0.ipa 文件。\n安装 TikTok 打开爱思助手，将手机连接到电脑，并点击 信任。\n如果之前没用过，会在手机上安装 爱思助手极速版，并需要打开一下，不然可能会因为服务未启动而无法安装。\n点击 应用游戏，从本地文件导入进行安装，找到刚刚下载的 TikTok 21.1.0.ipa 文件安装即可。\n如果打开让你选择感兴趣的话题，就说明安装成功了！恭喜你可以正常使用 TikTok 了！\n最后 启动！\nTikTok！启动！\n","permalink":"https://blog.bj-yan.top/p/blog-tiktok-unlock/","summary":"\u003ch2 id=\"写在前面\"\u003e写在前面\u003c/h2\u003e\n\u003cp\u003e众所周知，TikTok 会锁区，在国内是无法正常使用的，好早前就想上 TikTok 耍耍，一直也没成功。\u003c/p\u003e\n\u003cp\u003e今天逛 GitHub 的时候看到这个方法，但是项目 README 写的很不全，所以笔者就写了这篇文章来记录一下。\u003c/p\u003e","title":"免拔卡换区解锁 TikTok"},{"content":"Hi, 好久不见。今天是大年初三，新年快乐！\n一直很想记录一下崭新的 2023，想了很多，但又觉得似乎没什么值得记下的，不过这么久没写博客了，还是随便写点什么吧。\n首先随便说说各种 App 的年终总结，B 站自然是全勤小能手！观看时长都快有 2000 小时了。音乐 App 的年终总结参考价值已经不大了，毕竟我的音乐播放器已经完全变成了 YouTube 和 bilibili，想听啥有啥，没啥版权，我也不追求极值的音质，就还好（或许可以出一个自动统计播放时长的浏览器插件？）\n豆瓣倒是还有些参考价值，今年最开心的可能就是在朝阳区各大影院看首映礼了，2023 年大概看了 6 场首映吧，有《不虚此行》（第一次参加首映，一个不错的文艺片）、《莫斯科行动》（片子一般，但看到了华仔）、《困兽》（烂片一个，但是看到了蛙蛙）、《追缉》（大概是我首映看到最好的片子了）、《沉默笔录》（披着悬疑外衣的文艺片）、《黑土无言》（电视剧首映，就看了两集，啥剧情还都没展开，最后还烂尾了- -|||）。\n虽然我在首映能看到的好片子不多，在豆瓣上的评分大多也会偏高一些，但能现场看见一些主创和主创交流感觉也蛮好的 hhh。今年最喜欢的电影可能就是《奥本海默》以及《年会不能停》了，但这两个都是我自己去贡献票房的，首映礼根本抢不到 =A=。另外，《涉过愤怒的海》还算可以，但是估计是为了过审让步了太多了，多产电影、电视剧大多都有这个通病，为了过审非得搞个 Happy Ending，明明可以更深化一下主题，难道是审核的看不懂电影？？？还是说不想粘锅？？？\n想当初 22 年在 GitHub 上的异常活跃， 23 年像沉入了水底，所有的 Contribution 几乎都是给了 private 仓库，LLM 发展也让我自己有些乱了阵脚，新工作的不断“涌现”让人有一种学无止尽的感觉 hhh，但 23 年的几个工作几乎和 LLM 不沾边，希望 24 年可以做一些 MM 或者 LMM 的工作吧。\n23 年年初的时候，疫情刚放开，因为北京疫情比较严重，早早溜掉了，在海南呆了一个月考完了期末。回来以后本以为会因为放开了能多出去走走，走来走去也走不出怀柔，果然河北就是河北，别跟百京沾边（x。春季学期结束，早早选了夏季学期的课程，上完又跑到了海南，回来就参加了 WeBank 和 AIR 的可信联邦夏令营，然后就是回所，没几天就高温假，回来以后就是十一，还有团建，这段时间总感觉过的飞快，几乎没什么回忆了。后面又为了海南，投稿了 IEEE ICPADS，在年终总结的时候溜去了海南。\n其他令我开心的大概就是买了相机，虽然交了点学费，但是当当 gai 溜子感觉还不错，也去了北京的不少景点了，24 年还买了北京公园的年票，希望能多去走走，挣回票价 QAQ。\n今年 24 年，压力也随之而来了，毕业相关的事宜总归是来到了面前，雅思成绩、论文、简历、各种文书材料和信息收集都是要做的，在线求一个 25 fall PhD position！！！有一起申请交流的 uu 也可以通过邮箱、留言等各种方式找到我，非常乐意一起交流学习~！\n这一年希望家人身体健康！ :)\n也祝大家 loong 年大吉，万事如意！\n那么，新年快乐，一切顺利！\n","permalink":"https://blog.bj-yan.top/p/journey-annual-summary-2023/","summary":"\u003cp\u003eHi, 好久不见。今天是大年初三，新年快乐！\u003c/p\u003e\n\u003cp\u003e一直很想记录一下崭新的 2023，想了很多，但又觉得似乎没什么值得记下的，不过这么久没写博客了，还是随便写点什么吧。\u003c/p\u003e","title":"或许是 2023 年度总结"},{"content":"0x00 Preface 本文着眼于分布式机器学习中的效率分析，在分布式机器学习中，efficiency 通常指的是效率，即在一定的时间内，算法能够达到的最优解的质量，或者是需要得到一定的质量时，算法所需要的时间，参考1。\n0x01 Synchronous SGD Gradient Computation and Communication Time 通常，我们会假设梯度计算和通信的时间服从一个关于随机变量 $X$ 的概率分布，即 $F_{X}(x)$，这个分布往往取决于计算机的性能、网络的带宽、所用的通信协议等等。常见的分布有：\n指数分布：$F_{X}(x) = \\text{Exp}(\\lambda) = \\lambda e^{-\\lambda x}, x \\geq 0, \\lambda \u0026gt; 0$ 高斯分布：$F_{X}(x) = \\text{N}(\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}, x \\in \\mathbb{R}, \\mu \\in \\mathbb{R}, \\sigma \u0026gt; 0$ 帕累托（Pareto）分布： $$ F_{X}(x) = \\text{Pareto}(x_{m}, \\alpha) = \\begin{cases} \\frac{\\alpha x_{m}^{\\alpha}}{x^{\\alpha +1}}, \u0026 x \\geq x_{m} \\\\ 0, \u0026 x \u003c x_{m} \\end{cases}, x_{m} \u003e 0, \\alpha \u003e 0 $$ 其中，$x_{m}$ 和 $\\alpha$ 分别是范围和形状参数，越大的 $\\alpha$ 表示越快的衰减。帕累托随机变量的均值和方差分别为：\n$$ \\mathbb{E}[X] = \\begin{cases} \\infty, \u0026 \\alpha \\leq 1 \\\\ \\frac{\\alpha x_{m}}{\\alpha - 1}, \u0026 \\alpha \u003e 1 \\end{cases} \\\\ \\mathrm{Var}[X] = \\begin{cases} \\infty, \u0026 \\alpha \\leq 2 \\\\ \\frac{\\alpha x_{m}^2}{(\\alpha - 1)^2 (\\alpha - 2)}, \u0026 \\alpha \u003e 2 \\end{cases} $$ tip\n帕累托分布是从真实世界现象中发现的幂次定律分布，除了用于 cloud server delay 之外，还常用于硬件的错误和失败率、在线文件大小、社会财富分布（意大利20%人口拥有80%的财产）等等。 在这些分布假设下，实际的梯度计算和通信时间是偏移的（shifted），即 $\\Delta + \\text{Exp}(\\lambda)$，其中 $\\Delta$ 是一个常数时间，如通信和本地计算的开销。\n同时，通常我们会假设 $X$ 是独立同分布的（i.i.d.），即在每个 worker node 上的梯度计算和通信时间服从同一个分布。\n有了上面的假设，我们就可以开始着手分析了。\nEfficiency/Runtime Analysis 假设一轮的迭代时间为 $T_{\\text{sync}}$，共有 $m$ 个 worker node。\n那么\n$$ \\mathbb{E}[T_{\\text{sync}}] = \\mathbb{E}[\\max \\{X_{1}, X_{2}, \\cdots, X_{m}\\}] = \\mathbb{E}[X_{m:m}] $$ 其中，$X_{m:m}$ 表示 $m$ 个随机变量中的最大值，因为根据木桶原理，我们应该关注最慢的那个 worker node。\n当 $X$ 服从指数分布时，即 $X \\sim \\Delta + \\text{Exp}(\\lambda)$，我们有\n$$ \\mathbb{E}[X]=\\frac{1}{\\lambda}+\\Delta \\\\ \\mathbb{E}[T_{\\text{sync}}] = \\mathbb{E}[X_{m:m}] = \\Delta + \\frac{H_{m}}{\\lambda} \\approx \\Delta + \\frac{\\ln m}{\\lambda} $$ 其中，$H_{m} = \\sum_{i=1}^{m} \\frac{1}{i}$ 是第 $m$ 个调和数。\n因此，我们可以认为，分布式机器学习中，使用同步 SGD 单位时间处理 minibatches 的期望是 $\\frac{m}{\\mathbb{E}[T_{\\text{sync}}]}$。\n为了防止和迭代次数 $t$ 混淆，我们用 $T_{\\text{wall}}$ 表示 wall-clock time，即 $T$ 个单位时间。在 $T_{\\text{wall}}$ 时间内，同步 SGD 进行的迭次数 $t$，随机变量 $X\\sim \\text{Exp}(\\lambda)$，我们有\n$$ \\lim_{T_{\\text{wall}} \\rightarrow \\infty} \\frac{t}{T_{\\text{wall}}} = \\frac{1}{\\mathbb{E}[T_{\\text{sync}}]} \\approx \\frac{\\lambda}{\\ln m} $$ 于是，有 $t \\approx \\frac{\\lambda T_{\\text{wall}}}{\\ln m}$。\n同样的，如果我们限制的是迭代次数 $t$，那么 wall-clock time 为 $T_{\\text{wall}}\\approx \\frac{t\\ln m}{\\lambda}$。\n从 分布式机器学习中的收敛性分析 中我们知道，这个误差，代入 $t$ 得到\n$$ \\mathbb{E}[f(w_{T})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu bm} \\leq (1- \\eta \\mu)^{\\frac{\\lambda T_{\\text{wall}}}{\\ln m}}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu bm} \\right ) $$ 从上式可以看出存在一个关于 $m$ 的实际运行时间和误差的 trade-off，$m$ 越大，每轮迭代的期望运行时间变大了，但是实现了更小的误差。实现误差 $\\epsilon$ 所需要的 wallclock time 是 $O(\\frac{\\ln m}{\\lambda \\epsilon m})$，同时迭代次数 $t$ 是 $O(\\frac{1}{\\epsilon m})$，每轮运行时间是 $O(\\frac{\\ln m}{\\lambda})$。\n0x02 K-Sync SGD 在 K-Sync SGD 中，PS 会首先接收前 K 的 worker node 的梯度，然后进行平均，同时取消掉剩余的 worker node 的计算，保证每次迭代的初始参数是相同的。\n此时一轮迭代的期望时间为\n$$ \\begin{align} \\mathbb{E}[T_{\\text{k-sync}}] \u0026= \\mathbb{E}[\\max \\{X_{1}, X_{2}, \\cdots, X_{k}\\}] = \\mathbb{E}[X_{k:m}] \\\\ \u0026= \\frac{1}{m\\lambda} + \\frac{1}{(m-1)\\lambda} + \\cdots + \\frac{1}{(m-k+1)\\lambda} \\\\ \u0026= \\frac{1}{\\lambda} (H_{m} - H_{m-k}) \\\\ \u0026\\approx \\frac{1}{\\lambda} \\ln(\\frac{m}{m-k}) \\end{align} $$ 在经过 $t$ 次迭代后，误差被 bound 如下：\n$$ \\mathbb{E}[f(w_{t})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu bK} \\leq (1- \\eta \\mu)^{t}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu bK} \\right ) $$ 同样，这也存在一个 Trade-off，更小的 $K$ 能够让单轮迭代变快，但是误差会增加。\n这里多说一个 K-batch-sync 的情况，这种情况下，一个 worker 上传完梯度后，并不是停止等待，而是继续计算，直到 PS 收到 K 个梯度为止。这种情况下，一轮迭代的期望时间为 $\\mathbb{E}[T_{\\text{k-batch-sync}}] = \\frac{K}{m\\lambda}$，随着 $m$ 增加而降低，随着 $K$ 增加而增加。\n0x03 Asynchronous SGD 在异步的情况下，需要用到 Renewal Theorem2。\ndefination\nRenewal Theorem：假设 $S_{1}, S_{2}, \\cdots$ 是独立同分布的随机变量序列，并且期望是有界的 $0\u003c \\mathbb{E}[S_{i}] \u003c \\infty$。对于 $S_{i}$，我们指的是第 $i$ 个占用时间（$i$-th holding time）。同时定义 $J_{n} = \\sum_{i=1}^{n} S_{i}$，即第 $n$ 个跳跃时间（$n$-th jump time），而 $[J_{n}, J_{n+1})$ 也叫做更新间隔（renewal interval）。那么，对于任意的 $t \\geq 0$，我们有 $$ X_{t} = \\sum_{n=1}^{\\infty} \\mathbb{I}\\_{\\{J_{n} \\leq t\\}}=\\text{sup} \\\\{n: J_{n} \\leq t\\\\} $$ 其中，$\\mathbb{I}\\_{\\\\{J\\_{n} \\leq t\\\\}}$ 表示 $J_{n} \\leq t$ 的指示函数（成立时为1，其他情况为0）。$X_{t}$ 表示在 $t$ 时刻的跳跃次数，这个过程也叫做更新过程（renewal process）。 更新过程是泊松过程的推广。本质上，泊松过程是正整数（通常从零开始）的连续时间马尔可夫过程，每个整数具有独立的指数分布保持时间 $i$ 在前进到下一个整数之前，$i+1$。 每次迭代的期望运行时间 $\\mathbb{E}[T_{\\text{async}}] = \\frac{\\mathbb{E}[X]}{m}$，分析如下：\n对于第 $i$ 个 worker，$A_{i}(t)$ 表示第 $i$ 个 worker 在 $t$ 时间内给 PS 发送的梯度个数，由更新理论的基本更新定理（Elementary renewal theorem）。\n$$ \\lim_{t \\rightarrow \\infty} \\frac{A_{i}(t)}{t} = \\frac{1}{\\mathbb{E}[X]} $$ 对于所有 worker 的梯度个数，我们有\n$$ \\lim_{t \\rightarrow \\infty} \\frac{\\sum_{i=1}^{m} A_{i}(t)}{t} = \\frac{m}{\\mathbb{E}[X]} $$ 因此每轮的运行时间为 $\\mathbb{E}[T_{\\text{async}}] = \\frac{\\mathbb{E}[X]}{m}$。\n相较于同步的情况，两者的比值 $\\frac{\\mathbb{E}[T_{\\text{sync}}]}{\\mathbb{E}[T_{\\text{async}}]} \\approx m\\ln m$，因此，异步的情况下，每轮迭代的时间是同步的 $O(m\\ln m)$ 倍。\n0x04 K-Async SGD 在 K-Async SGD 中，每次迭代，PS 会接收前 K 个 worker 的梯度，然后进行平均。\n此时，每轮迭代的期望时间为\n$$ \\mathbb{E}[T_{\\text{k-async}}] = \\mathbb{E}[X_{k:m}] = \\frac{1}{\\lambda} (H_{m} - H_{m-k}) \\approx \\frac{1}{\\lambda} \\ln(\\frac{m}{m-k}) $$ 如果 $X$ 服从 new-longer-than-used 分布，上式是 upper bound。\n0x05 Reference 《Optimization Algorithms for Distributed Machine Learning》，Gauri Joshi\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWikipedia, https://en.wikipedia.org/wiki/Renewal_theory\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-efficiency-analysis-of-distributed-machine-learning/","summary":"\u003ch2 id=\"0x00-preface\"\u003e0x00 Preface\u003c/h2\u003e\n\u003cp\u003e本文着眼于分布式机器学习中的效率分析，在分布式机器学习中，efficiency 通常指的是效率，即在一定的时间内，算法能够达到的最优解的质量，或者是需要得到一定的质量时，算法所需要的时间，参考\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e。\u003c/p\u003e","title":"分布式机器学习中的效率分析"},{"content":"0x00 Preface 本文着眼于分布式机器学习中的收敛性分析，作为第四部分，主要介绍了分布式学习中的收敛性证明，参考主要还是1。同时我们把假设拓展到分布式的 setting 下。\nGradient Unbiased Estimate Assumption $$ \\mathbb{E}[g(w;\\xi)] = \\nabla f(w) $$ Gradient Bounded Variance Assumption $$ \\mathrm {Var}(\\nabla f(w;\\xi)) \\leq \\sigma^2 $$ 由 $\\frac{1}{m} \\sum_{i=1}^{m} g\\left(w, \\xi_{i}\\right)$ 为 $\\nabla f(w)$ 的可得\n$$ \\mathrm {Var}\\left(\\frac{1}{m} \\sum_{i=1}^{m} g\\left(w, \\xi_{i}\\right)\\right) = \\mathbb{E}\\left[\\left(\\frac{1}{m} \\sum_{i=1}^{m} g\\left(w, \\xi_{i}\\right)\\right)^{2}\\right] - \\mathbb{E}\\left[\\frac{1}{m} \\sum_{i=1}^{m} g\\left(w, \\xi_{i}\\right)\\right]^{2} \\leq \\frac{\\sigma^{2}}{bm} $$ 即\n$$ \\mathbb{E}_{\\xi}[||g(w; \\xi)||^2] \\leq ||\\nabla f(w)||^{2} + \\frac{\\sigma^2}{bm} $$ 0x01 Distributed Synchronous Stochastic Gradient Descent 先介绍一下几个分布式的优化方法，首先就是同步的分布式随机梯度下降，其实就是在随机梯度下降上的扩展。假设我们有 $m$ 个 worker node，在 Parameter Server Framework 就叫做 synchronous SGD。迭代过程如下：\n$$ \\begin{aligned} w_{t+1} \u0026=w_{t}-\\frac{\\eta}{m} \\sum_{i=1}^{m} g(w_{t}, \\xi_{i}) \\\\ \u0026=w_{t}-\\frac{\\eta}{m} \\sum_{i=1}^{m} \\frac{1}{b} \\sum_{j=1}^{b} \\nabla f\\left(w_{t}, \\xi_{i, j}\\right) \\end{aligned} $$ 对于同步的 SGD，我们有如下定理：\ndefination\n假设目标函数 $f$ 是 $R^{d}$ 上的$\\mu$-强凸函数，并且 $L$-光滑，同时满足梯度无偏估计和梯度方差有界假设，当步长 $\\eta \\leq \\frac{1}{L}$ 且起始点为 $w_0$ 时，经过 $t$ 步 Distributed Synchronous mini-batch SGD 迭代，$\\mathbb{E}[f(w_{t})]$ 被 bounded 如下： $$ \\mathbb{E}[f(w_{t})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu bm} \\leq (1- \\eta \\mu)^{t}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu bm} \\right ) $$ 其实根据上面假设也可以看出来，基本就是在 SGD 的结论上多加了一个 $m$，把 $b$ 替换成了 $bm$ 即可，这里就不进行证明了，读者可以自行推导。\n除此之外，还有 K-Synchronous SGD, K-batch-Synchronous SGD，证明基本雷同，将 $m$ 替换成 $K$ 即可。\n0x02 Distributed Asynchronous Stochastic Gradient Descent 同步的情况下，往往根据木桶原理需要等待最慢的，如果有一个 worker node 出现了故障，那么整个系统就会被阻塞。虽然 $K-Sync$ 和 $K-batch-sync$ 能够在一定程度上缓解，但也存在浪费算力的问题（因为需要取消其他的计算任务、白白消耗了大量资源）。如果采用异步的方式，那么就能够避免这种情况，但是代价则是滞后的梯度（因为不取消其他计算任务意味着并不是从相同的参数起开始计算梯度的，the cost of gradient staleness）\n这一部分则是本文的重点，先说假设依旧是 $L-smooth$ 和 $\\mu$-strongly convex，同时满足梯度无偏估计和梯度方差有界假设。但是这里的梯度无偏估计和梯度方差有界假设和之前的定义略有不同\ndefination\nUnbiased Stochastic Gradients: 随机梯度是真实梯度的无偏估计 $$ \\mathbb{E}_{\\xi_{j}|w_{k}}[g(w_{k};\\xi_{j})] = \\nabla f(w_{k}), \\forall k \\leq j $$ 相较于之前的定义 $\\mathbb{E}{\\xi{j}}[g(w;\\xi_{j})] = \\nabla f(w)$ 更加严格了，因为 $k\u0026lt;j$ 的时候并非是独立同分布的，只有当前的迭代轮次达到 $j$ 之后，或者说能够 access 到 $\\xi_{j}$ 后才是独立同分布的。\ndefination\nBounded Gradient Variance: 梯度方差有界 $$ \\mathbb{E}_{\\xi_{j}|w_{k}}[||g(w_{k};\\xi_{j})-\\nabla f(w_{k})||^2] \\leq \\frac{\\sigma^2}{b}, \\forall k \\leq j $$ 除此之外，我们还需要一个滞后性的假设，即\ndefination\nBounded Staleness Assumption: 我们假设 $\\gamma \\leq 1$ $$ \\mathbb{E}[||\\nabla f(w_{j})-\\nabla f(w_{\\tau(j)})||^2] \\leq \\gamma \\mathbb{E}[||\\nabla f(w_{j})||^2] $$ 其中 $\\tau(j)$ 表示 worker 收到的模型版本的 index，$\\tau(j)\\leq j$，是个随机变量。同时，$\\tau(j)$ 受一个参数 $p_{0}$ 影响，在迭代中接收新梯度的概率的下界。\ndefination\n假设 $p_{0}^{(j)}$ 是 $\\tau(j)=j$ 的条件概率，在给定过去所有延迟和参数的情况下，$p_{0}\\leq p_{0}^{(j)}$，有 $$ \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2] \\geq p_{0} \\mathbb{E}[||\\nabla f(w_{j})||^2] $$ Proof:\n$$ \\begin{align} \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2] \u0026= p_{0}^{(j)} \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2|\\tau(j)=j] + (1-p_{0}^{(j)}) \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2|\\tau(j)\\neq j] \\\\ \u0026\\geq p_{0} \\mathbb{E}[||\\nabla f(w_{j})||^2] \\end{align} $$ 如果每个 worker 计算梯度的时间服从指数分布，则 $\\tau(j)$ 是服从几何分布的（geometrically distributed），并且 $p_{0}=\\frac{1}{m}$。这是因为，当服从指数分布是，PS在一个时间窗口内收到的梯度个数是服从泊松分布的。\n根据以上定义和假设，我们有\ndefination\n假设目标函数 $f$ 是 $R^{d}$ 上的$\\mu$-强凸函数，并且 $L$-光滑，同时满足梯度无偏估计、梯度方差有界和滞后性假设，当步长 $\\eta \\leq \\frac{1}{2L}$ 且起始点为 $w_0$ 时，经过 $t$ 步 Distributed Asynchronous mini-batch SGD 迭代，$\\mathbb{E}[f(w_{t})]$ 被 bounded 如下： $$ \\mathbb{E}[f(w_{t})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b{\\gamma}'} \\leq (1- \\eta \\mu{\\gamma}')^{t}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b{\\gamma}'} \\right ) $$ 其中 ${\\gamma}' = 1-\\gamma+\\frac{p_{0}}{2}$ Proof:\n由 $L$-smooth 可得\n$$ \\begin{align} f(w_{j+1}) \u0026\\leq f(w_{j}) + (w_{j+1}-w_{j})^{\\top}\\nabla f(w_{j}) + \\frac{L}{2}||w_{j+1}-w_{j}||^2 \\\\ \u0026= f(w_{j}) - \\eta g(w_{\\tau(j)})^{\\top}\\nabla f(w_{j}) + \\frac{L\\eta^2}{2}||g(w_{\\tau(j)})||^2 \\\\ \u0026= f(w_{j}) - \\frac{\\eta}{2} ||\\nabla f(w_{j})||^2 - \\frac{\\eta}{2} ||g(w_{\\tau(j)})||^2 + \\frac{\\eta}{2} ||\\nabla f(w_{j})-g(w_{\\tau(j)})||^2 + \\frac{L\\eta^2}{2}||g(w_{\\tau(j)})||^2 \\end{align} $$ 最后一行由 $2a^{\\top}b = ||a||^2 + ||b||^2 - ||a-b||^2$ 得到。由于 $g(w_{\\tau(j)})$ 是无偏估计，对两边求期望得\n$$ \\begin{align} \\mathbb{E}[f(w_{j+1})] - \\mathbb{E}[f(w_{j})] \u0026\\leq - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})-g(w_{\\tau(j)})||^2] + \\frac{L\\eta^2}{2}\\mathbb{E}[||g(w_{\\tau(j)})||^2] \\\\ \u0026= - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})-\\nabla f(w_{\\tau(j)}) +\\nabla f(w_{\\tau(j)}) - g(w_{\\tau(j)})||^2] + \\frac{L\\eta^2}{2}\\mathbb{E}[||g(w_{\\tau(j)})||^2] \\\\ \u0026= - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{L\\eta^2}{2}\\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})-\\nabla f(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{\\tau(j)}) - g(w_{\\tau(j)})||^2] \\\\ \u0026= - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{L\\eta^2}{2}\\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})-\\nabla f(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} (\\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2] - 2\\mathbb{E}[\\nabla f(w_{\\tau(j)})^{\\top}g(w_{\\tau(j)})] + \\mathbb{E}[||g(w_{\\tau(j)})||^2]) \\\\ \u0026= - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{L\\eta^2}{2}\\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})-\\nabla f(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||g(w_{\\tau(j)})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2] \\\\ \u0026= - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2] + \\frac{L\\eta^2}{2}\\mathbb{E}[||g(w_{\\tau(j)})||^2] + \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})-\\nabla f(w_{\\tau(j)})||^2] \\\\ \u0026\\leq - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] - \\frac{\\eta}{2} \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2] + (\\frac{L\\eta^2\\sigma^{2}}{2b} + \\frac{L\\eta^2}{2}\\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2]) + \\frac{\\eta \\gamma}{2} \\mathbb{E}[||\\nabla f(w_{j})||^2] \\\\ \u0026= \\frac{\\eta}{2}(1-\\gamma) \\mathbb{E}[||\\nabla f(w_{j})||^2] + \\frac{L\\eta^2\\sigma^{2}}{2b} - \\frac{\\eta}{2}(1-\\eta L) \\mathbb{E}[||\\nabla f(w_{\\tau(j)})||^2] \\\\ \u0026\\leq \\frac{\\eta}{2}(1-\\gamma) \\mathbb{E}[||\\nabla f(w_{j})||^2] + \\frac{L\\eta^2\\sigma^{2}}{2b} - \\frac{\\eta}{4}p_{0}\\mathbb{E}[||\\nabla f(w_{j})||^2] \\\\ \u0026= -\\frac{\\eta}{2}(1-\\gamma+\\frac{p_{0}}{2}) \\mathbb{E}[||\\nabla f(w_{j})||^2] + \\frac{L\\eta^2\\sigma^{2}}{2b} \\end{align} $$ 后面，就是利用强凸性\n$$ 2\\mu (f(w) - f(w^{*})) \\leq ||\\nabla f(w)||^2 $$ 有\n$$ \\mathbb{E}[f(w_{j})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2b} \\leq (1- \\eta \\mu(1-\\gamma+\\frac{p_{0}}{2}))^{t}\\left (\\mathbb{E}[f(w_{j})] - f(w^{*}) \\right ) $$ 令 ${\\gamma}\u0026rsquo; = 1-\\gamma+\\frac{p_{0}}{2}$，再配平（？），累乘，即可得到结论。\n$$ \\mathbb{E}[f(w_{j})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b{\\gamma}'} \\leq (1- \\eta \\mu{\\gamma}')^{t}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b{\\gamma}'} \\right ) $$ 0x03 K-Async SGD 此时，\n$$w_{j+1}=w_{j}-\\frac{\\eta}{K} \\sum_{i=1}^{K} g(w_{\\tau(k,j)};\\xi_{k,j})$$\n其中，$k=1,2,\\cdots,K$ 表示在当前轮贡献的 worker 索引，$\\xi_{k,j}$ 表示第 $k$ 个 worker 在第 $j$ 轮迭代中的样本，$\\tau(k,j)$ 表示第 $k$ 个 worker 在第 $j$ 轮迭代中的模型版本的 index，$\\tau(k,j)\\leq j$，是个随机变量。同时，$g(w_{\\tau(k,j)};\\xi_{k,j}) = \\frac{1}{b} \\sum_{\\xi \\in \\xi_{k,j}} \\nabla f(w_{\\tau(k,j)};\\xi_{k,j})$。\n此时结论也是略有变动，${\\gamma}\u0026rsquo; = 1-\\gamma+\\frac{p_{0}}{2}$\n$$ \\mathbb{E}[f(w_{j})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b{\\gamma}'K} \\leq (1- \\eta \\mu{\\gamma}')^{t}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b{\\gamma}'K} \\right ) $$ Reference 《Optimization Algorithms for Distributed Machine Learning》，Gauri Joshi\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-convergence-analysis-in-deep-learning-part-4/","summary":"\u003ch2 id=\"0x00-preface\"\u003e0x00 Preface\u003c/h2\u003e\n\u003cp\u003e本文着眼于分布式机器学习中的收敛性分析，作为第四部分，主要介绍了分布式学习中的收敛性证明，参考主要还是\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e。同时我们把假设拓展到分布式的 setting 下。\u003c/p\u003e\n\u003ch3 id=\"gradient-unbiased-estimate-assumption\"\u003eGradient Unbiased Estimate Assumption\u003c/h3\u003e\n\u003cdiv class=\"has-mathjax\"\u003e\n\n\n$$\n\\mathbb{E}[g(w;\\xi)] = \\nabla f(w)\n$$\n\n\n\u003c/div\u003e\n\u003ch3 id=\"gradient-bounded-variance-assumption\"\u003eGradient Bounded Variance Assumption\u003c/h3\u003e\n\u003cdiv class=\"has-mathjax\"\u003e\n\n\n$$\n\\mathrm {Var}(\\nabla f(w;\\xi)) \\leq \\sigma^2\n$$\n\n\n\u003c/div\u003e\n\u003cp\u003e由 $\\frac{1}{m} \\sum_{i=1}^{m} g\\left(w, \\xi_{i}\\right)$ 为 $\\nabla f(w)$ 的可得\u003c/p\u003e","title":"分布式机器学习中的收敛性分析 (Part 4)"},{"content":"0x00 Preface 本文着眼于深度学习中的收敛性分析，作为第三部分，主要介绍了深度学习中随机梯度下降的收敛性证明1。相较于上一篇 (Part2) 的梯度下降，随机梯度下降的收敛性证明更加复杂，因为随机梯度下降的梯度是随机的，因此需要引入一些随机变量和假设，一些关于随机梯度下降的定义已经在 Part1 中进行了说明。\ncopy 一下先前的定义在下面：\nGradient Unbiased Estimate Assumption $$ \\mathbb{E}[g(w;\\xi)] = \\nabla f(w) $$ Gradient Bounded Variance Assumption $$ \\mathrm {Var}(\\nabla f(w;\\xi)) \\leq \\sigma^2 $$ 和上面的计算可以得到\n$$ \\mathbb{E}_{\\xi}[||g(w; \\xi)||^2] \\leq ||\\nabla f(w)||^{2} + \\frac{\\sigma^2}{b} $$ 0x01 Smooth and Strongly Convex with mini-batch SGD defination\n假设目标函数 $f$ 是 $R^{d}$ 上的$\\mu$-强凸函数，并且 $L$-光滑，同时满足梯度无偏估计和梯度方差有界假设，当步长 $\\eta \\leq \\frac{1}{L}$ 且起始点为 $w_0$ 时，经过 $t$ 步 mini-batch SGD 迭代，$\\mathbb{E}[f(w_{t})]$ 被 bounded 如下： $$ \\mathbb{E}[f(w_{t})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b} \\leq (1- \\eta \\mu)^{t}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b} \\right ) $$ Proof:\n由光滑性：\n$$ \\begin{align} f(w_{t+1}) - f(w_{t})\u0026\\leq \\nabla f(w_{t})^{\\top}(w_{t+1} - w_{t}) + \\frac{L}{2}||w_{t+1} - w_{t}||^{2} \\\\ \u0026\\leq -\\eta \\nabla f(w_{t})^{\\top}g(w_{t}; \\xi_{t}) + \\frac{L}{2}||-\\eta g(w_{t}; \\xi_{t})||^{2} \\\\ \u0026\\leq -\\eta \\nabla f(w_{t})^{\\top}g(w_{t}; \\xi_{t}) + \\frac{L\\eta^{2}}{2} ||g(w_{t}; \\xi_{t})||^{2} \\\\ \\end{align} $$ 对左右求期望得：\n$$ \\begin{align} \\mathbb{E}[f(w_{t+1}) - f(w_{t})] \u0026\\leq -\\eta \\mathbb{E}[\\nabla f(w_{t})^{\\top}g(w_{t}; \\xi_{t})] + \\frac{L\\eta^{2}}{2} \\mathbb{E}[||g(w_{t}; \\xi_{t})||^{2}] \\\\ \\mathbb{E}[f(w_{t+1})] - f(w_{t}) \u0026\\leq -\\eta ||\\nabla f(w_{t})||^{2} + \\frac{L\\eta^{2}}{2}||\\nabla f(w_{t})||^{2} + \\frac{L\\eta^{2} \\sigma^{2}}{2b} \\\\ \u0026\\leq (\\eta-\\frac{L\\eta^{2}}{2}) (-||\\nabla f(w_{t})||^{2}) + \\frac{L\\eta^{2} \\sigma^{2}}{2b} \\end{align} $$ 这里和 GD 就比较像了，取 $\\eta\u0026lt;\\frac{1}{L}$，在利用强凸性则有：\n$$ \\begin{align} \\mathbb{E}[f(w_{t+1})] - f(w_{t}) \u0026\\leq \\frac{\\eta}{2}(-||\\nabla f(w_{t})||^{2}) + \\frac{L\\eta^{2} \\sigma^{2}}{2b} \\\\ \u0026\\leq \\frac{\\eta}{2}(-2\\mu(f(w_{t})-f^{*})) + \\frac{L\\eta^{2} \\sigma^{2}}{2b} \\\\ \u0026\\leq -\\eta\\mu(\\mathbb{E}[f(w_{t})]-f^{*}) + \\frac{L\\eta^{2} \\sigma^{2}}{2b} \\\\ \\end{align} $$ 左右都 $+f^{}-f^{}$，得到\n$$ \\mathbb{E}[f(w_{t+1})] - f^{*} \\leq (1-\\eta\\mu)(\\mathbb{E}[f(w_{t})]-f^{*}) + \\frac{L\\eta^{2} \\sigma^{2}}{2b} $$ 接下来就需要配方了，我们还是假设一个未知数 $x$，使得\n$$ \\mathbb{E}[f(w_{t+1})] - f^{*} + x \\leq (1-\\eta\\mu)(\\mathbb{E}[f(w_{t})]-f^{*} + x) $$ 也就是\n$$ (1-\\eta\\mu)x - x = \\frac{L\\eta^{2} \\sigma^{2}}{2b} \\\\ x = - \\frac{L\\eta \\sigma^{2}}{2\\mu b} $$ 即\n$$ \\mathbb{E}[f(w_{t+1})] - f^{*} - \\frac{L\\eta \\sigma^{2}}{2\\mu b} \\leq (1-\\eta\\mu)(\\mathbb{E}[f(w_{t})]-f^{*} - \\frac{L\\eta \\sigma^{2}}{2\\mu b}) $$ 得到\n$$ \\mathbb{E}[f(w_{t})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b} \\leq (1- \\eta \\mu)^{t}\\left (\\mathbb{E}[f(w_{0})] - f(w^{*}) - \\frac{\\eta L \\sigma^{2}}{2\\mu b} \\right ) $$ 证毕\n0x02 Non-convex with mini-batch SGD defination\n假设目标函数 $f$ 是 $R^{d}$ 上的 $L$-光滑函数，并且满足梯度无偏估计和梯度方差有界假设，当步长 $\\eta \\leq \\frac{1}{L}$ 且起始点为 $w_0$ 时，经过 $t$ 步 mini-batch SGD 迭代，$f$ 梯度平方的平均期望被 bounded 如下： $$ \\mathbb{E}[\\frac{1}{t}\\sum_{i=1}^{t} ||\\nabla f(w_{i})||^{2}] \\leq \\frac{L \\sigma^{2}}{b} + \\frac{2(f(w_{0})-f(w_{\\inf}))}{t\\eta} $$ Proof:\n直接从上面的 $L$-光滑性得到的结论，和 $\\eta \u0026lt; \\frac{1}{L}$ 开始\n$$ \\mathbb{E}[f(w_{t+1})] - f(w_{t}) \\leq -\\eta ||\\nabla f(w_{t})||^{2} + \\frac{L\\eta^{2} \\sigma^{2}}{2b} $$ 对两边都求和，在除以 $t$，得到\n$$ \\begin{align} \\frac{1}{t}\\sum_{i=1}^{t} \\mathbb{E}[f(w_{i+1})] - f(w_{i}) \u0026\\leq -\\frac{\\eta }{2t}\\sum_{i=1}^{t} ||\\nabla f(w_{i})||^{2} + \\frac{L\\eta^{2} \\sigma^{2}}{2b} \\\\ \\frac{1}{t} \\sum_{i=1}^{t} ||\\nabla f(w_{i})||^{2} \u0026\\leq -\\frac{2\\mathbb{E}[f(w_{t+1})-f(w_{0})]}{\\eta t} + \\frac{L\\eta \\sigma^{2}}{2b} \\\\ \u0026\\leq \\frac{2(f(w_{0})-f(w_{\\inf}))}{\\eta t} + \\frac{L\\eta \\sigma^{2}}{2b} \\end{align} $$ 证毕\nReference 《Optimization Algorithms for Distributed Machine Learning》，Gauri Joshi\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-convergence-analysis-in-deep-learning-part-3/","summary":"\u003ch2 id=\"0x00-preface\"\u003e0x00 Preface\u003c/h2\u003e\n\u003cp\u003e本文着眼于深度学习中的收敛性分析，作为第三部分，主要介绍了深度学习中随机梯度下降的收敛性证明\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e。相较于\u003ca href=\"/p/blog-convergence-analysis-in-deep-learning-part-2/\"\u003e上一篇 (Part2)\u003c/a\u003e 的梯度下降，随机梯度下降的收敛性证明更加复杂，因为随机梯度下降的梯度是随机的，因此需要引入一些随机变量和假设，一些关于随机梯度下降的定义已经在 \u003ca href=\"/p/blog-convergence-analysis-in-deep-learning-part-1/\"\u003ePart1\u003c/a\u003e 中进行了说明。\u003c/p\u003e","title":"深度学习中的收敛性分析 (Part 3)"},{"content":"0x00 Preface 本文着眼于深度学习中的收敛性分析，作为第二部分，主要介绍了深度学习中梯度下降在（强凸光滑/光滑凸/非光滑凸/光滑非凸/非凸情况下）的收敛性证明。对于先前的定义，本文将不再赘述，读者可以先阅读 深度学习中的收敛性分析 (Part 1)。很多内容参考了1,2,3和4，少量参考 5。\n0x01 Definition of Convergence 通常，深度学习的优化问题可以表示为\n$$ \\min_{w} f(w) $$ 其中，$w$ 是待优化的参数，$f(w)$ 是待优化的目标函数。在深度学习中，我们通常使用梯度下降法来求解优化问题，即\n$$ w_{t+1} = w_t - \\eta \\nabla f(w_t) $$ 而一个梯度方法是收敛的可以从三个方面来定义：\n目标函数值收敛到最优值：$\\mathbb{E} f(w_T) - f^* \\leq \\epsilon(T)$，其中 $f^*$ 是目标函数的最优值\n迭代序列收敛到最优解：$\\mathbb{E} ||w_T - w^*||^2 \\leq \\epsilon(T)$，其中 $w^*$ 是参数的最优解\n如果，$\\epsilon(T) \\to 0$，那么我们称这个梯度方法是收敛的。对于收敛优化算法，它们的收敛速率可能并不相同，通常，用 $\\log \\epsilon(T)$ 的衰减速率来定义优化算法的收敛速率。\n1） 如果 $\\log \\epsilon(T)$ 与 $-T$ 同阶，那么我们称这个算法具有线性收敛速率。 2） 如果 $\\log \\epsilon(T)$ 比 $-T$ 衰减速度慢，那么我们称这个算法具有次线性收敛速率。 3） 如果 $\\log \\epsilon(T)$ 比 $-T$ 衰减速度快，那么我们称这个算法具有超线性收敛速率，进一步地，如果 $\\log \\log \\epsilon(T)$ 与 $-T$ 同阶，那么我们称这个算法具有二阶收敛速率。 而在非凸优化中，由于可能存在多个局部极小点，不容易找到全局最优，因此考虑算法能否收敛到梯度为 0 的临界点。\n利用梯度的遍历距离作为度量：$\\min_{t=1,\\cdots,T} \\mathbb{E} ||\\nabla f(w_T)||^2 \\leq \\epsilon(T)$ 或者 $\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}||\\nabla f(w_{t})||^2$ 趋于 0 info\n下面将从最强的假设 强凸+光滑 开始，逐步放松条件进行分析。 0x02 Smooth Strongly Convex with GD defination\n假设目标函数 $f$ 是 $R^{d}$ 上的$\\mu$-强凸函数，并且 $L$-光滑，当步长 $\\eta \\leq \\frac{1}{L}$ 且起始点为 $w_0$ 时，经过 $t$ 步迭代，$f(w_T)$ 被 bounded 如下： $$ f\\left(w_{t}\\right)-f^{*} \\leq (1-\\eta \\mu)^{t}\\left(f\\left(w_{0}\\right)-f^{*}\\right) $$ Proof:\ntip\n先说一个整体的证明思路，大致下面的内容也是这样的，先证明单步迭代的 bounded，然后再利用数学归纳法证明多步迭代的 bounded。其间会通过对 $\\eta$ 的取值进行限制（往往通过二次函数的顶点来确定，或者双曲函数来确定）。同时注意，光滑性给了函数的一个上界，强凸性给了函数的一个下界，有时候为了统一不等式符号方向，会对函数取负号。 同时，哪怕是对函数同样的假设，在不同的 $\\eta$ 设置中和不同的 bounded 中，也会有不同的收敛速率。 先看单步迭代：\n$$ \\begin{aligned} f\\left(w_{t+1}\\right)-f\\left(w_{t}\\right) \u0026=f\\left(w_{t}-\\eta \\nabla f\\left(w_{t}\\right)\\right)-f\\left(w_{t}\\right) \\\\ \u0026 \\leq \\nabla f\\left(w_{t}\\right)^{\\top}\\left(w_{t}-\\eta \\nabla f\\left(w_{t}\\right)-w_{t}\\right)+\\frac{L}{2}\\left\\|w_{t}-\\eta \\nabla f\\left(w_{t}\\right)-w_{t}\\right\\|^{2} \\\\ \u0026=-\\eta \\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2}+\\frac{L}{2} \\eta ^{2}\\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2} \\\\ \u0026=\\left(\\frac{L}{2} \\eta ^{2}-\\eta \\right)\\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2} \\end{aligned} $$ 这时候我们通过对两项都添加负号，然后利用二次函数的顶点来确定 $\\eta$ 的取值，同时希望用上强凸函数导出的性质，即\n$$ 2\\mu (f(x)-f^{*}) \\leq \\|\\nabla f(x)\\|^2 $$ 于是有\n$$ \\begin{aligned} f\\left(w_{t+1}\\right)-f\\left(w_{t}\\right) \u0026\\leq \\eta \\left(1-\\frac{L}{2} \\eta \\right)\\left(-\\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2}\\right) \\\\ \u0026 \\leq \\eta \\left(1-\\frac{L}{2} \\eta \\right)\\left(2\\mu \\left(f\\left(w_{t}\\right)-f^{*}\\right)\\right) \\end{aligned} $$ 这时，我们令 $\\eta \\leq \\frac{1}{L}$，则有 $(1-\\frac{L}{2} \\eta ) \\geq \\frac{1}{2}$，于是有\n$$ f\\left(w_{t+1}\\right)-f\\left(w_{t}\\right) \\leq -\\eta \\mu (f\\left(w_{t}\\right)-f^{*}) $$ 注意到，左右都是关于 $f(x)$ 的式子，在左边 $+-f^*$，得到\n$$ f\\left(w_{t+1}\\right)-f^{*}+f^{*}-f\\left(w_{t}\\right) \\leq -\\eta \\mu (f\\left(w_{t}\\right)-f^{*}) \\\\ \\Rightarrow f\\left(w_{t+1}\\right)-f^{*} \\leq (1-\\eta \\mu) (f\\left(w_{t}\\right)-f^{*}) $$ 后面就归纳一下：\n$$ \\begin{aligned} f\\left(w_{t+1}\\right)-f^{*} \u0026 \\leq(1-\\eta \\mu)\\left(f\\left(w_{t}\\right)-f^{*}\\right) \\\\ \u0026 \\leq(1-\\eta \\mu)\\left(1-\\eta \\mu\\right)\\left(f\\left(w_{t-1}\\right)-f^{*}\\right) \\\\ \u0026 \\leq \\cdots \\\\ \u0026 \\leq(1-\\eta \\mu) \\cdots(1-\\eta \\mu)\\left(f\\left(w_{1}\\right)-f^{*}\\right) \\\\ \u0026 \\leq(1-\\eta \\mu)^{t+1}\\left(f\\left(w_{0}\\right)-f^{*}\\right) \\end{aligned} $$ 现在，我们得到了 boundary，来计算一下复杂度。\n根据复杂度的定义，令 $f(w_t)-f^* \\leq \\epsilon$，则有\n$$ (1-\\eta \\mu)^{t}(f(w_0)-f^*) \\leq \\epsilon \\\\ \\Rightarrow t\\log (1-\\eta \\mu) + \\log (f(w_0)-f^*) \\leq \\log \\epsilon \\\\ \\Rightarrow t\\log \\frac{1}{1-\\eta \\mu} - \\log (f(w_0)-f^*) \\geq \\log \\frac{1}{\\epsilon} \\\\ \\Rightarrow t=O(\\log \\frac{1}{\\epsilon}) $$ tip\n其中，$Q=\\frac{L}{\\mu}$，一般被称为条件数。 从 0x02 和 0x03，我们对梯度下降法的收敛性质有以下讨论： 1. 当目标函数是强凸函数时，梯度下降法的收敛速率是线性的；当目标函数是凸函数时，其收敛速率是次线性的。也就是说，强凸性质会大大提高梯度下降法的收敛速率。进一步地，强凸性之越好（即$\\mu$ 越大），条件数 $Q$ 越小，收敛越快。 2. 光滑性质在凸和强凸两种情形下都会加快梯度下降法的收敛速率，即 $L$ 越小（强凸情况下，条件数 $Q$ 越小），收敛越快。 0x03 Smooth Convex with GD defination\n假设目标函数 $f$ 是 $R^{d}$ 上的凸函数，并且 $L$-光滑，当步长 $\\eta =\\frac{1}{L}$ 且起始点为 $w_0$ 时，经过 $t$ 步迭代，$f(w_t)$ 被 bounded 如下： $$ f\\left(w_{t}\\right)-f^{*} \\leq \\frac{L}{2T} || w_{0} - w^{*} ||^{2} $$ Proof:\n由上面的证明，我们已经知道在 $L$-光滑的情况下，有\n$$ f(w_{t+1})-f(w_{t}) \\leq \\eta \\left(1-\\frac{L}{2} \\eta \\right)\\left(-\\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2}\\right) $$ 根据凸性质，有\n$$ f(w_{t})-f^{*} \\leq \\nabla f(w_{t})^{\\top}(w_{t}-w^{*}) $$ 根据梯度下降有等式\n$$ \\left \\| w_{t+1} - w^{*} \\right \\|^{2} = \\left \\| w_{t} - w^{*} \\right \\|^{2} - 2 \\eta \\nabla f(w_{t})^{\\top}(w_{t}-w^{*}) + \\eta^{2} \\left \\| \\nabla f(w_{t}) \\right \\|^{2} $$ 我们用 GD 得到的等式中的 $\\nabla f(w_{t})^{\\top}(w_{t}-w^{*})$ 替换掉凸性质中的，有\n$$ \\begin{aligned} f(w_{t+1})-f^{*} \u0026= f(w_{t+1})-f(w_{t})+f(w_{t})-f^{*} \\\\ \u0026 \\leq \\eta \\left(1-\\frac{L}{2} \\eta \\right)\\left(-\\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2}\\right) + \\nabla f(w_{t})^{\\top}(w_{t}-w^{*}) \\\\ \u0026= \\eta \\left(1-\\frac{L}{2} \\eta \\right)\\left(-\\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2}\\right) + \\frac{1}{2\\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2\\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} + \\frac{\\eta}{2} \\left \\| \\nabla f(w_{t}) \\right \\|^{2} \\\\ \u0026 = (\\frac{L}{2}\\eta ^2-\\eta + \\frac{\\eta}{2}) \\left \\| \\nabla f(w_{t}) \\right \\|^{2} + \\frac{1}{2\\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2\\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} \\\\ \u0026 = \\frac{\\eta}{2}(L\\eta - 1) \\left \\| \\nabla f(w_{t}) \\right \\|^{2} + \\frac{1}{2\\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2\\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} \\end{aligned} $$ 注意这里，我们令 $\\eta = \\frac{1}{L}$，于是就能够将 $||\\nabla f(w_{t})||^2$ 的项消去，这个取值其实是从 $f(w_{t+1})-f(w_{t})$ 的不等式中取值得到的，因为要小于最小值，后面其实是一个等式替换，不涉及 $\\eta$ 的取值。\n$$ f(w_{t+1})-f^{*} \\leq \\frac{L}{2} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{L}{2} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} $$ 看到这个相比就知道后面怎么做了，就是一个求和了\n$$ \\begin{aligned} \\sum_{t=0}^{T} f(w_{t+1})-f^{*} \u0026\\leq \\frac{L}{2} \\sum_{t=0}^{T} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{L}{2} \\sum_{t=0}^{T-1} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} \\\\ \u0026= \\frac{L}{2} \\left \\| w_{0} - w^{*} \\right \\|^{2} - \\frac{L}{2} \\left \\| w_{T+1} - w^{*} \\right \\|^{2} \\\\ \u0026\\leq \\frac{L}{2} \\left \\| w_{0} - w^{*} \\right \\|^{2} \\end{aligned} $$ 注意等式左边也可以继续进行放缩，即\n$$ \\min_{t=1,\\cdots,T} f(w_{t})-f^{*} \\leq \\frac{L}{2T} \\left \\| w_{0} - w^{*} \\right \\|^{2} $$ 证毕。\n这时候，我们得到了 boundary，来计算一下复杂度。\n根据复杂度的定义，令 $f(w_t)-f^* \\leq \\epsilon$，则有\n$$ f(w_{t}-f^{*}) \\leq \\frac{L}{2T} \\left \\| w_{0} - w^{*} \\right \\|^{2} \\leq \\epsilon \\\\ T \\geq \\frac{L}{2\\epsilon} \\left \\| w_{0} - w^{*} \\right \\|^{2} \\\\ \\Rightarrow T=O(\\frac{1}{\\epsilon}) $$ 是次线性的收敛速率。\n0x04 Non-smooth Convex with GD 如果我们仅剩凸性质，那么必须加上梯度有界的假设才能 bound 住，从而保证收敛，因而我们可以得到如下的结论：\ndefination\n假设目标函数 $f$ 是 $R^{d}$ 上的凸函数，当步长 $\\eta =\\frac{f(w_{0})-f^*}{\\sqrt{T+1}G}$ 且起始点为 $w_{0}$ 时，经过 $t$ 步迭代，$f(w_{t})$ 被 bounded 如下： $$ \\min_{t=0,\\cdots,T} f\\left(w_{t}\\right)-f^{*} \\leq \\frac{G||w_{0}-w^{*}||^{2}}{\\sqrt{T+1}} $$ Proof:\n其实和上面是大概相同的思路，有\n$$ \\begin{aligned} f(w_{t})-f^{*} \u0026\\leq \\nabla f(w_{t})^{\\top}(w_{t}-w^{*}) \\\\ \u0026= \\frac{1}{2\\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2\\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} + \\frac{\\eta}{2} \\left \\| \\nabla f(w_{t}) \\right \\|^{2} \\\\ \u0026\\leq \\frac{1}{2\\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2\\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} + \\frac{\\eta}{2} G^{2} \\end{aligned} $$ 同样对左右进行求和\n$$ \\begin{aligned} \\sum_{t=0}^{T} f(w_{t})-f^{*} \u0026\\leq \\sum_{t=0}^{T} \\frac{1}{2\\eta} (\\left \\| w_{t} - w^{*} \\right \\|^{2} - \\left \\| w_{t+1} - w^{*} \\right \\|^{2}) + (T+1) \\frac{\\eta}{2} G^{2} \\\\ \u0026= \\frac{1}{2\\eta} \\left \\| w_{0} - w^{*} \\right \\|^{2} - \\frac{1}{2\\eta} \\left \\| w_{T+1} - w^{*} \\right \\|^{2} + \\frac{\\eta (T+1)}{2} G^{2} \\\\ \u0026\\leq \\frac{1}{2\\eta} \\left \\| w_{0} - w^{*} \\right \\|^{2} + \\frac{\\eta (T+1)}{2} G^{2} \\\\ \\end{aligned} $$ 即\n$$ \\min_{t=0,\\cdots,T} f\\left(w_{t}\\right)-f^{*} \\leq \\frac{1}{2\\eta (T+1)} \\left \\| w_{0} - w^{*} \\right \\|^{2} + \\frac{\\eta}{2}G^{2} $$ 根据小学二年级的对勾函数，我们有当 $\\eta = \\sqrt{\\frac{||w_{0}-w^{}||^{2}}{G^{2}(T+1)}}=\\frac{||w_{0}-w^{}||}{G\\sqrt{T+1}}$ 时，有\n$$ \\min_{t=0,\\cdots,T} f\\left(w_{t}\\right)-f^{*} \\leq \\frac{G||w_{0}-w^{*}||^{2}}{\\sqrt{T+1}} $$ 证毕。\n复杂度很容易就看出来\n$$ \\frac{G||w_{0}-w^{*}||^{2}}{\\sqrt{T+1}} \\leq \\epsilon \\\\ T \\geq \\frac{G^{2}||w_{0}-w^{*}||^{2}}{\\epsilon^{2}} \\\\ \\Rightarrow T=O(\\frac{1}{\\epsilon^{2}}) $$ 是次线性的收敛速率。\n这里有一个 Alternative 的方法，反着推比较容易，我个人觉得不太容易从正面想到。\ndefination\n假设目标函数 $f$ 是 $R^{d}$ 上的凸函数，当步长 $\\eta = \\frac{f(w_{t})-f^{*}}{||\\nabla f(w_{t})||^2}$ 且起始点为 $w_{0}$ 时，经过 $t$ 步迭代，$f(w_{t})$ 被 bounded 如下： $$ \\min_{t=0}^{T} f(w_{t})-f^{*}\\leq \\frac{G\\left \\|| w_{0}-w_{*}\\right \\||}{\\sqrt{T+1}} $$ Proof:\n从梯度下降出发：\n$$ \\begin{aligned} \\left \\|w_{t+1}-w^{*}\\right \\|^{2} \u0026= \\left \\|w_{t}-\\eta \\nabla f(w_{t})-w^{*}\\right \\|^{2} \\\\ \u0026= \\left \\|w_{t}-w^{*}\\right \\|^{2} - 2\\eta \\nabla f(w_{t})^{\\top}(w_{t}-w^{*}) + \\eta^{2} \\left \\| \\nabla f(w_{t}) \\right \\|^{2} \\\\ \u0026= \\left \\|w_{t}-w^{*}\\right \\|^{2} - 2\\eta (f(w_{t})-f^{*}) + \\eta^{2} \\left \\| \\nabla f(w_{t}) \\right \\|^{2} \\end{aligned} $$ 这时，是一个关于 $\\eta$ 的二次函数，直接令 $\\eta = \\frac{f(w_{t})-f^{*}}{||\\nabla f(w_{t})||^2}$，这个也称为 Polyak 步长，于是有\n$$ \\left \\|w_{t+1}-w^{*}\\right \\|^{2} \\leq \\left \\|w_{t}-w^{*}\\right \\|^{2} - \\frac{(f(w_{t})-f^{*})^{2}}{||\\nabla f(w_{t})||^{2}} $$ 移项得到\n$$ (f(w_{t})-f^{*})^{2} \\leq ||\\nabla f(w_{t})||^{2} (\\left \\|w_{t}-w^{*}\\right \\|^{2} - \\left \\|w_{t+1}-w^{*}\\right \\|^{2}) \\\\ \\sum_{t=0}^{T} (f(w_{t})-f^{*})^{2} \\leq \\sum_{t=0}^{T} G^{2} (\\left \\|w_{t}-w^{*}\\right \\|^{2} - \\left \\|w_{t+1}-w^{*}\\right \\|^{2}) \\\\ \\Rightarrow \\min_{t=0}^{T} (f(w_{t})-f^{*})^{2} \\leq \\frac{G^2\\left \\| w_{0}-w_{*}\\right \\|^2}{T+1} \\\\ \\Rightarrow \\min_{t=0}^{T} (f(w_{t})-f^{*}) \\leq \\frac{G\\left \\| w_{0}-w_{*}\\right \\|}{\\sqrt{T+1}} $$ 与上面方法选择的 $\\eta$ 不同，但是有相同的收敛速率。\n0x05 Smooth non-convex with GD defination\n假设目标函数 $f$ 是 $R^{d}$ 上的 $L$-光滑函数，当步长 $\\eta =\\frac{1}{L}$ 且起始点为 $w_0$ 时，经过 $t$ 步迭代，$f(w_t)$ 被 bounded 如下： $$ \\min_{t=0,\\cdots,T} \\left\\||\\nabla f(w_{t})\\right\\||^{2} \\leq \\frac{2L (f(w_{0})-f(w^{*}))}{(T+1)} $$ Proof:\n我们直接从上面的结论出发，有\n$$ \\begin{align} f(w_{t+1})-f(w_{t}) \u0026\\leq \\eta \\left(1-\\frac{L}{2} \\eta \\right)\\left(-\\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2}\\right) \\\\ \\eta (1-\\frac{L}{2}\\eta) \\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2} \u0026\\leq f(w_{t})-f(w_{t+1}) \\end{align} $$ 左边取最大值，即 $\\eta = \\frac{1}{L}$，有\n$$ \\frac{1}{2L} \\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2} \\leq f(w_{t})-f(w_{t+1}) $$ 简单求和，再放缩一下：\n$$ \\begin{aligned} \\sum_{t=0}^{T} \\frac{1}{2L} \\left\\|\\nabla f\\left(w_{t}\\right)\\right\\|^{2} \u0026\\leq \\sum_{t=0}^{T} f(w_{t})-f(w_{t+1}) \\\\ \u0026= f(w_{0})-f(w_{T+1}) \\\\ \u0026\\leq f(w_{0})-f(w^{*}) \\end{aligned} $$ 证毕。\n0x06 Strongly Convex and Non-smooth with GD 好了到这里只剩最后一个了，但注意这里除了强凸性，还需要 $L$-Lipschitz 连续性，相当于各点梯度一致有界，至少梯度不能直接飞了\u0026hellip;\ndefination\n假设目标函数 $f$ 是 $R^{d}$ 上的 $\\mu$-强凸函数，且 $L$-Lipschitz 连续，当步长 $\\eta_{t} =\\frac{2}{\\eta (t+1)}$ 且起始点为 $w_0$ 时，经过 $t$ 步迭代，$f(w_t)$ 被 bounded 如下： $$ \\min_{t=0,\\cdots,T} f(w_{t})-f^{*} \\leq \\frac{2L^{2}}{\\mu (T+1)} $$ Proof:\n由 GD 和 强凸性\n$$ \\left \\| w_{t+1} - w^{*} \\right \\|^{2} = \\left \\| w_{t} - w^{*} \\right \\|^{2} - 2 \\eta \\nabla f(w_{t})^{\\top}(w_{t}-w^{*}) + \\eta^{2} \\left \\| \\nabla f(w_{t}) \\right \\|^{2} \\\\ \\leq (1-\\eta \\mu ) \\left \\| w_{t} - w^{*} \\right \\|^{2} - 2 \\eta (f(w_{t})-f^{*}) + \\eta^{2} \\left \\| \\nabla f(w_{t}) \\right \\|^{2} $$ 有 $L$-Lipschitz 连续性\n$$ |f(w_{t}) - f^{*}| \\leq L \\left \\| w_{t} - w^{*} \\right \\| \\\\ \\frac{f(w_{t}) - f^{*}}{\\left \\| w_{t} - w^{*} \\right \\|} = \\left \\| \\nabla f(w_{t}) \\right \\| \\leq L $$ 于是有\n$$ \\begin{aligned} f(w_{t})-f^{*} \u0026\\leq \\frac{1}{2 \\eta} (1-\\eta \\mu ) \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2 \\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} + \\frac{\\eta}{2} L^{2} \\\\ \u0026= \\frac{1}{2 \\eta} (1-\\eta \\mu ) \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2 \\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} + \\frac{1}{2 \\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2 \\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} + \\frac{\\eta}{2} L^{2} \\\\ \u0026= - \\frac{\\mu}{2} \\left \\| w_{t} - w^{*} \\right \\|^{2} + \\frac{\\eta}{2}L^2 + \\frac{1}{2 \\eta} \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\frac{1}{2 \\eta} \\left \\| w_{t+1} - w^{*} \\right \\|^{2} \\end{aligned} $$ 正常求和放缩可能只能得到次线性的收敛速率，如果配方裂项，可以得到一个更紧的 bound。通过解方程的方法设 $t$ 项的系数为 $c\\cdot (t-1)$ （注意到最后有一个常数项需要乘 $t$ 之后才方便放缩，则有\n$$ \\left\\{\\begin{matrix} c\\cdot (t-1) = x - \\mu \\\\ c\\cdot (t+1) = x \\end{matrix}\\right. $$ 解得\n$$ \\left\\{\\begin{matrix} c = \\frac{\\mu}{2} \\\\ x = \\frac{\\mu(t+1)}{2} \\end{matrix}\\right. $$ 也就是，$\\frac{1}{\\eta} = \\frac{\\mu(t+1)}{2}$，即 $\\eta = \\frac{2}{\\mu (t+1)}$，于是有\n$$ \\begin{aligned} f(w_{t})-f^{*} \u0026\\leq \\frac{1}{8} [\\mu (t-1) \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\mu (t+1) \\left \\| w_{t+1} - w^{*} \\right \\|^{2}] + \\frac{1}{\\mu (t+1)}L^2 \\\\ t(f(w_{t})-f^{*}) \u0026\\leq \\frac{1}{8} [\\mu t(t-1) \\left \\| w_{t} - w^{*} \\right \\|^{2} - \\mu t(t+1) \\left \\| w_{t+1} - w^{*} \\right \\|^{2}] + \\frac{t}{\\mu (t+1)}L^2 \\\\ \\sum_{t=0}^{T} t(f(w_{t})-f^{*}) \u0026\\leq \\frac{1}{8} [0 - \\mu T(T+1) \\left \\| w_{T+1} - w^{*} \\right \\|^{2}] + \\frac{T}{\\mu}L^2 \\\\ \\sum_{t=0}^{T} t(\\min_{t={0,\\cdots,T}} f(w_{t})-f^{*}) \u0026\\leq \\frac{T}{\\mu}L^2 \\end{aligned} $$ 注意左边是个等差数列了，于是有\n$$ \\min_{t={0,\\cdots,T}} f(w_{t})-f^{*} \\leq \\frac{2L^{2}}{\\mu (T+1)} $$ 证毕。\n0x07 Conclusion 其实还有一个非凸非光滑，但是这个情况下，梯度下降法不一定能收敛\u0026hellip;\n我们用到梯度有界的假设，在 非光滑凸 和 非光滑强凸，我们不难看出，非光滑对收敛性是一个很不友好的 setting，而强凸往往能保证有着很好的收敛速率，光滑强凸和非光滑强凸都能够带来线性的收敛速率。\nReference 不同条件下梯度方法的收敛性分析 1——(Non)convex+(Non)smooth，https://zhuanlan.zhihu.com/p/92385493\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n《分布式机器学习——算法、理论与实践》, 刘铁岩等\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZJU-CSE Summer School 2021，Ying Sun\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n《First-order methods in optimization》，Beck, A\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n《Introductory Lectures on Convex Programming》，Nesterov\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-convergence-analysis-in-deep-learning-part-2/","summary":"\u003ch2 id=\"0x00-preface\"\u003e0x00 Preface\u003c/h2\u003e\n\u003cp\u003e本文着眼于深度学习中的收敛性分析，作为第二部分，主要介绍了深度学习中梯度下降在（强凸光滑/光滑凸/非光滑凸/光滑非凸/非凸情况下）的收敛性证明。对于先前的定义，本文将不再赘述，读者可以先阅读 \u003ca href=\"/p/blog-convergence-analysis-in-deep-learning-part-1/\"\u003e深度学习中的收敛性分析 (Part 1)\u003c/a\u003e。很多内容参考了\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e,\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e,\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e和\u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e，少量参考 \u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e。\u003c/p\u003e","title":"深度学习中的收敛性分析 (Part 2)"},{"content":"0x00 Preface 本文着眼于深度学习中的收敛性分析，作为第一部分，首先介绍了深度学习中的优化问题的基本概念以及常见不等式的推导。\n笔者并非优化科班出身，因为研究需要所以对这部分内容进行了学习，如本文内容和公式推导有误恳请指出。\n在此想总结下自己的学习到的知识，由于完整篇幅过长可能不适合阅读，因此分成了几个部分进行撰写，希望能帮到在阅读的你。\n0x01 Fundamental Concepts Optimization Problem 优化问题是指在一定的约束条件下，求解目标函数的最大值或最小值的问题。优化问题的一般形式如下：\n$$ \\begin{aligned} \\min_{x} \\quad \u0026 f(x) \\\\ \\text { s.t. } \\quad \u0026 g_{i}(x) \\leq 0, \\quad i=1,2, \\ldots, m \\\\ \u0026 h_{j}(x)=0, \\quad j=1,2, \\ldots, p \\end{aligned} $$ 而在深度学习中，$f(x)$ 一般为损失函数，并且是无约束的，所以本文也将不涉及有约束的优化问题，包括拉格朗日乘子法等方法。\nConvex Function 凸函数是指函数的定义域为凸集，且函数的任意两点连线上的函数值都小于等于这两点的函数值之和。凸函数的定义如下：\ndefination\n考虑实值函数 $f: R^d \\to R$，如果对任意自变量 $x,y\\in R^d$，都有下面不等式成立： $$ f(y) \\geq f(x)+\\nabla f(x)^{\\top}(y-x) $$ 则称函数 $f$ 是凸的。 因此由这个公式，可以推导出凸函数的另一种形式：\n$$ f(\\lambda x+(1-\\lambda) y) \\leq \\lambda f(x)+(1-\\lambda) f(y), \\forall \\lambda \\in[0,1] $$ $\\mu$-strongly convex 通常我们会遇到凸函数，但是在实际中，我们更希望函数更加凸，即函数的曲率更大，这样可以加快函数的收敛速度。因此我们引入了 $\\mu$-强凸的概念，$\\mu$-强凸的定义如下：\ndefination\n考虑实值函数 $f: R^{d}\\to R$，和模 $||\\cdot||$，如果对任意自变量 $x,y\\in R^d$，都有下面不等式成立： $$ f(y) \\geq f(x)+\\nabla f(x)^{\\top}(y-x)+\\frac{\\mu}{2}||y-x||^2, \\quad \\forall x, y \\in \\mathcal{D} $$ 则称函数 $f$ 关于模 $||\\cdot||$ 是 $\\mu$-强凸的。 可以看到，$\\mu$-强凸的定义是在凸函数的基础上，加上了一个模，这个模的系数为 $\\mu$，也就是让 $\\mu$-强凸的函数的曲率更大。\n如果令 $y = x^*$，则 $\\nabla f(y) = \\nabla f(x^*) = 0$，则有：\n$$ \\langle \\nabla f(x), x-x^{*}\\rangle \\geq \\frac{\\mu}{2}||x-x^{*}||^2 $$ 同时，也不难验证，函数 $f$ 是 $\\mu$-强凸的当且仅当 $f-\\frac{\\mu}{2}||\\cdot||^2$ 是凸的。\nLipschitz continuous $L$-Lipschitz 连续，要求函数图像的曲线上任意两点连线的斜率一致有界，就是任意的斜率都小于同一个常数，这个常数就是 Lipschitz 常数。\ndefination\n考虑实值函数 $f: R^{d}\\to R$，和模 $||\\cdot||$，如果存在常数 $L\u003e0$，对任意自变量 $x,y\\in R^d$，都有下面不等式成立： $$ \\|f(x)-f(y)\\| \\leq L||x-y|| $$ 则称函数 $f$ 关于模 $||\\cdot||$ 是 $L$-Lipschitz 连续的。 Smoothness 对于可导函数，光滑性质依赖于函数的导数，定义如下：\ndefination\n考虑实值函数 $f: R^{d}\\to R$，和模 $||\\cdot||$，如果存在常数 $L\u003e0$，对任意自变量 $x,y\\in R^d$，都有下面不等式成立： $$ f(x)-f(y) \\leq \\nabla f(y)^{\\top}(x-y)+\\frac{L}{2}||x-y||^2 \\tag{1} \\label{1} $$ 则称函数 $f$ 关于模 $||\\cdot||$ 是 $L$-光滑的。 另一种形式是：\n$$ |\\nabla f(x)-\\nabla f(y)| \\leq L||x-y|| \\tag{2} \\label{2} $$ 即，凸函数$f$是$L$-光滑的充分必要条件是其导数$\\nabla f$是$L$-Lipschitz 连续的。\n把 $\\eqref{1}$ 和 $\\eqref{2}$ 结合起来，可以看出，$L$-Lipschitz 其实是给出了函数的一个上界，而 $\\mu$-强凸则给出了函数的一个下界 1。\n首先证明一下 $\\eqref{1}$ 和 $\\eqref{2}$ 的等价性，这里笔者参考了2的证明过程。\nProof: $$ \\begin{align} f(y) \u0026= f(x) + \\int_{0}^{1} \\nabla f(x + \\tau(y - x))^{\\top}(y - x) \\mathrm{d}\\tau \\\\ \u0026= f(x) + \\int_{0}^{1} \\nabla f(x)^{\\top}(y - x) \\mathrm{d}\\tau + \\int_{0}^{1} (\\nabla f(x + \\tau(y - x)) - \\nabla f(x))^{\\top}(y - x) \\mathrm{d}\\tau \\\\ \\end{align} $$ 因此有\n$$ \\begin{align} |f(y) - f(x) - \\nabla f(x)^{\\top}(y - x)| \u0026= \\left|\\int_{0}^{1} (\\nabla f(x + \\tau(y - x)) - \\nabla f(x))^{\\top}(y - x) \\mathrm{d}\\tau\\right| \\\\ \u0026\\leq \\int_{0}^{1} \\|\\nabla f(x + \\tau(y - x)) - \\nabla f(x)\\|\\|y - x\\| \\mathrm{d}\\tau \\tag{3.1} \\label{3.1} \\\\ \u0026\\leq \\int_{0}^{1} \\tau L\\|y - x\\|^{2} \\mathrm{d}\\tau \\tag{3.2} \\label{3.2} \\\\ \u0026= \\frac{L}{2}\\|y - x\\|^{2} \\end{align} $$ 证毕。\n$\\eqref{3.1}$ 处使用了 Cauchy-Schwarz 不等式，$\\eqref{3.2}$ 处使用了 $\\eqref{1}$ 处 $L$-Lipschitz 连续的定义。也可以看出有了 $|\\nabla f(x) - \\nabla f(y)| \\leq L||x - y||$，我们可以建立起自变量和梯度的关系。\n0x02 Optimization Methods Gradient Descent 梯度下降公式为：\n$$ w_{t+1}=w_{t}-\\eta_{t} \\nabla f(w_{t}) $$ 其中，$\\eta_t$ 为学习率，$w_t$ 为参数，$f(w_t)$ 为目标函数，且 $\\eta_t \\leq \\eta_{t-1} \\leq \\cdots \\leq \\eta_1$ 为递减序列。\n有下面任何情况下都成立的等式3：\n$$ \\begin{align} \\| w_{t+1} - w^* \\|^2 \u0026= \\| w_{t} - \\eta_t \\nabla f(w_t) - w^* \\|^2 \\\\ \u0026= \\| w_{t} - w^* \\|^2 - 2\\eta_t \\langle \\nabla f(w_t), w_t - w^* \\rangle + \\eta_t^2 \\| \\nabla f(w_t) \\|^2 \\\\ \\end{align} $$ Stochastic Gradient Descent 由于梯度下降在数据量大的时候，计算复杂度也相对较大，因此有了随机梯度下降，每次只用一个 sample $(\\mathbf{x_i}, y_i)$的梯度来估计总体梯度，随机梯度下降公式为：\n$$ w_{t+1}=w_{t}-\\eta_{t} \\nabla f(w_{t}; \\xi_{t}) $$ 随机梯度经常用 $g(w_t)=\\nabla f(w_t; \\xi_t)$ 来表示。\nMini-batch Stochastic Gradient Descent Mini-batch Stochastic Gradient Descent 是随机梯度下降的一种改进，每次使用 $b$ 个样本来估计总体梯度，即，$g(w_t)=\\frac{1}{b}\\sum_{i=1}^b \\nabla f(w_t; \\xi_{t,i})$。Mini-batch Stochastic Gradient Descent 公式为：\n$$ w_{t+1}=w_{t}-\\frac{\\eta_{t}}{b} \\sum_{i=1}^{b} \\nabla f(w_{t}; \\xi_{t,i}) $$ 0x03 Common Assumptions 深度学习的相关优化方法的分析中，都会给出下述几个假设条件\nVariance Bounded Assumption 变量有界假设，设模型参数为 $w$，则有下式：\n$$ \\|w_1 - w_2\\|^2 \\leq D, \\quad \\forall w_1, w_2 $$ Gradient Bounded Assumption 梯度有界假设，设梯度为 $\\nabla f(w)$，则有下式：\n$$ ||\\nabla f(w)||^2 \\leq G^2 $$ Unbiased Estimate mini-batch SGD 的梯度估计是无偏的，即：\n$$ \\mathbb{E}_{\\xi} [g(w; \\xi)] = \\nabla f(w) $$ Gradient Bounded Variance Assumption 梯度方差有界假设，设一次 mini-batch sample 出来的梯度为 $\\nabla f(w; \\xi)$，则有下式：\n$$ \\mathrm {Var}(\\nabla f(w; \\xi)) \\leq \\sigma^2 $$ tip\n由以上两个假设（无偏估计和梯度方差有界），我们有： $$ \\mathrm{Var}(g(w; \\xi)) = \\mathbb{E}_{\\xi}[||g(w; \\xi)||^2]- ||\\mathbb{E}_{\\xi}[g(w; \\xi)]||^{2} \\leq \\frac{\\sigma^2}{b} $$ 即， $$ \\mathbb{E}_{\\xi}[||g(w; \\xi)||^2] \\leq ||\\nabla f(w)||^{2} + \\frac{\\sigma^2}{b} $$ 0x04 Common Inequalities 笔者这里只写几个在收敛性分析中非常常见的不等式（甚至有些论文中不会提到这两个不等式直接进行使用，这也是笔者最初阅读时产生困惑的重要原因）。\nCauchy-Schwarz Inequality $$ \\langle x, y\\rangle \\leq\\|x\\|\\|y\\|, \\quad \\forall x, y \\in \\mathbb{R}^{n} $$ Jensen Inequality $$ f\\left(\\sum_{i=1}^{n} \\eta_{i} x_{i}\\right) \\leq \\sum_{i=1}^{n} \\eta_{i} f\\left(x_{i}\\right), \\quad \\forall x_{i} \\in \\mathbb{R}, \\eta_{i} \\geq 0, \\sum_{i=1}^{n} \\eta_{i}=1 $$ 而常见形式则是各个 $\\eta_i$ 相等，即：\n$$ f\\left(\\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\right) \\leq \\frac{1}{n} \\sum_{i=1}^{n} f\\left(x_{i}\\right) $$ 等价于\n$$ f\\left(n \\bar{x}\\right) \\leq n f\\left(\\bar{x}\\right) $$ Triangle Inequality $$ \\|x+y\\| \\leq\\|x\\|+\\|y\\| $$ Polyak-Lojasiewicz (PL) Inequality defination\n如果一个函数是 $\\mu$-强凸的，那么对任意 $x\\in R^{d}$它的下界可以写成： $$ 2\\mu(f(x)-f(x^*)) \\leq ||\\nabla f(x)||_2^2 $$ Proof:\n这个公式的证明，是从 $\\mu$-强凸的定义出发，来最小化不等式左右两边。\n$$ f(x_1) \\geq f(x_2) + \\nabla f(x_2)^{\\top}(x_1 - x_2) + \\frac{\\mu}{2}||x_1 - x_2||^2 $$ 令左边为最小值，即设置 $x_1 = x^*$ 即可。令右边最小值，则对 $x_1$ 求导，令导数为 0。\n$$ \\begin{align} \\nabla_{x_1} [f(x_2) + \\nabla f(x_2)^{\\top}(x_1 - x_2) + \\frac{\\mu}{2}||x_1 - x_2||^2] \u0026= \\nabla f(x_2) + \\mu(x_1 - x_2) \\\\ \u0026= 0 \\\\ \\end{align} $$ 即，$x_1 = x_2 - \\frac{1}{\\mu}\\nabla f(x_2)$，代入原式：\n$$ f(x^*) \\geq f(x_2) - \\frac{1}{\\mu}||\\nabla f(x_2)||^2 + \\frac{\\mu}{2}||-\\frac{1}{\\mu}\\nabla f(x_2)||^2 $$ 移项后即可得到，证毕。\n0x05 Acknowledgement 笔者前前后后断断续续学习优化内容有快 1 年的年头了，也走了不少弯路。在学习的过程中，笔者最先从论文中的推导进行学习，然而很多定义无法看懂或理解，于是选择了专门的优化书进行学习，可能悟性较差，但是很多也是摸不着头脑或者跟自己研究方向有些偏离太多了，变有些浮躁，因此也才会断断续续。在 22 年下半年选修了 牛凌峰 老师开的 《实用最优化算法及其应用》 这门公选课，才对整个领域有所了解和认识，在今年再进行阅读领域相关内容变得轻松很多。在此感谢 牛凌峰 老师开设的课程，让我能够轻松入门和了解优化相关内容，却不用选择像 《最优化理论与方法》 这样的专业课程。\nReference 非凸优化基石：Lipschitz Condition, https://www.zhihu.com/tardis/bd/art/27554191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n《Introductory Lectures on Convex Programming》，Nesterov\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n不同条件下梯度方法的收敛性分析 1——(Non)convex+(Non)smooth，https://zhuanlan.zhihu.com/p/92385493\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-convergence-analysis-in-deep-learning-part-1/","summary":"\u003ch2 id=\"0x00-preface\"\u003e0x00 Preface\u003c/h2\u003e\n\u003cp\u003e本文着眼于深度学习中的收敛性分析，作为第一部分，首先介绍了深度学习中的优化问题的基本概念以及常见不等式的推导。\u003c/p\u003e\n\u003cp\u003e笔者并非优化科班出身，因为研究需要所以对这部分内容进行了学习，如本文内容和公式推导有误恳请指出。\u003c/p\u003e","title":"深度学习中的收敛性分析 (Part 1)"},{"content":"0x00 前言 起因是这样的，马上就要回所了，计算所的宿舍选择有三项，苏州街、青年公寓和科一招，其中科一招应该是较差的，苏州街住宿条件最好，但是 6 人间，并且通勤时间较长，青年公寓就显得比较 OK。\n而青年公寓和苏州街的名额有限，往往通过抽签的方式，而最传统的抽签方式就是抢红包，笔者所在的实验室采取的策略是赢家通吃，也就是获得微信红包的 Top K 的获得更好的住宿。\n0x01 分析 毕导在 2020 年就做过了微信抢红包的分析 BV1z7411e7qB，得到的结论是，所有人的期望都是相同的，但是越往后越容易抽到“大红包”，方差会变大。\n由此也有了获得运气王的概率：\n而在这个条件下，我们希望获得了可以不是运气王，Top K 就可以了，所以这算是毕导工作的一个 Incremental work。\n0x02 模拟 从毕导的视频中可以看到，微信红包的金额是[0.01, 剩余金额平均值的 2 倍]，于是乎，笔者用 ChatGPT 写了个程序模拟，自己修改了一下 BUG，这里我们只计算至多 20 个人的至多 Top10，模拟了 100000 次。\n但是有一些坑需要注意，首先，抢到的金额应当是保留两位小数的，同时，如果是最后一个人，那么他抢到的金额应当是剩余的金额。\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 import random import matplotlib.pyplot as plt # 模拟参数 num_trials = 100000 def simulate_red_envelope(num_users): total_amount = 100.0 red_envelope = [0.0] * num_users for i in range(num_users): remaining_envelope = num_users - i remaining_amount = total_amount - sum(red_envelope) avg_amount = remaining_amount / remaining_envelope max_amount = min(avg_amount * 2, remaining_amount) amount = ( random.uniform(0.01, max_amount) if remaining_envelope \u0026gt; 1 else remaining_amount ) amount = round(amount * 100) / 100.0 red_envelope[i] = amount return red_envelope def calculate_topk_probability(num_users, num_trials): probabilities = [] for k in range(1, min(num_users, 10)): results = [0] * num_users for _ in range(num_trials): red_envelope = simulate_red_envelope(num_users) sorted_envelope = sorted( range(num_users), key=lambda x: red_envelope[x], reverse=True ) topk = sorted_envelope[:k] # 统计获得 topk 的概率 for i in range(k): results[topk[i]] += 1 probabilities.append([result / num_trials for result in results]) return probabilities def plot_probability(probabilities): num_users = len(probabilities[0]) if len(probabilities) \u0026gt; 0 else 0 k_values = list(range(1, min(num_users, 10))) # 绘制 k 个子图 plt.figure(figsize=(4 * len(k_values) + 4, 4)) for i, k in enumerate(k_values): ax = plt.subplot(1, len(k_values), i + 1) ax.plot(range(1, num_users + 1), probabilities[i], label=\u0026#34;Probability\u0026#34;) print(probabilities[i], k) ax.set_xlabel(\u0026#34;Rank\u0026#34;) ax.set_xlim(1, num_users) # 只显示整数坐标 ax.set_xticks(range(1, num_users + 1)) ax.set_ylabel(\u0026#34;Probability\u0026#34;) ax.set_ylim(0, 1) # Title ax.set_title(\u0026#34;Probability of Top {} Amounts\u0026#34;.format(k)) # plt.xlabel(\u0026#34;Rank\u0026#34;) # plt.xlim(1, num_users) # # 只显示整数坐标 # plt.xticks(range(1, num_users + 1)) # plt.ylabel(\u0026#34;Probability\u0026#34;) # plt.ylim(0, 1) # plt.title(\u0026#34;Probability of Top K Amounts\u0026#34;) # plt.legend() plt.savefig(\u0026#34;red_envelope_probability_N{}_K{}.png\u0026#34;.format(num_users, k)) for N in range(2, 21): # 模拟抢红包并计算概率 probabilities = calculate_topk_probability(num_users=N, num_trials=num_trials) # 绘制概率图表 plot_probability(probabilities) 0x03 结果 \u0026amp; 结论 得到的结果有点多，笔者仅展示有特点的几个（ $N = 2,3,4,5,10,20$ )。\nN=2\nN=3\nN=4\nN=5\nN=10\nN=20\n首先 Top1 其实就是运气王啦，用来和毕导得到的结果比较，验证我的结果是否是正确的。\n关于运气王，也正如毕导所得到的结论，当人数越多时，后两个人获得运气王的概率越大。\n关于 Top K，当 K 增加时，这个曲线会逐渐从一个下凹的曲线变成一个上凸的曲线，直到最后会变成一个单调下降的曲线。这也就是所谓的方差变大，当 K 增加时，最后一名获得较低金额的概率会变大，因而获得 Top K 的概率会变小。同时，这个 Top K 的概率也会随着 K 的增长，概率的均值变大，毕竟你 10 个人获得 Top 10 的概率始终为 1。\n也就是说，在一定范围内，你获得 Top K 应当是越晚抽越好，但是当 K 超过一定值时，应当是越早抽越好。\n那么这个阈值应当存在于什么地方呢？接下来来探究一下这个问题。\n这里其实是有一些小 trick，首先最后一个抽红包的一定是一个非常特殊的，因为他获得的金额并不是通过采样得到的。笔者这里计算转折点时，如果考虑让整个序列单调下降，那么这个序列是极其不稳定的，甚至没有太多的规律（非递增），可能需要更多的理论计算才能支撑得到这个结论，同时也受到了很大的采样误差的影响，因为最后两个的概率差异并不大，这里笔者受概率论知识限制，将这个难题留给读者思考。但如果不考虑最后一个，只考虑前面的序列递减的话，那么这个阈值就变成了随着 N 的增加递增的了。\n绘制的 N 关于阈值 k 的图如下所示：\n曲线变化阈值 k 关于 N的曲线\n一个猜测的结论就是这个阈值 k 满足下面的公式：\n$$ k = \\left \\lfloor \\frac{N-1}{4} \\right \\rfloor $$\n至于为什么是 4，应该是与微信红包的金额分布有关，但这里笔者缺少理论分析。\n0x04 局限性 这个其实是一个大家对立的 setting，在抽红包的过程中，大家不进行信息共享，但是是在真实环境中，你可以通过询问已抽过红包的同学获得当前的人数以及剩余金额，那么这种条件下决策则会更为复杂。比如说，前面的人抽到的都是小红包，此时决策应当是什么样子；前面有人抽到了一个很大的红包，此时决策应当是什么样子。这个问题还有待探究，留给读者思考。\n这其中其实也还有很多未研究透彻的点，同时受笔者概率知识限制，难以给出更多的概率理论计算，读者若感兴趣，欢迎在评论区讨论和交流。\n","permalink":"https://blog.bj-yan.top/p/blog-the-top-k-of-wechat-red-envelopes/","summary":"\u003ch2 id=\"0x00-前言\"\u003e0x00 前言\u003c/h2\u003e\n\u003cp\u003e起因是这样的，马上就要回所了，计算所的宿舍选择有三项，苏州街、青年公寓和科一招，其中科一招应该是较差的，苏州街住宿条件最好，但是 6 人间，并且通勤时间较长，青年公寓就显得比较 OK。\u003c/p\u003e","title":"如何获得微信红包的 Top K"},{"content":"写在前面 本文主要介绍使用 Zotero 和 Notion 管理文献和笔记的方法。\n我个人是 Notion 的重度用户，平时笔记和日程管理也都是用 Notion 进行的，而且 Notion 还有教育优惠，可以一直白嫖，不用太担心存储空间的问题，同时 Notion 的图片和公式也是我比较喜欢的。\n在 @鱼鱼 的推荐下，尝试用 Zotero 管理文献，发现有 Notero 这种东西来做联动，那再好不过！\nStep by step 首先创建一个 integration，名字和 Logo 都随意。 打开 https://www.notion.so/my-integrations，点击 Create\n在 Secrets 下，你会得到一个 token，注意不要泄露该 token。 管理权限 创建文献模板库副本（点击右上角 Duplicate 即可复制），我的模板经过了修改，用的并非此模板，读者可以根据自己需要进行修改，可以添加，也可以删除中文的标签，但是不要改动英文标签。 https://slash-gem-e5d.notion.site/e629fd800387440b9e406b198b1520bd?v=f7e40abd4f2b4600a8510218efd9ed4f\n建立连接 获得 database ID，点击 copy link，保存一下 database ID。 note\nNotion 的链接格式如下： ```text https://notion.so/{workspace_name}/{database_id}?v={view_id} ``` 接下来下载 Notero 打开 Notero 的 release，下载最新的即可，注意后缀为 .xpi。\n安装插件 读者首先需要安装 Zotero，还有 Zotero Connector 然后打开后在\nTools - Add-ons - 右上角小齿轮 - Install Add-ons from file，选择下载的 .xpi 文件即可。\n配置 Notero 填入之前的信息即可\n大功告成~！右键文件夹或者单个 item 就可以看到 Sync Item to Notion 啦！ 我大概花了大半天完整了我笔记的迁移 QAQ，希望后续能方便我的工作流 hhh\nFAQ 我遇到了一个问题是，保存文献时出现了 “保存此条目时发生错误” 的字样，提示翻译器错误，于是我下载了 Zotero 最新的 translator，以及一些中文的 translator，但是问题依旧没有解决。最后发现是我之前好久下了 Zotero，版本落后太多了，更新一下就好了 hhh\n参考 https://zhuanlan.zhihu.com/p/455231476 ","permalink":"https://blog.bj-yan.top/p/blog-using-zotero-and-notion-manage-your-papers-and-notes/","summary":"\u003ch2 id=\"写在前面\"\u003e写在前面\u003c/h2\u003e\n\u003cp\u003e本文主要介绍使用 Zotero 和 Notion 管理文献和笔记的方法。\u003c/p\u003e\n\u003cp\u003e我个人是 Notion 的重度用户，平时笔记和日程管理也都是用 Notion 进行的，而且 Notion 还有教育优惠，可以一直白嫖，不用太担心存储空间的问题，同时 Notion 的图片和公式也是我比较喜欢的。\u003c/p\u003e","title":"使用 Zotero 和 Notion 管理文献和笔记"},{"content":"最近有件事还让我蛮印象深刻的，起因是有人在某群里问了一句想并行开几个 Python 程序有没有什么好办法，然而群友给的意见大多是 tmux、nohup 或者直接干脆\u0026amp;来直接实现多开几个进程，我听了听感觉都不如直接装个 mpi，一行代码 mpirun -np [num] python main.py 直接解决，专业的并行程序显然会比自己多开带来的效率提升和资源竞争解决的更好，而且数量也可以得到很好地控制，很可惜，至少他本人应该没有采用这个方案，甚至我强调过便捷性也完全没有考虑过（当然这仅是我一方之言，至少我不会知道他有没有自己去搜索过，但他却是没有回复和继续追问）。\n想想倒也正常，毕竟一个完全没听说过的程序，明明已有的方式应该足够解决了，愿意去尝试的人又有多少呢？包括我自己在内。我感觉随着时间和年龄的增长，去接受一个新概念可能很容易，但是去尝试一个新的产品或软件的动力却下降了很多。毕竟在我自己的知识域中，我确信和确定自己已有已掌握的工具栈已经足够解决了当前问题，除非有人特别指出或者要求我去使用，不然真正去使用的动力却是不够强烈。\n最近在读《人类简史》也有这种感觉，或许后人来看我们也会有同样的感觉，就是他们和“我们”都被困在了自己的认知中，这个观点似乎也是经常被提到的观点了。想要跳出，那么就得花时间去尝试和试错，同时保持着怀疑的态度去看待问题（是否会有更好的方法，更优的结果？）。\n但在如今快节奏的时代里，真的可以做到吗？人类始终在不断的“逼迫”自己和世界变快，人类从爬行变成直立行走，雌性的盆骨变窄给生育带来了很大的压力，从而让怀胎时间变短，胎儿的母亲子宫中的发育也变简单了；从智人迁徙的途中，每当他们到达一个地点，必会引来一次物种灭绝，尤其是繁殖周期长的物种，因为他们繁殖的速度赶不上人类的捕猎速度而被灭绝；农业时代也让人从不频繁的捕猎变成了每日的农耕劳作，劳作频率反而加快了；再到后来工业时代亦是如此；科技时代的到来更不用说了，原先字字斟酌的信件变成了随时可说的即时消息，工作效率提高的同时，也意味着工作频率的加快。我们真的有足够的时间去试错吗？最近读到几个知乎的问答也是如此，真正沉心从基础开始做 Research 的，往往没有什么成果，反而是，想一个做一个，赶热点的，成果满天飞，倒不是说两者有错或是怎么样，只是感觉明明两者都有独到之处，但是前者反而没有得到应得的结果。像我自己，其实每次都想从基础来补充课程、知识，但是这其实是完全不可能的，毕竟人脑的遗忘摆在那里，又不是课程或者什么频繁复习的东西，很容易看过过几天有事没看，而再想继续看的时候已经忘得差不多了，到现在也就是即看即用了。而去学习和接受一个新事物的成本，显然不如用已有可行的方法凑活着解决得了，deadline 在那里，未知在那里，为什么还要用呢？另外呢就是，新事物太多了，就拿现在 AIGC 的产品来说，爆发和喷薄的程度已经超过了我先尝试的阈值，除非是特别有特点的产品，不然最多也就是收藏夹吃灰了。\n其实我也一直质疑有信仰的人，同时也挺羡慕有信仰的人，这挺矛盾的。我觉得相信一个虚拟的假构的神，尤其是遇到困难的时候去祷告，我一直将这种行为看作是一种思想的控制，从而减少矛盾抑制反抗的一种手段。但换句话说，这种信念，反而带来了脱离苦海，不愿放弃的执念。一个没有信仰的人，可能去放弃自己生命的概率会更大吧，毕竟没有宗教规则礼教的约束，人作为一个自己独立的个体，想不开就重开。而这种信仰却孕育了科学，这话听起来挺离谱的，宗教很多反而是在发现科学修正理论的过程。发现科学的过程，往往是需要怀疑在先的，现在呢，他可能换了一个词，叫“杠精”。为什么有时候的反问会带来这样的反馈呢？（当然这里肯定是除了 yygq 之类的以外，而是单纯的质疑）一定程度上是因为另一方，无法接受、不愿接受或者是干脆不想听到自己认知以外的观点。\n似乎，除了自己主观的不愿接受以外，客观的一些因素也在约束着我们困在了自己的知识域中。而如何摆脱在我看来也有两种，一是有利益所趋，比如游戏试玩、产品试用带来的收益，或者我试用了一下我可以发一篇知乎文章/公众号/视频教程来带来流量和粉丝，亦或是对 research 而言，我看了 A，结合自己领域发一篇 A+B 的 paper\u0026hellip;二是猎奇心理，什么我不了解的都要去尝试一下，这个我个人感觉会随着年龄的增长而衰弱，所以我自己 GitHub 的 profile 里也有一句 “保持好奇:)”\n但是困在自己的知识域中，也并非全是坏事，如果我用已有的工具，创造出一种新的更便捷的工具不也是一种超脱的思维吗，虽然花费的时间成本可能较多，但条条大路通罗马，创造自己的工具链也并非坏事。\n","permalink":"https://blog.bj-yan.top/p/misc-wo-men-zong-bei-kun-zai-zi-ji-de-ren-zhi-zhong/","summary":"\u003cp\u003e最近有件事还让我蛮印象深刻的，起因是有人在某群里问了一句想并行开几个 Python 程序有没有什么好办法，然而群友给的意见大多是 tmux、nohup 或者直接干脆\u0026amp;来直接实现多开几个进程，我听了听感觉都不如直接装个 mpi，一行代码 \u003ccode\u003empirun -np [num] python main.py\u003c/code\u003e 直接解决，专业的并行程序显然会比自己多开带来的效率提升和资源竞争解决的更好，而且数量也可以得到很好地控制，很可惜，至少他本人应该没有采用这个方案，甚至我强调过便捷性也完全没有考虑过（当然这仅是我一方之言，至少我不会知道他有没有自己去搜索过，但他却是没有回复和继续追问）。\u003c/p\u003e","title":"我们总是被困在自己的认知中"},{"content":"前言 最近我正在进行实验，发现自己之前搭建的框架用起来有些不舒服，于是决定进行重构。然而新的框架还没有写好，于是我先搭建了一个基于 mpi4py 的简单联邦学习模拟器，用来跑一些简单的实验。\n代码放在了这个 GitHub 仓库：https://github.com/beiyuouo/mpi-fedsim\n代码结构 代码结构比较简单，主要分为五个部分：\nmodel.py：模型定义，包括模型的定义，以及模型的初始化 utils.py：一些工具函数，以及数据集下载划分等 server.py 和 client.py：服务器和客户端的定义，包括接收和发送模型，以及模型的更新 main_sync.py：同步联邦学习的主程序 algor：一些联邦学习的算法，包括 fedavg.py config：一些配置和实验参数。 日志模块使用的 loguru 和 tensorboard，模型创建和训练是 PyTorch，虽然比较的简单，但还是 “五脏俱全” 的，哈哈哈哈哈\n执行逻辑 逻辑主要存在于主函数中1，首先如果 rank=0 的话，就是服务器，否则就是训练进程。服务器会先初始化模型，然后等待每个进程上传样本个数和分配到的客户端 id，并记录。其他进程的话，会先根据预先规则分配到客户端 id，然后根据 id 加载对应的数据集，收到模型后开始训练，每个进程训练完之后，会把模型上传到服务器，服务器收到之后，会把模型更新到全局模型，然后把模型发送给所有进程，进程收到之后，更新模型，然后开始下一轮训练。\n因为我本身做实验是单机多卡的环境，因此在线程分配的时候可以顺便分配一下指定的 gpu，但 CNN 毕竟很小不会爆显存，所以这块我没有写，有需要的话只需要在 main_sync.py 中修改一下 client_id 与 gpu_id 的映射关系即可。\n由于每个进程包含多个 client，但接受模型参数时通讯一次，因此在数据传输上或许会快上一些。\n其实，设置多少个线程都是无所谓的，线程的限制源于对显存的限制，因此只要显存够，线程数可以设置的很大，这种方式只是在有限的显存下，使用尽量多的显存来进行加速。\n使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # install requirements pip install -r requirements.txt # dataset prepare python utils.py # check and download the dataset you need # run the simulation # for linux mpirun -np 4 python main_sync.py # 4 is the number of processes # for windows mpiexec -n 4 python main_sync.py # 4 is the number of processes # launch the tensorboard tensorboard --logdir=logs Benchmark 这里就用了一个两层卷积的 CNN 来做 MNIST 分类，没跑太多。实测的话 10 个客户端，每个客户端 6000 个样本，local epoch 为 1，round 为 50，开了 11 个进程，大概 1 分钟左右就能跑完。\n待补充\n改进 其实代码写的还是比较粗糙，还有很多部分可以改进，首先就是接收和发送模型的部分，对于同步来说，用广播的方式应该会更好，比较能提高效率，不需要 1 对 1 的 check。\nhttps://github.com/beiyuouo/mpi-fedsim/blob/main/main_sync.py\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-accelerating-federated-learning-simulation-using-mpi/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e最近我正在进行实验，发现自己之前搭建的框架用起来有些不舒服，于是决定进行重构。然而新的框架还没有写好，于是我先搭建了一个基于 mpi4py 的简单联邦学习模拟器，用来跑一些简单的实验。\u003c/p\u003e","title":"使用 MPI 加速联邦学习的模拟"},{"content":"嗨害嗨，哥们 600h Apex Legends 时长，终于单排上钻了。\n从 S14 入坑，0.6 的 KD，打的第一个赛季的排位就铂金了，之后基本就在匹配，排位基本上铂金就开摆了。这赛季因为是轮换地图，而且铂金上的比较轻松，就花了一周的时间试试能不能冲钻，花了大概 50-60 h，就上钻了 233。不过感觉这次上钻直接耗费了自己的全部热情了，后面就收收心了 - -。\n段位提升！\n纵观自己多年的游戏史，从小学的时候玩 CF、AVA 之类的 FPS 游戏；到初中大伙都玩 LOL 的时候，我还在 FPS or Minecraft，到高中的时候才开始玩 LOL；上了大学也就在 LOL 和 CSGO 中切换了；来了 UCAS 看舍友玩才开始玩的 Apex，似乎每次都会慢一步（除了 Minecraft） 233。\n但在排位来说，似乎我只上过两次钻石，一次是端游的云顶之弈，一次就是这次了。端游的云顶之弈上钻也是肝了好久，当时就记得一个 黎明 BUFF 太猛了，前中期拿到羁绊强无敌，基本稳前 4，后面稍微运营下变个阵还有机会吃鸡。然鹅召唤师峡谷从来没上过钻 233，如果极地大乱斗也有排位我觉得我能上钻（确信。\nApex 单排上钻确实不太容易，记得我铂金 I 的时候还排到过黄金带白银 - -。我枪法也就一般般，起码给个大侧身、大背身秒了或者打个大残应该没啥问题，近战能游感觉就差不多够了，KD 也一般般，从上铂金的 1.6 几，到上钻后只有 1.1 左右了。这上半赛季的排位地图是轮换的，三张图都打过，除了残月上分少，其他两张图多多少少都吃过挺多次鸡的。不同图玩的英雄也不太一样，残月进圈压力大，我基本上就玩瓦鸡或者机器人，风暴点高低差太大了，有些圈型也容易被卡，瓦鸡玩的多一点，世界尽头就基本机器人了。\n单排最希望看到的就是愿意交流、想上分的队友了，有些人落地就喜欢 roll，我觉得 roll 一队倒也无所谓，看着 3、4 队跳，还要硬 roll 的基本就是不想上分的，这时候得提醒转点，可以来劝，让转不转的，卖了就完事 - -。有些队友比较会玩的看到其他队有来劝的意思，跑的比我都快，不会被劝死总是好的。我感觉我铂金排到后半段的时候，队友的素质还是比较高的，基本都愿意开麦交流，我也会给他们报报点、报报伤害啥的，前压的时候一定要叫队友，有时候队友可能看不到倒地信息。\n另外除了交流就是运营了，我从看 PUBG 的比赛学到一些顺位、强弱侧的判断，刷圈机制的理解，再加上我玩的基本都是瓦鸡、机器人有转点能力的英雄，在进圈方面做得决策一般都是对的，有些队友不能理解强侧进圈的压力，顶着压力往里走，基本不是被卡就是被劝烂，我一般都会选择带队友走弱侧，先进圈再说，没事干就进圈踩点就行了。实在不行也是可以先不急着进圈，血魔流一波，这基本是从 Apex 比赛中学到的（这一点其实很多人不懂），毕竟前期打架的期望收益还是太低了。\n说到期望，可以根据排位分计算一下你打一队的期望风险和期望收益，基本就能判断是不是该打架了。没资源是一定要找一队爆的，为了进圈跟一队爆了或者打个 3v3 是值得的，如果被打先手，还要硬接 3v3 就得判断一下局势了。\n另外就是游戏环境了，我感觉我偶尔会遇到挂，但是概率还好，因为基本挂都没啥脑子，开着也会被劝死，对对枪能看出来是不是挂。准哥们不一定是挂，但是提前枪一定是了，什么距离打了什么样的伤害也能判断一下，有挂润就完事了。\n上钻以后，钻排一直没敢打，毕竟怪东西太多了 - -，不过等忙完手头的工作，也试试钻排，万一大师了呢 XD.\n","permalink":"https://blog.bj-yan.top/p/misc-games-rank-diamond/","summary":"\u003cp\u003e嗨害嗨，哥们 600h Apex Legends 时长，终于单排上钻了。\u003c/p\u003e\n\u003cp\u003e从 S14 入坑，0.6 的 KD，打的第一个赛季的排位就铂金了，之后基本就在匹配，排位基本上铂金就开摆了。这赛季因为是轮换地图，而且铂金上的比较轻松，就花了一周的时间试试能不能冲钻，花了大概 50-60 h，就上钻了 233。不过感觉这次上钻直接耗费了自己的全部热情了，后面就收收心了 - -。\u003c/p\u003e","title":"杂记：钻石分段"},{"content":"引言 今天(2023.03.02) OpenAI 发布了 GPT 3.5 Turbo 最新的 API，目前定价是 $0.002/1k tokens1。\nwarning\n本文信息具有时效性，请注意辨别。 使用指南 Usage 官方文档在这里2，显然会比我写的更详细 233，没意外还是建议查看官方文档。\n我写完发现，可能还真没我写的详细！233\n注册 Register warning\n这里可能需要一个自由的网络环境，同时提一嘴，如果你是使用的代理软件，那么在下面运行程序的时候需要在命令行中环境中设置 `HTTP_PROXY` 和 `HTTPS_PROXY`，否则会访问错误。Windows 下可以使用 `set` 命令，`set HTTP_PROXY=http://127.0.0.1:xxxx`，Linux 下可以使用 `export` 命令，`export HTTP_PROXY=http://127.0.0.1:xxxx`，`xxxx` 为代理软件端口号。 首先得在 OpenAI Platform 注册一个开发者账号，随后在 API Keys 页面生成一个 API Key。\n创建 APIKEY\n目前，OpenAI 提供了 $18 一个月的免费额度，用来测试应该是绰绰有余了。\n一个月的免费额度\nDemo Example 现在直接上手！在开始前需要先安装一下 openai 库，目前最新版本是 v0.27.0。\n1 pip install openai 如果你之前安装过，那么你可能需要升级一下\n1 pip install openai --upgrade 下面是一个官方提供的 Demo，将里面的 API key 文本替换成你自己的就可以直接运行了。\n1 2 3 4 5 6 7 8 9 10 11 import os import openai os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34; # replace with your API key openai.api_key = os.getenv(\u0026#34;OPENAI_API_KEY\u0026#34;) completion = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hello!\u0026#34;}] ) print(completion.choices[0].message) Say Hi to GPT 3.5 Turbo\n这样我们成功跟 GPT 3.5 Turbo 打了个招呼！\nAdvanced Usage # 1 我们先来看一个更长的栗子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import os import openai os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34; # replace with your API key openai.api_key = os.getenv(\u0026#34;OPENAI_API_KEY\u0026#34;) completion = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who won the world series in 2020?\u0026#34;}, { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;The Los Angeles Dodgers won the World Series in 2020.\u0026#34;, }, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Where was it played?\u0026#34;}, ], ) print(completion.choices[0].message) 首先需要利用 openai 库的 ChatCompletion 后调用 create 方法来创建一个 ChatCompletion 对象，这个对象中包含了我们的请求信息。\n观察一下请求的格式：\nmodel: 这个不用多说，便是模型的名称，目前现在我们在测试 gpt-3.5-turbo 这个模型，并且目前仅支持两个模型，gpt-3.5-turbo 和 gpt-3.5-turbo-0301，后面带日期的模型是不会更新的，但对今天来说，两者是相同的。 messages: 这个是一个列表，列表中的每个元素都是一个字典，字典中的 role 表示这个消息，目前支持 user，system和assistant三种，content 表示消息的内容。 system：系统消息，用来设置 ChatGPT 的行为。 user：用户消息，用来和 ChatGPT 交互。 assistant：助理消息，用来帮助你存储 ChatGPT 在此之前的回复。 来看一下完整的回复\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \u0026#34;choices\u0026#34;: [ { \u0026#34;finish_reason\u0026#34;: \u0026#34;stop\u0026#34;, \u0026#34;index\u0026#34;: 0, \u0026#34;message\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;The 2020 World Series was played at Globe Life Field in Arlington, Texas.\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34; } } ], \u0026#34;created\u0026#34;: 1677759714, \u0026#34;id\u0026#34;: \u0026#34;chatcmpl-6pcEUG6zKP0Ld33OP1dZGbg3GwWhC\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;gpt-3.5-turbo-0301\u0026#34;, \u0026#34;object\u0026#34;: \u0026#34;chat.completion\u0026#34;, \u0026#34;usage\u0026#34;: { \u0026#34;completion_tokens\u0026#34;: 19, \u0026#34;prompt_tokens\u0026#34;: 56, \u0026#34;total_tokens\u0026#34;: 75 } } 这其实就是一个多轮对话的栗子，如果是想动态的进行多轮对话，那么必须每次都将之前的回复都记录并传入才行。\n首先我们设置了 system 的消息，这个消息的内容是 You are a helpful assistant.，随后我们设置了 user 的消息，这个消息的内容是 Who won the world series in 2020?，这个消息相当于前一轮对话的信息，然后我们设置了 assistant 的消息，这个消息的内容是 The Los Angeles Dodgers won the World Series in 2020.，意思是 ChatGPT 在上一轮的回复。最后我们又设置了 user 的消息，这个消息的内容是 Where was it played?，表示本轮消息的问题，也就是当前想让 GPT 回复的问题。\n可以看到，收到的回复内容是 The 2020 World Series was played at Globe Life Field in Arlington, Texas.，我们询问时只询问了地点，而 ChatGPT 已经通过之前的回复，知道了这次的回复是关于 2020 年世界系列赛的，并且回答了这个问题。\n同时，我们还可以看到 usage 字段，这个字段表示这次请求使用了多少 token，prompt_tokens 输入的 token 数量，completion_tokens 是 ChatGPT 回复的 token 数量，total_tokens 是总共使用的 token 数量，这一波消耗了 75 个 token。\nAdvanced Usage # 2 我们再来看一个更复杂的栗子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import os import openai os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34; # replace with your API key openai.api_key = os.getenv(\u0026#34;OPENAI_API_KEY\u0026#34;) completion = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#39;I want you to act as an Chinese translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in Chinese. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level Chinese words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \u0026#34;Non terrae plus ultra\u0026#34;\u0026#39;, }, ], temperature=0.9, # 0.0 to 2.0 (default 1.0) top_p=1, # 0.0 to 1.0 (default 1.0) (not used if temperature is set) n=5, # number (default 1) How many chat completion choices to generate for each input message. stream=False, # boolean (default False) stop=None, # string or array (default None) max_tokens=10, # inf (default 4096-prompt_token) presence_penalty=2.0, # -2.0 to 2.0 (default 0) frequency_penalty=0, # -2.0 to 2.0 (default 0) # logit_bias= # user= ) print(completion) for choice in completion.choices: print(choice.message.content) 这里的 prompt 修改自 3，prompt 与我想解释的参数无关\n这里面涉及到了更多的参数：\ntemperature: 0.0 to 2.0 (默认 1.0) 温度，越高越随机，越低越有规律（或确定性）。\ntop_p: 0.0 to 1.0 (默认 1.0) 使用温度的另一种选择，也叫核采样（nucleus sampling），建议不要同时使用 temperature 和 top_p。top_p 表示模型只考虑概率最高的 top_p 的 token，比如 top_p=0.1，表示模型只考虑概率最高的 10% 的 token。\nn: number (默认 1) 生成的回复数量。\nstream: boolean (默认 False) 是否使用流式模式，如果设置为 True，将发送部分消息增量，就像在 ChatGPT 中一样。什么意思捏，就是每次单独给你蹦几个词，好让你动态的去更新文本，像你在 ChatGPT 中等待完整的回复一样。\nstop: string or array (默认 None) 用来停止生成的 token，可以是一个字符串，也可以是一个字符串列表，如果是字符串列表，那么只要其中一个 token 出现，就会停止生成，最多 4 个。\nmax_tokens: inf (默认 4096-prompt_token) 生成的最大 token 数量。\nfrequency_penalty 和 presence_penalty: -2.0 to 2.0 (默认 0) 用来惩罚重复的 token。关于此参数的更多细节在 4 中有介绍，看起来一个是处理的频率，一个是处理的存在次数（整数）。这两个参数的值越大，生成的文本越不会重复。\n公式是这样的：\n1 mu[j] -\u0026gt; mu[j] - c[j] * alpha_frequency - float(c[j] \u0026gt; 0) * alpha_presence logit_bias: dict (默认 None) 用来调整 token 的概率，可以接受 json。数值是 -100 to 100，-100 相当于直接禁用这个词，100 相当于如果相关就必须使用。\nuser: dict (默认 None) 用来设置用户的信息，具体内容可以参考 5，主要是为了防止滥用。\n而这段代码的输出是下面内容（因为中文在 json 中会有转义，所以这里我把中文替换过了）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \u0026#34;choices\u0026#34;: [ { \u0026#34;finish_reason\u0026#34;: \u0026#34;stop\u0026#34;, \u0026#34;index\u0026#34;: 0, \u0026#34;message\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;\\\u0026#34;天涯海角\\\u0026#34;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34; } }, { \u0026#34;finish_reason\u0026#34;: \u0026#34;stop\u0026#34;, \u0026#34;index\u0026#34;: 1, \u0026#34;message\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;\\n\\n无穷尽之地\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34; } }, { \u0026#34;finish_reason\u0026#34;: null, \u0026#34;index\u0026#34;: 2, \u0026#34;message\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;\\n\\n\\\u0026#34;无出其右\\\u0026#34;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34; } }, { \u0026#34;finish_reason\u0026#34;: \u0026#34;stop\u0026#34;, \u0026#34;index\u0026#34;: 3, \u0026#34;message\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;\\n\\n\\\u0026#34;无地不可至\\\u0026#34;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34; } }, { \u0026#34;finish_reason\u0026#34;: \u0026#34;length\u0026#34;, \u0026#34;index\u0026#34;: 4, \u0026#34;message\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;\\n\\n无地可往，更远\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34; } } ], \u0026#34;created\u0026#34;: 1677760749, \u0026#34;id\u0026#34;: \u0026#34;chatcmpl-6pcVBkXoD9xr2CSioR1Gz3ubEOdpg\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;gpt-3.5-turbo-0301\u0026#34;, \u0026#34;object\u0026#34;: \u0026#34;chat.completion\u0026#34;, \u0026#34;usage\u0026#34;: { \u0026#34;completion_tokens\u0026#34;: 45, \u0026#34;prompt_tokens\u0026#34;: 124, \u0026#34;total_tokens\u0026#34;: 169 } } Advanced Usage # 3 这里是关于 steam 参数的一个栗子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import os import openai os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34; openai.api_key = os.getenv(\u0026#34;OPENAI_API_KEY\u0026#34;) completion = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#39;I want you to act as an Chinese translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in Chinese. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level Chinese words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \u0026#34;Non terrae plus ultra\u0026#34;\u0026#39;, }, ], temperature=1, # 0.0 to 2.0 (default 1.0) top_p=1, # 0.0 to 1.0 (default 1.0) (not used if temperature is set) n=1, # number (default 1) How many chat completion choices to generate for each input message. stream=True, # boolean (default False) stop=None, # string or array (default None) # max_tokens=100, # inf (default 4096-prompt_token) presence_penalty=2.0, # -2.0 to 2.0 (default 0) frequency_penalty=0, # -2.0 to 2.0 (default 0) # logit_bias= # user= ) for completion_ in completion: # print(completion_) for choice in completion_.choices: print(choice.delta.content if \u0026#34;content\u0026#34; in choice.delta else \u0026#34;\u0026#34;) 开启 Stream 模式后，返回的会是流式数据，而不是返回一个包含所有数据的对象，并且这个返回的对象是可以迭代的。下面是返回的一个 item 样例，这里注意 delta 中未必会有 content，所以需要判断一下。\n也就是说，其实 ChatGPT 在输出前就已经得到了完整的结果，他一个词一个词蹦纯属在前端拖延你的时间？！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \u0026#34;choices\u0026#34;: [ { \u0026#34;delta\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;\\uff1f\u0026#34; }, \u0026#34;finish_reason\u0026#34;: null, \u0026#34;index\u0026#34;: 0 } ], \u0026#34;created\u0026#34;: 1677763452, \u0026#34;id\u0026#34;: \u0026#34;chatcmpl-6pdCm5jwsB1e3YyEDZ1MQXbpHzWvn\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;gpt-3.5-turbo-0301\u0026#34;, \u0026#34;object\u0026#34;: \u0026#34;chat.completion.chunk\u0026#34; } Advanced Usage # 4 这是一个关于 stop 参数的栗子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import os import openai os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34; openai.api_key = os.getenv(\u0026#34;OPENAI_API_KEY\u0026#34;) completion = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#39;I want you to act as an Chinese translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in Chinese. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level Chinese words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \u0026#34;Non terrae plus ultra\u0026#34;\u0026#39;, }, ], temperature=1, # 0.0 to 2.0 (default 1.0) top_p=1, # 0.0 to 1.0 (default 1.0) (not used if temperature is set) n=1, # number (default 1) How many chat completion choices to generate for each input message. stream=False, # boolean (default False) stop=\u0026#34;无\u0026#34;, # string or array (default None) # max_tokens=100, # inf (default 4096-prompt_token) presence_penalty=0, # -2.0 to 2.0 (default 0) frequency_penalty=0, # -2.0 to 2.0 (default 0) # logit_bias= # user= ) for choice in completion.choices: print(choice.message.content) 这里我们依然让他扮演一个翻译的角色，来翻译 Apex Legends 中动力小子的一句台词，用 \u0026ldquo;无\u0026rdquo; 作为停止条件，当输出的结果中遇到 \u0026ldquo;无\u0026rdquo; 时，就停止并返回结果。输出如下：\n1 您好，您所给出的第一句话“Non terrae plus ultra”是拉丁语，意为“没有比这更远的土地”，翻译成中文可写作“ 可以看到输出直接给断开了，并且会将中断的词自动转为 token，不过我暂时还没想到有啥应用场景 - -\nError 在使用的时候我有好几次触发了这个错误，并不是我请求格式的问题，大概是同时请求的人太多了，所以会出现这个错误，这个错误的信息是下面这样的：\n1 2 3 4 5 6 7 8 9 openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 7d8d2f6b67d92ff7850ef3e17d742827 in your email.) { \u0026#34;error\u0026#34;: { \u0026#34;message\u0026#34;: \u0026#34;The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 7d8d2f6b67d92ff7850ef3e17d742827 in your email.)\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;server_error\u0026#34;, \u0026#34;param\u0026#34;: null, \u0026#34;code\u0026#34;: null } } 500 {\u0026#39;error\u0026#39;: {\u0026#39;message\u0026#39;: \u0026#39;The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 7d8d2f6b67d92ff7850ef3e17d742827 in your email.)\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;server_error\u0026#39;, \u0026#39;param\u0026#39;: None, \u0026#39;code\u0026#39;: None}} {\u0026#39;Date\u0026#39;: \u0026#39;Thu, 02 Mar 2023 12:37:21 GMT\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Content-Length\u0026#39;: \u0026#39;366\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39;, \u0026#39;Openai-Model\u0026#39;: \u0026#39;gpt-3.5-turbo-0301\u0026#39;, \u0026#39;Openai-Organization\u0026#39;: \u0026#39;user-8qnumkqgd3l02hvzq5rqz0y1\u0026#39;, \u0026#39;Openai-Processing-Ms\u0026#39;: \u0026#39;750\u0026#39;, \u0026#39;Openai-Version\u0026#39;: \u0026#39;2020-10-01\u0026#39;, \u0026#39;Strict-Transport-Security\u0026#39;: \u0026#39;max-age=15724800; includeSubDomains\u0026#39;, \u0026#39;X-Request-Id\u0026#39;: \u0026#39;7d8d2f6b67d92ff7850ef3e17d742827\u0026#39;} 结语 这个定价我只能说，实在是太便宜了，感觉很多公司可能都不会去想办法复现了，直接调包，性能好，不需要担心成本、电费、算力等种种因素，价格还便宜。我感觉小公司就算有自己模型，光算力和电力成本可能比 API 高不少，毕竟这也是一个利用率的问题。\n另外我感觉这个其实也一定程度上改变了翻译市场，以腾讯云的翻译 API 为例，他的价格稍微计算一下，大概是 GPT 3.5 Turbo API 价格的 3 倍左右，但是算上输入的 token，也就 1.5 倍吧，但是附赠了其他功能，包括改写润色。\n腾讯云翻译 API 价格\n通过体验也可以发现，如果你每次都是长文本输入，其实消耗 token 还是挺快的，输入输出都会计费。同时，如果你想进行 session 级别的对话，那么你消耗的 token 也会增长很快，每次 * 2，再累计，也就是平方级别的了，所以长对话的消耗其实还是挺大的。\n不过，遗憾的是，目前 OpenAI 只支持虚拟信用卡支付，国内用户想自费使用的话，可能还得有些自己的手段。\n还记得，去年 9 月份我写了一篇博客来讲讲我对 Stable Diffusion 的想法6，现在再来看看 SD 模型，简直像是差了一个世纪\u0026hellip;lora、ControlNet\u0026hellip;如果说 SD 只是影响到了艺术、设计领域，那么 ChatGPT 的大模型潜力是真的很大，会影响很多的行业，因为输出的多样性实在是太丰富了，比如可能会有人用他来输出一段代码，驱动机器等等7\u0026hellip;应用的场景完全取决于想象力了，但目前也存在科学性的问题，如果有一个更强大的知识库来建立，输出时给予理论依据，那么这个模型的应用场景就会更加广泛，比如医疗、金融等等，对证据、决策要求更高的领域也会大放异彩。\nhttps://openai.com/blog/introducing-chatgpt-and-whisper-apis\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://platform.openai.com/docs/guides/chat\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/f/awesome-chatgpt-prompts\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://platform.openai.com/docs/api-reference/parameter-details\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://platform.openai.com/docs/guides/safety-best-practices/end-user-ids\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://blog.bj-yan.top/p/blog-will-ai-replace-the-artists/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/microsoft/PromptCraft-Robotics\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-advantage-usage-for-gpt-3-5-turbo/","summary":"\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003e今天(2023.03.02) OpenAI 发布了 GPT 3.5 Turbo 最新的 API，目前定价是 $0.002/1k tokens\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e。\u003c/p\u003e\n\n  \u003cblockquote class=\"book-hint2 warning\"\u003e\n    \u003cp class=\"hint-title warning\"\u003e\n      \u003csvg class=\"book-icon\"\u003e\n        \u003cuse href=\"/svg/hint-icons.svg#warning-notice\"\u003e\u003c/use\u003e\n      \u003c/svg\u003e\u003cspan\u003ewarning\u003c/span\u003e\u003c/p\u003e\n    \n本文信息具有时效性，请注意辨别。\n\n  \u003c/blockquote\u003e\n\n\u003ch2 id=\"使用指南-usage\"\u003e使用指南 Usage\u003c/h2\u003e\n\u003cp\u003e官方文档在这里\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e，显然会比我写的更详细 233，没意外还是建议查看官方文档。\u003c/p\u003e","title":"Advantage Usage for GPT 3.5 Turbo API"},{"content":" 没啥用小知识来了！本文主要是记录一些 GitHub 上的小技巧。\n为什么要用 GitHub？ 代码管理 白嫖 GitHub Pages 和 Actions！ 特殊的仓库 主要有两种特殊的仓库，一个是 username.github.io，另一个是 username/username（个人账户和组织账户都有这两种仓库）。\nusername.github.io 这种仓库的主要作用是用来托管个人博客的，当然也可以用来托管其他的东西，比如个人网站，个人项目的文档等等。GitHub Pages 会自动将这个仓库的内容托管到 https://username.github.io 这个地址上。\nusername/username 这种仓库一般是用来托管个人账户的信息的，比如个人简介等等。打开你的首页，这个仓库的 README.md 就是你的个人简介了。\n参考：beiyuouo - GitHub\n而组织账户会稍有区别，你需要放在 organization/.github 这个仓库的 profile/README.md 文件中。\n参考：awesome-actions-template - GitHub\nGitHub Pages 自定义域名 一般需要在你仓库的 GitHub Pages 的根目录下放一个 CNAME 文件，里面写上你的域名，然后在你的域名的 DNS 服务商那里添加一条 CNAME 记录，二级域名如 www，指向 username.github.io，另外，添加 A 记录，二级域名如 @，指向 GitHub Pages 的 IP 地址。如果你是用的博客引擎，那么你应该将 CNAME 文件放在博客引擎的 static 目录下。\n1 2 3 4 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 warning\n注意，这里的 IP 地址具有时效性，如果你发现这些 IP 地址已经失效了，可以在 [Managing a custom domain for your GitHub Pages site - GitHub Docs](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site) 这里找到最新的 IP 地址。 如果你是 IPv6 的用户，那么你还需要添加一条 AAAA 记录，二级域名如 @，指向 Managing a custom domain for your GitHub Pages site - GitHub Docs 中提供的 IPv6 地址。\nGitHub Actions github-actions[bot] 现在 GitHub Actions 更新过后，对权限的管理进行了更细化的管理，往往默认情况下 github-actions[bot] 是没有仓库的写权限的，需要手动添加。\n添加方式：Settings -\u0026gt; Actions -\u0026gt; General -\u0026gt; Workflow permissions -\u0026gt; Read and write permissions -\u0026gt; Save\nPro 账户 如果你是学生，那么你可以在 education.github.com 免费申请一个 Pro 账户，拥有 Pro Plan。可以在 Private 仓库中使用 GitHub Actions 和 GitHub Pages。\nGitHub Emoji GitHub 有自己的 Emoji，可以在 GitHub Emoji Cheat Sheet 中找到，并在 issue、commit message、Discussions 等地方使用，当然也可以在下方由 giscus 驱动的评论区中使用！\n结语 不定期更新 QAQ\n","permalink":"https://blog.bj-yan.top/p/blog-github-useless-tips/","summary":"\u003cblockquote\u003e\n\u003cp\u003e没啥用小知识来了！本文主要是记录一些 GitHub 上的小技巧。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"为什么要用-github\"\u003e为什么要用 GitHub？\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e代码管理\u003c/li\u003e\n\u003cli\u003e白嫖 GitHub Pages 和 Actions！\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"特殊的仓库\"\u003e特殊的仓库\u003c/h2\u003e\n\u003cp\u003e主要有两种特殊的仓库，一个是 \u003ccode\u003eusername.github.io\u003c/code\u003e，另一个是 \u003ccode\u003eusername/username\u003c/code\u003e（个人账户和组织账户都有这两种仓库）。\u003c/p\u003e","title":"GitHub 没啥用小技巧"},{"content":" 时隔半年，我终于又更新了这个项目！！！\n之前在写完这个项目初版的时候发过一篇相关的博客，后面断断续续也修改过几次，但大多都只更新在本地了，这次修改了一下才有了这个 v0.1.0 版本。\n其实我的很多项目也都使用了这个库（毕竟不需要重复造轮子，实在是爽），比如 fedhf，但用的时候往往被自己的 __frozen__ 这个属性搞烦，所以索性直接从你能看到的地方都删了（包括输出和比较），比较的话也是重新修改过的，忽略掉了这个参数可以直接和字典进行比较了。\n另外，也修改了一个让我头疼的就是 load 的方式，本来以为实例化一下再 load 应该也没啥问题，用了一段时间以后发现，还是麻烦了，每次得 import 一下 Config 对象再 load，感觉多此一举了，索性直接写了一个 load 函数，直接调用就行了，不用再实例化了。\n这里是从第一个版本到现在的更新：v0.0.1...v0.1.0\n其实，用久了也发现，像是 cfg.a.b.c = 1 这样的赋值对我来说并不常用，往往查询才是最常用的情景。\n后续应该还会不定时更新一下，大多数都会是我自己的需求，应该会抽时间搞一下 ez.save()，刚才忘记了顺手写上了 QAQ。另外也得处理下和 pathlib 的兼容问题，毕竟 pathlib 的 Path 对象也是我常用的。\n顺手把上面的问题也更新了一下，这下好了，这下不是 v0.1.0 了，是 v0.1.1 了。\n这里是最近一次的更新：v0.1.0...v0.1.1\n关于 pathlib 的处理应该单独做一个 utils，看看后面我自己的使用情况，使用方便的话又没有其他需求的话应该不会有太大改动了。\ninfo\n如果你有什么好的建议或者想法，欢迎在评论区留言，或者直接在 [GitHub](https://github.com/beiyuouo/ezkfg) 上提 issue。 ","permalink":"https://blog.bj-yan.top/p/blog-public-release-of-ezkfg-v011/","summary":"\u003cblockquote\u003e\n\u003cp\u003e时隔半年，我终于又更新了这个项目！！！\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e之前在写完这个项目初版的时候发过一篇相关的\u003ca href=\"/p/blog-project-ezkfg\"\u003e博客\u003c/a\u003e，后面断断续续也修改过几次，但大多都只更新在本地了，这次修改了一下才有了这个 \u003ccode\u003ev0.1.0\u003c/code\u003e 版本。\u003c/p\u003e\n\u003cp\u003e其实我的很多项目也都使用了这个库（毕竟不需要重复造轮子，实在是爽），比如 \u003ca href=\"https://github.com/beiyuouo/fedhf\"\u003e\u003ccode\u003efedhf\u003c/code\u003e\u003c/a\u003e，但用的时候往往被自己的 \u003ccode\u003e__frozen__\u003c/code\u003e 这个属性搞烦，所以索性直接从你能看到的地方都删了（包括输出和比较），比较的话也是重新修改过的，忽略掉了这个参数可以直接和字典进行比较了。\u003c/p\u003e","title":"Public Release of 🍕 Easy Configuration(ezkfg) v0.1.1"},{"content":"导言 如果你是深度学习领域的工作者，最近大火的 Diffusion model 你一定不会太陌生。在知名的机器学习模型托管网站抱抱脸（Hugging Face） 的 Treading 中，前几个无一例外的全是扩散模型。\n而这些扩散模型生成的图也是非常惊艳，无论是风景还是人物亦或是各种风格的绘画，生成的图像都有极高的素质，这里简单放几张由这些模型生成的图片。\n图源自 Midjourney Hanzo\n图源自 Midjourney LiaLöwenherz🦁💙\n当然，不少大小企业也已经开始利用扩散模型进行商业化的运作。 比如，国外的：\nMidjourney Stability AI 国内的：\n6pen.art 百度-文心 ERNIE-ViLG 也有人用 AI 给 LOL 夺冠作图1，甚至人民日报还在 B 站发了一个利用扩散模型生成的中秋节视频，说明是真的 “火” 出圈了。\n笔者最近在上自然辩证法的课，便也想来思考一下这件事，因此也就有了这篇文章。关于扩散模型的一些简史、原理、性能比较，可以去看我的另一篇文章。\n问题的提出 那么这些模型效果如此惊艳，或许有朝一日我们便不再需要艺术家来作画？\n那么艺术家的工作，会不会被这样的生成艺术所取代？5 年？10 年？20 年？100 年？未来的艺术和艺术家会是什么样的？\nAI 的飞速发展 AI 的历史可以追溯到很久，这里就简单说一下近几年 AI 领域，尤其是深度学习领域的重要进展，几个 milestone：\n2012，AlexNet 模型在 ImageNet 图像分类任务上超越人类 2016，AlphaGo，在一个人类从来不认为会战胜人类的领域-围棋，大败世界围棋冠军李世石 2018，StyleGAN，生成的人脸图像，人眼无法分辨真假 2021，OpenAI - GPT3，基于上下文的大语言生成模型，可以生成各种各样的文本，甚至是代码。据说花费了 OpenAI 460 万美元才训练出来2。 2021，DeepMind - AlphaFold 2，蛋白质结构预测模型，对未知蛋白质有很高的准确率，有助于药物研发。 2022，Stable-Diffusion（aka Dalle·E 2），高质量的文本到图像生成。 AI 已经在很多领域战胜了人类，并开始处于一个统治的地位。\n这次的 CLIP + Diffusion 模型也是打破了很多固有认知，就像当初 AlphaGo 的出现，在此之前人们认为没有什么模型能够在围棋这种复杂的领域击败人类，但是结果大家自然都知道了，AlphaGo 以 3:1 击败围棋世界冠军李世石。此后，在围棋这个领域已经没有人能战胜 AI 了。\nAlphaGo 战胜李世石之后，柯洁曾经就在直播的时候吐槽过，AI 让围棋变得非常“无聊”3。现在不是你有多厉害，而是你理解 AI 有多少，能和 AI 有多像，去学习 AI 下棋，但不可否认的是，AI 也让人类在围棋这个领域有了巨大的进步。\n这次的 Diffusion 模型也是如同 AlphaGo 带来的冲击一样，先前的很多人认为深度学习模型不会具有创造性，只是对已有知识的归纳演绎，无法创造一个未曾看过的事物（包括我）。但在这里，它不仅能够理解一些奇怪语言的描述，无论多么天马行空，都能生成出一个合理的符合描述的图像，也可以生成一些没有见过或者人类的世界观中不能发生的事情，甚至还能够生成一些非常有创造性和想象力的事物。\n图源自 Midjourney Discord 社区 BartonDH4，这张图片甚至被人拿去到 OpenSea 上作为 NFT 售卖，最终被举报下架，由此也可以看出 NFT 市场的版权还是非常难以解决的一个问题。\n什么样的工作会被取代 从古到今，机器替代人工提高生产效率的事情是必然的。\n2019 年 1 月，牛津大学未来研究所的人工智能管理中心学者 Baobao Zhang 和 Allan Dafoe 发布了 111 页的报告《Artificial Intelligence: American Attitudes and Trends》5 6，报告中提到了 AI 对一些重复性工作替代的风险。2013 年，Frey et al. 的《The future of employment: How susceptible are jobs to computerisation?》7中给出了 700 多项工作及其被替代的概率，指出在美国有 47% 的工作有很高的被替代风险，这其中就包括了电话销售、标题审查员、纺织工人等等。而这些大多是有着很多重复性的工作，比如电话销售，大多数的工作就是重复的打电话，而且几乎用着一样的话术，现在大家接到的一些骚扰电话也很多都已经不是人工来进行的了。而像艺术家、科学家这一类有创造性的工作他们认为是有较低概率被取代的。\n当然这已经是 2013 年的文章，很多观点其实也有些过时了，原先他认为超低概率被取代的职业也已经有很大概率被取代的风险了。比如最近也是非常火的领域 AI in Science。比如 2021 年 12 月登上 Nature 封面的文章《Advancing mathematics by guiding human intuition with AI》8，就是用 AI 来引导数学公式的证明。虽然这并不意味着 AI 已经能够取代数学家的工作，但是 AI 已经引导科学家或数学家的数学直觉，具有一些数学素养，帮助数学家获得证明定理的灵感，在未来用 AI 引导直觉，提升研究效率也并不是空想。\nAI 能做到什么程度？有什么问题？ 那么重新讲回艺术，现在的扩散模型，大多的逻辑主线不会变，就是能够从一个随机噪声或初始值生成出一张完整的画。\nCavemen taking a group selfie\nAn astronaut, riding a horse, in a photorealistic style\n并且除了生成之外9 10，也已经有了非常多的绘画技能，例如图像补全、图像超分根据语言描述来 P 图。\n这就是一张由 OpenAI 的 Dall·E 补全的《戴珍珠耳环的少女(The Girl with a Pearl Earring)》11。\nImagen 论文中的超分辨率12。\nDall·E-2 的图像编辑10。 AI 能做到这种程度其实是有一定风险的，毕竟 AI 能够去理解一些专有名词的含义，因为现在这些 AI 的训练数据大多是来自于网络图片，而非固定的数据集。那么这样会带来很多版权的问题（ 除了著作权，还有肖像权，角色的各种所属权利），这也在网上引起了很大的争论，也被很多画师抵制 AI 作画13 14。\nGenerated by Stable Diffusion, prompt: trump kiss putin\n很多插画师或者原画师的饭碗取决于自己独有的画风，但是一个很现实也是很容易的事就是，这些画师们用了几年设计了一个优雅完善的画风，AI 看了一眼，用了数据 train 了一下，轻轻松松几秒内生成了一堆同画风的作品，这创作效率是否有些不够平衡，画师们来抵制也就合情合理不足为奇了15。毕竟这种产品最终是要进行商业化运作的，而画师们的画通过免费的方式发布在互联网上被 AI 吸收和学习，这对画师们显然是不公平的。\nDALL·E 2 VARIATIONS of The Girl with a Pearl Earring\n但是这从来不是画师们说的算的，现有法律是没办法禁止这样的创作的。毕竟，画风的模仿，并不能算在抄袭或者侵权的范畴，至少在如今我国法律是没有保护这方面权利的条文，从这里也可以看出，“伦理的建设远不及科技的发展速度”。根据我国现有的法律案例来看，有两个方面，一个方面是对 AI 生成物的版权肯定，另一方面是“独创性”的定义。\n法律是承认并且保护 AI 创作的版权的16，肯定对 AI 模型训练和 prompt 调参的工作（炼丹）。AI 生成的画作的过程中，只是用了数据进行训练，而对成品具有原作的某些元素而已，符合“独创性”，就像人类观摩其他作品后，不可避免有风格相近的地方17。\n而在国际上的对 AI 独创性方面的认可，一个非常典型的栗子就是最近发生的。2022 年 8 月，美国科罗拉多州举办艺术博览会，《太空歌剧院》获得数字艺术类别冠军18。\n《Théâtre D\u0026rsquo;opéra Spatial》 by Jason Allen via Midjourney\nAI 必将对绘画这个领域带来巨大的颠覆，同时也不仅仅是这样，更多的还有对动漫影视行业的冲击，虽然目前无法生成非常连续的视频，但是有插值补帧的一些方法，随着研究的更加深入，由 AI 生成视频也会很快的实现，已经有 AI 进行视频编辑19 以及 AR20 的 demo。\n另外一点就是，AI 生成的图片会有其他元素的风险，比如色情、血腥暴力等元素，例如 Reddit 就已经 ban 了很多 NSFW 的帖21。\n“创作者” + 技术力 = “艺术家” 那么，AI 生成的图片现在有一些风险，但毕竟这是一个高速迭代的领域，这些风险会在后续的发展中逐渐规避。但不可否认的是，AI 生成的图像已经有很多是富有想象力和创造性的图片，那么或许我们真的不需要 “艺术家” 了？\n让我们回到最原始的问题，什么是艺术家，将其所体验的世界通过各艺术种类的独特艺术语言和表现手段转化成艺术作品的人 被称为艺术家22。而在这一过程中，艺术种类、艺术语言、表现手法随着 AI 的发展必然可以占领到艺术的各个领域，例如音乐、水彩、油画、素描等等。而最关键的是什么，是艺术家们通过所体验世界得到的 idea，而不管形式如何，形式也就都是艺术家的一种表现手法而已。\n因此，我认为 “创作者(creator)” 可能会在未来代替艺术家的地位，弱化了艺术家的艺术技能，而注重内容的表达。\n在短期内，艺术家们可以利用 AI 作为工具，快速生成初代作品进行迭代升级和修补填充23；但在中长期来看，AI 取代艺术家的工作是必然的，它能够让没有技术技能的人，通过不同的形式去表达自己的思想和观点，让更多人参与到艺术创作当中。\n现在的在 B 站就有一些 “创作者”，用 AI 生成图像和视频来进行盈利24。而同时也出现了很多衍生职业：例如进行 prompt 提示词的教学，售卖 高质量图像的 prompt 等等。也有像 openart 和 prompthero 这样的 prompt 搜索网站的出现，真正出现了 “prompt 工程师”。\n结语 虽然目前 AI 还不能完全取代 “艺术家” 的所有工作，但已经可以作为一个工具，提供给更多人进行艺术表达，能极大地提高 “创作者” 的生产力。在不久的将来，扩散模型一定能提供更多更细节的优化，比如光影、视角等等来进行更精细的场景控制，到时候每个人都可以成为 “创作者”，将自己的灵感随时展现在大众面前。\n当然与此同时，也应该注重对艺术家的版权和思想的保护，可以利用如今 NFT、Web 3.0 等技术和方法，完善相关法律法规，保护艺术家的原创作品。\n然而，在遥远的未来，如果 AI 真的发展到已经地步，有了自己的情感，和人类共存，那么他是一定能取代 “艺术家” 的所有工作的。那么人工智能的奇点也到来了25，可以看到艺术和科学是两大顶峰，AI 如果占领了艺术，那么最终全面战胜人类也不远了。而现在，无法推论这到底是福祉还是灾难。\nReference https://lol.qq.com/news/detail.shtml?type=6\u0026amp;docid=4934556576507716833\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.sohu.com/a/429205048_120828615\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://view.inews.qq.com/a/20220514A087C500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://discord.com/channels/662267976984297473/1008049088324972657/1015362328906182748\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://isps.yale.edu/sites/default/files/files/Zhang_us_public_opinion_report_jan_2019.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.zhihu.com/zvideo/1326127307812700160\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://ora.ox.ac.uk/objects/uuid:4ed9f1bd-27e9-4e30-997e-5fc8405b0491/download_file?safe_filename=future-of-employment.pdf\u0026amp;file_format=application%2Fpdf\u0026amp;type_of_work=journal+article\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.nature.com/articles/s41586-021-04086-x.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/midjourney/comments/wvoscd/cavemen_taking_a_group_selfie/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://openai.com/dall-e-2/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://openai.com/blog/dall-e-introducing-outpainting/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://arxiv.org/abs/2205.11487\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.gamersky.com/ent/202208/1513964.shtml\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.zhihu.com/question/550660606\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.zhihu.com/question/550997249/answer/2656595328\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://zhuanlan.zhihu.com/p/565071999\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.zhihu.com/question/552231525/answer/2665147875\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://baike.baidu.com/item/%E5%A4%AA%E7%A9%BA%E6%AD%8C%E5%89%A7%E9%99%A2/61959625?fr=aladdin\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://twitter.com/runwayml/status/1568220303808991232\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://twitter.com/StrangeNative/status/1569700294673702912\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://zhuanlan.zhihu.com/p/560232893\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://baike.baidu.com/item/%E8%89%BA%E6%9C%AF%E5%AE%B6/23418?fr=aladdin\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://zhuanlan.zhihu.com/p/378444440\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://space.bilibili.com/335884771\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.zhihu.com/question/284243786/answer/1131987569\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-will-ai-replace-the-artists/","summary":"\u003ch2 id=\"导言\"\u003e导言\u003c/h2\u003e\n\u003cp\u003e如果你是深度学习领域的工作者，最近大火的 Diffusion model 你一定不会太陌生。在知名的机器学习模型托管网站\u003ca href=\"https://huggingface.co/\"\u003e抱抱脸（Hugging Face）\u003c/a\u003e 的 Treading 中，前几个无一例外的全是扩散模型。\u003c/p\u003e","title":"AI 会取代艺术家的工作吗？"},{"content":" 本来是想在 另一篇文章 中写这个部分的，结果发现这一小部分内容较多，且与文字主题相关性低了一些，于是单独提出来形成了这篇文章，也是调研了一下扩散模型。笔者这里就只简单介绍一下 Diffusion 模型的原理和历史，还有自己对相关知识的整合。\n什么是扩散模型？ 这里还请让我偷个懒，有关内容可以去看李沐老师的 视频，还有苏神有关扩散模型的 博客，有非常深入的数学原理，笔者这里就不再赘述了。\n但说白了还是从一个随机噪声或初始值生成出一张完整的画，训练的时候确是反正进行的，从一幅幅完整的话不断变成随机噪声，DDMP 的第一个 D 就是 Denosing。\n扩散模型的简史 被玩出花的生成模型简史\n军备简史\n2020.6.19 Ho et al. 发表了 DDPM 的论文 《Diffusion Probabilistic Models for Image Generation》1。 2022.4.13 OpenAI 表了 Dall·E 2 的论文 《Hierarchical Text-Conditional Image Generation with CLIP Latents》2。 2022.4.13 Stable Diffusion 发表了论文《High-Resolution Image Synthesis with Latent Diffusion Models》3。 2022.5.30 Google Brain 发布 Imagen4 5。 2022.6.19 Google \u0026amp; NVIDIA 在 CVPR 2022 发布 Tutorial 《Denoising Diffusion-based Generative Modeling: Foundations and Applications》6。 2022.8.30 OpenAI 发了一篇 Blog，讲的是用 Dall·E 进行的图像补全7。 各种模型试玩 由于笔者并不太了解图像生成领域的 metrics，同时由于各种模型能够提供的参数不同，在生成性能和迭代次数上存在差异。笔者只进行了一些模型的试玩，并不能作为严格的性能指标，只能说明他们提供的 demo 效果如何。\n所有的图像使用同一 Prompt 进行生成: On a black starry background, Pikachu stands with a star stick in his right hand\n各模型试玩地址如下，这些也都是免费的版本：\nDall·E-mini: https://huggingface.co/spaces/dalle-mini/dalle-mini ERNIE-ViLG: https://huggingface.co/spaces/PaddlePaddle/ERNIE-ViLG Stable Diffusion: https://huggingface.co/spaces/stabilityai/stable-diffusion Dream Studio: https://beta.dreamstudio.ai/dream 生成效果：\n由 Dall·E-mini 生成\n由 ERNIE-ViLG 生成\n由 Stable Diffusion 生成\n由 Stability AI 生成\n可以看出百度在 Hugging face 的 ERNIE-ViLG 生成的图像素质还是非常高的，但是没有任何调参的方式，因为百度的“无限探索”除了在 Hugging face 上并不对外开放。Stability AI 也就是 Stable Diffusion 所创建的公司，生成的图像也是较为清晰，但我调的参数可能不太好，质量看起来会略差与 ERNIE-ViLG。Dall·E-mini 和 Dream Studio 的生成效果就不太理想，但大概语义还是理解了的。\n大概在参数上的影响除了前置训练的 CLIP 模型之外，还有迭代次数和图像大小，其他的参数笔者不了解，也不太会调节 - -。\nReference https://arxiv.org/abs/2006.11239\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://arxiv.org/abs/2204.06125\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://arxiv.org/abs/2112.10752\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://imagen.research.google/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://arxiv.org/abs/2205.11487\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://cvpr2022-tutorial-diffusion-models.github.io/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://openai.com/blog/dall-e-introducing-outpainting/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-diffusion-model-trial/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本来是想在 \u003ca href=\"/p/blog-will-ai-replace-the-artists/\"\u003e另一篇文章\u003c/a\u003e 中写这个部分的，结果发现这一小部分内容较多，且与文字主题相关性低了一些，于是单独提出来形成了这篇文章，也是调研了一下扩散模型。笔者这里就只简单介绍一下 Diffusion 模型的原理和历史，还有自己对相关知识的整合。\u003c/p\u003e","title":"扩散模型试玩"},{"content":"导言 先说结论，我对国内开源环境持悲观态度。\n起因来自于 V2EX 上的一帖：【国内开源环境】- V2EX，顺便也谈谈自己对开源项目的一些看法。\n什么是开源？ 开源最早起源于free software movement，注意这里的 free 并非是免费的意思，而是指的自由。自由软件是指对软件的运行、研究、修改、共享（分发副本无论修改与否）。\n开源是指一种计算机程序，其中源代码可供公众使用或对其原始设计进行修改。代码是根据软件许可条款发布的。根据许可条款，其他人可以下载、修改并将其版本（分叉）发布回社区1。\n好哒，现在我们来看一下国内 “最大” 的 “开源社区” Gitee 是什么情况的呢？\n【如何看待 5 月 18 日 Gitee 仓库开源须审核，已开源部分仓库暂时关闭，审核通过后再次公开？ - 知乎】(https://www.zhihu.com/question/533388365)\n当然，我很早就注册过 Gitee，不使用不代表不好用，毕竟速度这块肯定是在国内要比 GitHub 强一些，但大多是带有我个人一些偏见。主要是项目太少，质量太差，当时的功能一般，当时并没有像 GitHub Pages 这样的功能，同时永远永远会慢 GitHub 很多步。另外一点便是对仓库的各种限制，比如容量一类。我也知道 Gitee 官方也回答了这个问题，说此举出于无奈2。既然已经从政策上禁止了，那么所谓的 “自由软件” 也便不复存在了。\n国内的开源项目 首先，先说说我对 开源项目 这一个词的理解吧，我认为开源项目最首先要具备的就是 README 和 LICENSE，这两个文件是开源项目的基础，直接说明了你这个开源项目的使用和分发方法。同时，Awesome-List 并不应该在开源项目的范畴之内，顶多算是开源文档一类的。而一个完整的开源项目，应该具有比较完整的 workflow 和规范的贡献方式，比如 CONTRIBUTION.md 告诉社区如何贡献和提交代码，以及基础的代码规范。最重要的是有一个完整的文档和版本号，更好的便是 milestone 或者 roadmap，这样才能让社区更好的参与进来，看到开源项目未来的发展规划。当然还要有人去解决 issues 和 Discussion 中的问题。同时，还应该有一些基础的测试用例，以及 CI/CD 的配置，这样才能保证项目的质量。\n不得不说，国内其实有非常多的优秀开源项目，有许多开源项目都被 Apache 基金会孵化。\n但你观察就会发现，这些优秀的开源项目，几乎都是由企业承担，而个人开发者的优秀项目则是少而又少。\n国内的开源是企业的，没有个人开发者，有开源软件，没有开源社区。\n个人开发者环境 在国内，一个开源项目的归宿有两个，一个是被企业收购（我认为是一个开源项目最好的归宿），另一个是自己成立公司。\n我们先说第一点，当然这其实大多数企业是不愿意做的，毕竟这也是一笔不小的开支，而给企业带来的收益呢？既然是开源，本来就能用，那么\u0026hellip;收购和不收购的区别也就是让 roadmap 更符合自己项目的需求吧。而且，在现在国内的疫情环境下，裁员毕业这种事已经成了常态了，原先分给企业内部开源部门的经费和人员大多也都分到了业务部门，所以收购更是不太可能了。\n那第一点走不通，第二点呢？这个的难度不言而喻，怎么实现盈利呢？那自然是 2B，和企业 API 对接。那其实和第一点就差不多了，至于如何 2B，难度就是在这里了。那么你要做的就是拿开源项目做自己的名片，展示给公司，才能进行合作。但是你作为一个开源项目，想维护好这张名片，想要他长久的生存，那必然还得 2C。\n只做 2C 有没有其他的道路呢？有，Sponsor。哦，对了，忘了说，中国大陆开发者，在 GitHub 是没法注册 Sponsor 的，也就是，你只能通过放置自己的二维码来实现 Sponsor，而很多 GitHub Sponsor 的功能，你也就无法使用了。Gitee 好像是没有 Sponsor 制度的，这块国内的审查明显要过段时间，毕竟涉及到税收问题。但 Sponsor 还是能收到一些帮助的，但其实无论是国内还是国外，结果也都差不多，真正的方式应该是用 Pro 来提现差异化，引导用户付费。我觉得这条路是个人开发者自己搞能走的最好的路。\n不知道有多少人还记得之前 colors.js 的事件3，作者选择了 MIT Licence，希望能够得到 Sponsor 盈利或工作机会，然而结果就是企业都在用，却没有任何人买单，最终作者设置加入恶意代码，导致非常多的项目运行出现问题，甚至作者 GitHub 账号一度被封禁。从一个开发者的角度我很容易去理解作者的心情，但又很不理解的是他最初选择的开源协议，既然想一次盈利，要么做出差异化，要么干脆不要使用这么无限制的开源协议。hcaptcha-challenger 这个项目亦是如此，不少人使用它去爬 Discord Token 或是做一些灰产内容实现盈利，但是没有人愿意开源，没有人愿意遵守项目给出的 GPLv3.0 Licence。\n国内在开源协议这块也在慢慢健全法律法规，有很多由开源协议引发的法律纠纷得到判决，说明开源协议在我国法律中的有效性，希望类似由开源协议引发的事件在国内开源项目能够得到很好的解决。\n使用者环境 一个很简单的问题，如果不是高强度的 GitHub 使用者（比如我这个刷 GitHub 比刷空间+朋友圈都多的人\u0026hellip;），上 GitHub 大多是具有目的性的，比如上来找找实验代码，找找有没有现成的项目拿来用用。能顺利使用的小白就不多（毕竟需要科学上网才能下载 release 和显示出来 README 中的图片），更别说让他去遵守开源协议了，可能连开源协议都不知道是啥。当然有些小白不仅啥也不知道，代码不愿看，甚至直接就来开 issue 提问，Wiki 也不看，态度还贼差，好像开源开发者就是为他服务的一样。\n从 hcaptcha-challenger 这个项目就能看出来，我和另一个开发者还经常收到邮件“问候”，项目无关的问题我为什么要去帮你解决？就比如我收到过让我帮他去解决某网站的验证码的邮件。先不说这个项目的初衷是对抗 hCaptcha，而不是针对他的“某网站”，代码都是开源的，自己甚至不愿意去了解项目结构，纯结果性的寻找答案。反正这种人我是不会帮助的，我不太相信就他这种发邮件“问候”都要用翻译软件回复的人后续能带来什么收益，本身就是灰色产业，我也不愿意染指。\n当然，这块并不是国内环境，稍微有点跑题，但是国内很多用户也是一样的态度，比如 YOLOv7 的骂战，看得我都觉得丢人（现在好像找不到了，直接当时有人用中文说以辱骂的语气声讨原先的 YOLOv7 项目的命名问题）。所以我也奉劝各位在 GitHub 交流尽量使用英文，不要使用网页翻译插件以后回复，提问请友好交流多用敬语，尊重开发者的工作，开发者不是你的员工！！！\n结语 以上大概就是这篇文章的全部内容了，非常希望国内能够建设好开源社区，最起码是不要影响产品和项目迭代，不要让审核成为开发者的累赘而限制了开源项目的发展。另外就是希望能够建立良好的 Sponsor 制度，让优秀的个人开发者能够做自己感兴趣的事情，维护好自己的开源社区还能养活自己。\nReference https://en.wikipedia.org/wiki/Open_source\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.zhihu.com/question/533388365/answer/2491172345\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://zhuanlan.zhihu.com/p/456125379\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-talk-about-the-open-source-environment-in-china/","summary":"\u003ch2 id=\"导言\"\u003e导言\u003c/h2\u003e\n\u003cp\u003e先说结论，我对国内开源环境持悲观态度。\u003c/p\u003e\n\u003cp\u003e起因来自于 V2EX 上的一帖：\u003ca href=\"https://www.v2ex.com/t/879105\"\u003e【国内开源环境】- V2EX\u003c/a\u003e，顺便也谈谈自己对开源项目的一些看法。\u003c/p\u003e\n\u003ch2 id=\"什么是开源\"\u003e什么是开源？\u003c/h2\u003e\n\u003cp\u003e开源最早起源于\u003ca href=\"https://en.wikipedia.org/wiki/Free_software_movement\"\u003efree software movement\u003c/a\u003e，注意这里的 \u003ccode\u003efree\u003c/code\u003e 并非是免费的意思，而是指的自由。自由软件是指对软件的运行、研究、修改、共享（分发副本无论修改与否）。\u003c/p\u003e","title":"浅谈国内开源社区环境"},{"content":"前言 刚结束完选课，马上就要开始上课了，但这个日程一直是个痛点，刚换手机也还不太熟练日程的管理，索性多了解了一下这里大概汇总了几种解决方案。\n首先会根据日程的导出设置分成了从课程网站导出和其他方式导出，导入这里主要讲解了 iOS 的方法，按理说 Android 只会更简单。最后说几个一体化的解决方案，也就是课表 APP。\n内容会有一些不完整，欢迎补充~\nics 文件格式 ics 文件是一个纯文本的文件，有一些 core object，比如 DTSTAMP，DTSTART，DTEND 等等 1\n课表日程导出 从课程网站导出 首先进入 SEP - 选课系统\n在选择课程 - 选择课程 - 已选择课程中点击加入课程网站\n随后进入 SEP - 课程网站中\n此时点击左侧的日程即可找到所有课表的信息\n根据需要点击发布（私有）即可得到 ics 文件和订阅链接\n或者发布（公开），可以直接下载 ics 文件，支持 iCal 导出\n（如果你对我的课表感兴趣，可以试试这几个链接 233）\n油猴插件（推荐） 另一个方法是通过一个学长编写的油猴插件实现导出 ics 文件，因为从课程网站导出的时候，课程是分开的，也就是每一小节课程成为了一个日程，而不是一个整体，可能会造成多次的提醒。\n学长编写的脚本见 2，首先你需要在 Chrome 或者 Edge（任何你使用的浏览器）中安装油猴插件（Tampermonkey），然后点击这个链接 3 即可开始下载安装。\n安装完成后，在选课系统 - 查看个人课表中，也就是 4 这个链接，即可看到插件，对于 2022 级雁栖湖研究生，按照如下方式配置即可。\nWakeup 日程导出 Wakeup 这个 APP 是支持导出 ics 文件的，但是不幸的是 iOS 版本导出是付费的，但是 Android 版本是免费的，那么你只需要有一个安卓设备即可。 ics 导入 iOS 日历可见下文。\n课表导入（iOS） 这里主要是介绍 iOS 设备，因为很多 Android 设备早已支持了 ics 文件的导入，但是 iOS，并没有很好的开放该功能，甚至可以说非常 yaxi\n这里大概学习到了两种方案\n通过邮件导入 如果你已经使用过 iOS 的邮件功能，设置过邮箱，那么你可以直接通过 QQ 或者 微信 发送给手机一份 ics 文件，然后利用邮件转发给自己，这时候你点击一下附件的 ics 文件即可导入日历。\n通过 AirDrop 导入 这个就比较简单了，直接把 ics 文件 AirDrop（隔空投送） 到另一个设备即可导入。\n这里有个比较蛋疼的地方就是没法指定导入到的日历是哪个一个，因为一下子导入很多应该默认是第一个，当修改的时候只能修改当前选择的一个，而不是全部修改。\n通过 Outlook 导入 如果你是 Windows 电脑，那么双击 ics 文件，或者打开 outlook 再导入即可，你需要在 iOS 设备下载 outlook 并登录账号，将 outlook 日历添加到日历中\n通过订阅导入 目前没有发现很好的 ics 转换订阅链接的工具，或许过段时间有空我可以写一个？\n更好的方案请见下一个标题。\n那就向课程网站妥协了，把课程网站的订阅链接复制一下，在下面的添加订阅日历即可导入（我不确定这个订阅日历的更新情况是怎么样的，不知道链接失效了日程会不会失效，如果不失效的话或许这个转换只需一次性即可？）\n当然你也可以通过 iOS 内置的分享功能，也就是点日历旁边的 i 图标可以分享一个从 iCloud 导入的日历给其他人订阅。\n通过 GitHub 存储自己的日程（推荐） 通过实验发现，由于课表本身是纯本文的形式，可以很方便放在 GitHub 上进行迭代更新。同时 GitHub Pages 可以让你的日程公开到互联网中，这样当你的课程有什么变动时，只需要更改 GitHub 上的 ics 文件即可。\n方法很简单首先新建一个 GitHub 仓库，将仓库 pull 下来后，新建一个 docs 文件夹，将 ics 文件放在文件夹中，提交修改。我们假设这里的 ics 文件是 course-schedule.ics。\n然后按照下图点上 5 下即可 pub 你的日程。地址就是在方框中的地址后面加上你的文件名，例如这里应是 webcal://www.bj-yan.top/webcal/course-schedule.ics。（注意更改协议头为 webcal）\n最后在你的设备上导入订阅日历即可。\n课表导入（Windows） 双击打开 ics 文件，登录账户即可导入 outlook\n其他课表导入方案 当然，这种方式就比较简单了，wakeup，超级课程表什么的 APP 都可以解决。但是我好像没找到对应的教务接口？不知道是不是我姿势错误，不过一共也没几个课，不如就直接手动一下呗。\n最推荐的还是国科大在线了，反正慕课什么的也都得下，APP 里面就有课表，但是更新会有些延迟，估计得 1 天才能更新。\n我个人还是比较喜欢系统日历，毕竟方便提醒，都是系统内置的功能管理起来也会方便许多。\nReference https://en.wikipedia.org/wiki/ICalendar\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/LinHeLurking/Sep_Calendar\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/LinHeLurking/Sep_Calendar/raw/main/sel.user.js\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://jwxk.ucas.ac.cn/course/personSchedule\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-ucas-course-schedule/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e刚结束完选课，马上就要开始上课了，但这个日程一直是个痛点，刚换手机也还不太熟练日程的管理，索性多了解了一下这里大概汇总了几种解决方案。\u003c/p\u003e\n\u003cp\u003e首先会根据日程的导出设置分成了从课程网站导出和其他方式导出，导入这里主要讲解了 iOS 的方法，按理说 Android 只会更简单。最后说几个一体化的解决方案，也就是课表 APP。\u003c/p\u003e","title":"UCAS 课程表日程解决方案"},{"content":"免责声明 仅做技术分享，使用者应知道技术风险并有能力对自己行为负责，本教程及作者不承担任何责任。\n准备 首先补充一下准备阶段，现在大部分电脑都是支持 IPv6 的，如果你打开 https://ipv6-test.com/ 发现并没有 IPv6，那可能是因为你没有开启。可以尝试 follow 下面的步骤来打开：\n打开 “网络和 Internet” 设置 点击 “更改适配器选项” 选择对应的网络，打开 “属性” 4. 勾选 “IPv6 地址”，并确定保存\n利用代理 参考1，这种方式的原理就是，利用 IPv6 的代理，将我们的流量通过 IPv6 转发给代理，然后让代理通过 IPv4/IPv6 访问对应的服务，最后返回。\n在 Vultr 选择的服务器配置可以参考下图\n其中这里的是 5 刀一个月，1 TB 流量，可以弹性使用，可以销毁重建，如果几个人合租的话可以 +1 刀升级到 2 TB 一个月，好像内存也会多一点。购买完在 Products 里面就可以看到 root 和 密码了。\n不过需要注意的是 Vultr 的很多 IP 因为被滥用已经封禁了，所以可能访问不了 Google Scholar，但是可以销毁重建，不需要额外的费用。毕竟大概 5 min 就能搭建好。\n如果可以建议尝试 hysteria 协议，也挺方便，但还没仔细研究过。\n另外，代理规则可以选择绕过局域网，这样国内流量也会被代理，但是如果不手动配置 QQ 的代理，可能无法收发消息。\nDNS64 这种方式是免费的，但是使用有局限性，但是足矣绕过刷 B 站的流量，免掉流量大头也是可以的 hhh\n主要是通过 DNS64 实现绕过，参考 2 3，简单的来说，其实是将 IPv4 的服务器地址解析成了 IPv6 的地址。当请求 AAAA 记录时，仅返回 A 记录和一个指向 IPv4 到 IPv6 地址转换的服务器地址，从而能够通过 IPv6 的地址去访问 IPv4 服务的内容。\n方法也很简单，其实就是把上面勾选 IPv6 的地方双击打开，手动配置 DNS 为一个 DNS64 地址即可。\n这里我 copy 一下 2 中的地址\n提供商 国家/城市 DNS64 服务 NAT64 前缀 Kasper Dupont 芬兰/赫尔辛基 2a01:4f9:c010:3f02::1 2a01:4f9:c010:3f02:64::/96 Trex 芬兰/坦佩雷 2001:67c:2b0::4 2001:67c:2b0:db32::/96 Trex 芬兰/坦佩雷 2001:67c:2b0::6 2001:67c:2b0:db32:0:1::/96 level66.network 德国/美因河畔法兰克福 2a09:11c0:f1:bbf0::70 2a09:11c0:f1:be00::/96 Kasper Dupont 德国/纽伦堡 2a01:4f8:c2c:123f::1 2a01:4f8:c2c:123f:64::/96 go6Labs 斯洛文尼亚 2001:67c:27e4:15::6411 2001:67c:27e4:642::/96 go6Labs 斯洛文尼亚 2001:67c:27e4::64 2001:67c:27e4:64::/96 go6Labs 斯洛文尼亚 2001:67c:27e4:15::64 2001:67c:27e4:1064::/96 go6Labs 斯洛文尼亚 2001:67c:27e4::60 2001:67c:27e4:11::/96 Kasper Dupont 荷兰/阿姆斯特丹 2a00:1098:2b::1 2a00:1098:2b::/96 Tuxis 荷兰/中部 2a03:7900:2:0:31:3:104:161 2a03:7900:6446::/96 Kasper Dupont 英国/伦敦 2a00:1098:2c::1 2a00:1098:2c::/96 多终端设备 有时候那个校园网不是很稳定，手机等智能设备可能会出现断连的问题，可以尝试开启电脑的移动热点，将网络共享给手机，然后在手机上添加代理 IP，可以实现网络共享。\n这里我遇到了一个问题就是手机可能连接不上热点，在属性里面开启共享即可。\niOS 设置 WiFi 代理的方式是点击右边的 i，然后划到最下面有一个代理，设置代理为 电脑ip:端口。\n电脑 ip 查询方式是 ipconfig /all 找到移动热点对应的地址即可，如果是 macOS 或者其他 Linux 系统可以使用 ip addr 或者 ifconfig 进行查询。\n如果你使用的是 v2RayN，先在 设置-参数设置 中勾选 允许来自局域网的连接，那么你的端口应该是 10809，如果你的 v2RayN 版本比较新，可能会换成 10811。\n如果你使用的是 SSR，在 右键小飞机-选项设置-本地代理 中打开 允许来自局域网的连接，你应该可以看到端口为 1080 填上即可。\n附一个 CDN： https://dl.capoo.xyz/\nReference https://github.com/Tremb1e/ucas_ipv6_bypass\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://blog.cloudwai.com/archives/201/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.whosneo.com/free-by-ipv6/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.bj-yan.top/p/blog-ucas-ipv6-bypass/","summary":"\u003ch2 id=\"免责声明\"\u003e免责声明\u003c/h2\u003e\n\u003cp\u003e仅做技术分享，使用者应知道技术风险并有能力对自己行为负责，本教程及作者不承担任何责任。\u003c/p\u003e\n\u003ch2 id=\"准备\"\u003e准备\u003c/h2\u003e\n\u003cp\u003e首先补充一下准备阶段，现在大部分电脑都是支持 IPv6 的，如果你打开 \u003ca href=\"https://ipv6-test.com/\"\u003ehttps://ipv6-test.com/\u003c/a\u003e 发现并没有 IPv6，那可能是因为你没有开启。可以尝试 follow 下面的步骤来打开：\u003c/p\u003e","title":"UCAS 利用 IPv6 绕过校园网流量计费"},{"content":"I 不知道为什么最近好像不太喜欢打空格和逗号你看我这么长的一句话都不加个标点符号的感觉都要喘不上气来了\nII 找到工作的朋友都要去工作了，感觉毕业以后还联系的朋友挺难得的，以前在学校天天约游戏的生活变成了一天就等着晚上玩会游戏聊天的生活\n我自己也对未来的路有些迷茫了，不太清楚自己究竟想要什么的，究其原因还是时间和年龄的问题\nIII 有时候感觉自己整天都在忙，回头看却不知道自己一天天的做了些啥，奇奇怪怪\n比如我觉得我从推免完到现在好像什么都没提升，但回想一下好像自己学了不少东西，学哪里去了？\n学习上感觉有点误区，可能是我高数线代什么的基础太差（？），可是有时翻起来看一看好像也能看懂，但就是忘了。可见建立自己的知识库有多重要，但是这个笔记的整理也是要花费大量时间，有些搞不懂。是我记忆退化了？\nIV 关于家庭我不知如何评论，只是感觉我妈过于“热情”，也因此拌过很多次嘴\n感觉一个良好的状态是，需要时出现，支持，关系融洽，互不打扰\nV 有时候我发现，我非常愿意重头写一个项目，这可能就是我小项目多的原因吧\n但到了自己该做的项目，比如我那个 FedHF 框架的更新，却总是一直拖着\n应该有两方面的原因吧，除了没有反馈，主观上不太想去做，比如那个配置文件的问题，其实我很清楚这到底有多简单\u0026hellip;要么就是复杂的，那就更不想改了，甚至只想重写一个\n难道我天生就喜欢被 push？\nVI 关于分别，真的是只有在最后真的要分开的时候能够感受到令人难忘的痛苦，比如那最清醒的凌晨四点半\nVII 和一些业界的朋友交流多了，就会感觉到意义和能否产生社会价值的问题，思维会发生些许的转变\nVIII 有时候真的很想扩大自己的影响力，以后我也会这样做，不仅局限于 GitHub，还应包括其他自媒体平台\n","permalink":"https://blog.bj-yan.top/p/misc-20220706/","summary":"\u003ch2 id=\"i\"\u003eI\u003c/h2\u003e\n\u003cp\u003e不知道为什么最近好像不太喜欢打空格和逗号你看我这么长的一句话都不加个标点符号的感觉都要喘不上气来了\u003c/p\u003e\n\u003ch2 id=\"ii\"\u003eII\u003c/h2\u003e\n\u003cp\u003e找到工作的朋友都要去工作了，感觉毕业以后还联系的朋友挺难得的，以前在学校天天约游戏的生活变成了一天就等着晚上玩会游戏聊天的生活\u003c/p\u003e","title":"近日有感 - 20220706"},{"content":"序 仿佛，四年的时光是那么的快，我曾写过一篇文章来分享我的大学学业生活，当然大学也不光只有学业，还有我难以忘记的大学生活。\n整个大学生活想要回忆起来，总是复杂的，很难记起每一件事，甚至是重要的事也会写出很多内容，而且往往非常零碎。也就是和好友坐在一起，大家共同回忆，可能才算是欢愉的事情。在这，我就随便说说吧，想到哪里说哪里。\n壹 转眼间，四年的大学生活也将落幕，我也将离开已经在这生活了四年的小岛。说实话，还是有些惆怅的。\n还记得没来海南的时候，总是会为海南的气候感到焦虑，我一直是一个怕热的人，可能是高中时期在闷热的教室里受够了吧。当初在高中教室，区区几十平的空间，紧紧地坐着五十多号人，有时候即使到夏天了也不让开空调，尤其是邻近高考，以“怕学生感冒”更是不会开了。每当这个时候，尤其是晚自习，从教室走出来，呼吸一下新鲜空气，感受室外更低的温度，总是让我感觉很爽，因此我也就一直觉得，我是个“怕热”的人。\n而当我真正来到了这里，除去军训时期的暴晒，我发现，我更喜欢这里的气候。你可能想象不到，其实在祖国最南部的省份，在热带地区的省份，有时，同样是晴天，海南的温度会比大陆低上不少。而在雨后——通常海南中午下午会下雨——海南的温度，真的会让人觉得舒适。而当你遵循了当地人的作息规律——早上吃早茶，中午睡大觉，下午下午茶，晚点吃宵夜——海南真的是非常适宜生存的地方。\n当然，不可否认的是，海南是真的“晒”，但做好遮阳，其实就还好。男生，也是要打伞的啊，不然，有时候晒上几分钟，脖颈就会有些炙热的疼痛了。\n还有一点，不得不提的，就是海南的天空，我是真的喜欢。海南的云是非常低的，在一些小山区，比如五指山，你都可以看到云海，而你就在云层上面，要知道五指山的主峰也就海拔 1867 米而已。还有黄昏的彩色祥云，或是火焰般的，或是雨后的双彩虹……\n想想，以后来海南养老，似乎也是一个不错的事（XD）。\n贰 这，是关于毕业。\n和高中初中的匆匆毕业不同——大家经历了一场“关乎人生的考试”，然后各奔东西，我甚至在返校拿材料的时候都是找人代取的，没什么感觉——而大学的毕业，却是在享受这个过程。\n从大三下学期开始，课程开始减少；到了大四上学期，大家开始各忙各的事情，实习的实习，考研的考研，推免的推免；到大四下学期，除了毕设，大家就在为各自的去向而努力了。当毕设结束，交上最后的文件袋，大学的生活也快要到尽头了，最后一次踏出校门，也就真正毕业了。\n享受毕业有意思的一点就是，你现在做的事情，做一次少一次，或者说，每一次都是特定的“最后一次”。最后一次去某个食堂、某个窗口，最后一次走学校的这条路，最后一次上世纪大桥，最后一次……最后一次和不同群体的朋友吃饭、聊天，看看大家四年的变化。\n叁 这，是关于海大。\n之前的文章我也提过我对海大看法的变化，究其原因，我认为，我们这届赶上了好时机，海大的巨大变化和发展也在我们这届学生眼中进行。\n海大的宿舍空调，其实是从我们这届才开始有的，这得感谢前面学长学姐还有老师的努力。据说，先前没有空调时候的学长学姐除了一天冲凉好几次，晚上甚至会去思源学堂睡觉。幸好我没有体验到（x\n另外，还有骆清铭校长的到来，一个 院士 的头衔和资源，实在是能给海大带来的太多的改观了。拿我们学院举例，新来了另一个院士和许多教授，师资力量得到了不少的补强，生物医学工程学院更为尤甚。另外，似乎海大的行政效率也变得极高了。\n海大的排名也是在极快地上升，海大毋庸置疑地在向好的方向快速发展，欢迎报考！！（我的毕业证含金量还需要学弟学妹的努力！）\n末 朋友，话不用说太多，希望我们下次见面的时候，再讲给我听！\n","permalink":"https://blog.bj-yan.top/p/misc-good-bye-hainan/","summary":"\u003ch2 id=\"序\"\u003e序\u003c/h2\u003e\n\u003cp\u003e仿佛，四年的时光是那么的快，我曾写过一篇\u003ca href=\"/p/journey-man-man-qiu-xue-lu\"\u003e文章\u003c/a\u003e来分享我的大学学业生活，当然大学也不光只有学业，还有我难以忘记的大学生活。\u003c/p\u003e\n\u003cp\u003e整个大学生活想要回忆起来，总是复杂的，很难记起每一件事，甚至是重要的事也会写出很多内容，而且往往非常零碎。也就是和好友坐在一起，大家共同回忆，可能才算是欢愉的事情。在这，我就随便说说吧，想到哪里说哪里。\u003c/p\u003e","title":"别了，我的小岛"},{"content":"之前做项目的时候就曾用过这个技术，说白了也很简单，就是测试的时候做数据增强，来增强整个系统的鲁棒性。\n另外，最近 hCAPTCHA 的更新是关于给图片加噪声的，说白了也是一种比较简单的模型攻击嘛，但是令我觉得好奇的是，他这个场景做模型攻击究竟会有什么用呢？\n我觉得大部分的模型攻击和防御会在现实场景中进行，毕竟你很难去针对性的改动现实场景的事物，但是这个场景\u0026hellip;我是没搞懂\n我只需要对你加的噪声加一个扰动，或者做一个简单的降噪，也就一行 img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)，再不济，我加个滤波 img = cv2.GaussianBlur(img, (5, 5), 0) 似乎你这个加噪的操作也没什么用了啊。\n毕竟，我的模型输入不由你来决定，你对我的模型攻击是近乎 0 作用的。\n所以，这个加噪的操作我是真没看懂，这是为了抵御人类？让人类看眼花，机器人能做出正确判断，那么通过的就一定是机器人，未通过的一定是人类这样吗？这未免也太搞笑了 8，haha\n@hCAPTCHA 快多整点活儿，最近都觉得没意思了，快整点有难度的去！\n我觉得验证码最终形态一定不是图形验证码，而是一些环境监测，让你感受不到验证码的存在，这可能才是未来验证码的真正形态吧，就和分布式系统的最终目的一样。\n","permalink":"https://blog.bj-yan.top/p/blog-hcaptcha-test-time-augmentation-and-model-attack-defense/","summary":"\u003cp\u003e之前做项目的时候就曾用过这个技术，说白了也很简单，就是测试的时候做数据增强，来增强整个系统的鲁棒性。\u003c/p\u003e\n\u003cp\u003e另外，最近 hCAPTCHA 的更新是关于给图片加噪声的，说白了也是一种比较简单的模型攻击嘛，但是令我觉得好奇的是，他这个场景做模型攻击究竟会有什么用呢？\u003c/p\u003e","title":"Test Time Augmentation and Model Attack \u0026 Defense"},{"content":"🍕 Easy Configuration(ezkfg) GitHub: 🍕 Easy Configuration(ezkfg)\n想说一下最近写的一个小项目，ezkfg。\n为什么叫这个名呢？主要是因为(kfg,config,cfg,ezcfg,ezconfig)之类的名字都已经被占用了\n其次就是，配置文件这个东西总是需求很多的，我在很多项目中都会用到，但是一直没找到一个自己喜欢的。与其不如自己造一个轮子，取其精华去其糟粕。\n快来 pip install ezkfg !\n几种配置方式 argparse:\n最常见的就是argparse的方式，支持很多数据类型，支持设置默认值，支持设置可选值，支持设置可选值的描述之类的。这个也是很多项目和我经常使用的方式，尤其是深度学习的项目，因为可以非常方便的指定实验参数。但是参数很难保留，要么就要手写文件读入，要么就在文件中传入 list 先进行参数解析。\nconfig.py:\n这是除此上面的方式以外我最喜欢也是常用的形式了吧，因为毕竟是原生的 Python 内容，可以定义多个 config class，然后通过 from config import config_xxx as config 的方式导入，也挺方便配置，同时支持所有 Python 的数据类型。但是毕竟是要修改掉 import 包的信息，每次修改可能都要至少修改两个文件内的参数，容易让人困惑。\nYAML:\nYAML 也算是非常灵活的配置文件类型，结构简单，而且可以通过文件读入，非常方便复现，支持列表之类的数据结构。是我很喜欢的配置文件类型。\njson:\n同上，但是文件结构较为复杂，内容多了以后不太直观。\nini:\n方便选取多种配置，有内置的库支持，但是是没有数据类型的，读入全是字符串，需要手动进行数据转换，同时是 k-v 形式的，因此是没有层级的。\n同时，我又看到了 addict 这个项目，嵌套的.进行属性调用真的还挺方便，但是没有文件的 IO。\n明确需求 所以，还是要明确一下需求。\n文件其实只是个载体，我个人认为文件格式的差异其实都是可以接受的，可能根据应用场景略有差别。比如我想要把我的实验内容发给其他人，或者在其他机器上快速复现，那么我用配置文件的方式显然要比其他方式优秀的多。\n另外，在实验中调用的形式也是非常重要的，首先是参数的预加载。预加载时，有些参数我们是需要提供默认值的，而有些参数可能明显用不到，那么最好不要占用存储，简化配置文件的重量。\n其次，数据类型是必要的，毕竟在实验中的参数可能是有多种形式的。\n然后就是在 Code 中的参数引用，如果对于特定的参数，我希望能够利用嵌套的.实现层级的调用，而不是使用一长串的[]来调用。但是在另外一些场景，比如两种方法，但是两种方法有着相同的超参数，那么我用.来进行调用，很不利于代码的复用，更好的方式是config['method'].alpha的形式看起来会更加直观，这样我们就可以动态的修改method以使用对应的alpha值。因此，这两种形式都是必要的。\n最后就是文件 IO 了，这个是必须支持的。如果你要在其他地方部署，显然直接用配置文件，不改动原项目任何代码的效果会好很多。\n实现 首当其冲的就是属性调用和索引调用，这两个是必须实现的，而且都要支持嵌套。通过[]的索引调用其实没什么好说的，本来就是内置功能，因为在 Python 中每一个类其实都有一个__dict__变量，存储了类中的所有属性。所有的配置参数也是借用了这个字典来进行存储的。\n首先是初始化，现在是支持几种初始化方式的，有字典，列表和Config类。dict就需要递归去解决，Config就用内置的update方法即可。\n其中__getitem__和__setitem__方法就是用__getattr__和__setattr__调用即可，实现起来也不会有歧义，__setitem__方法实现需要先进行分割，然后递归进行即可。但是__getattr__的实现也是很简单，直接递归查询即可。但是__setattr__就不是了，因为在 set 前会先调用 get 方法来进行查询，如果不存在\n最后解决文件 IO 的问题。\n在handler方面，为喜欢自定义的用户提供了注册器，可以直接将自定义的handler注册到包中，或者将自定义的文件格式使用已有的handler进行解析。\nRoadmap 目前项目进行到了v0.0.1版本，经过了 3 个pre-release版本。\n但是肉眼可见的存在一些问题。\n首先是目前还不支持数据类型的转换，默认的参数可能只能通过预先入读默认文件或者预先转换argparse的形式来实现，在py和ini文件的接口还有待优化，目前都是 hard code 了名称。\nTakeaways 说实话，这个项目确实让我了解了很多配置文件的格式及各自特点，已经 Python 的内置函数和内置函数的调用顺序，比如__setattr__会先调用 __getattr__ 但是并不是在 __setattr__ 中实现的，而是在更高一级实现，所以需要做好处理。\n除此之外，更为重要的是方便我自己的项目配置文件书写吧，毕竟很可能没什么人会用 hhh\n","permalink":"https://blog.bj-yan.top/p/blog-project-ezkfg/","summary":"\u003ch2 id=\"-easy-configurationezkfghttpsgithubcombeiyuouoezkfg\"\u003e\u003ca href=\"https://github.com/beiyuouo/ezkfg\"\u003e🍕 Easy Configuration(ezkfg)\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eGitHub: \u003ca href=\"https://github.com/beiyuouo/ezkfg\"\u003e🍕 Easy Configuration(ezkfg)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e想说一下最近写的一个小项目，ezkfg。\u003c/p\u003e\n\u003cp\u003e为什么叫这个名呢？\u003cdel\u003e主要是因为(kfg,config,cfg,ezcfg,ezconfig)之类的名字都已经被占用了\u003c/del\u003e\u003c/p\u003e","title":"Project: 🍕 Easy Configuration(ezkfg)"},{"content":"前言 起因是最近事项确实有点多，又需要了一款日程管理软件了，但目前我好像找到了一个比较适合我的软件。\n难以满足的日程管理软件 回想起高中时候，我还是保留了从小学就开始的用本子记作业的习惯，（虽然到后面摆烂了）但是确实“好记性不如烂笔头”，记下来总归想找的时候可以找到，所记的内容除了作业也无他。\n从刚上大学起，自己有了手机，自然不会再用小本本记作业了，那么手机上就需要一款日程管理软件了。期初，我就直接用了手机的备忘录，简单记一下什么课程的作业 DDL 是什么时候，倒也还好，只不过有时候因为没有提醒就算记了也会忘了去查看，也不会及时清除。\n在加入了一些组织之后，日程管理就变得复杂了起来，那天该发推文，什么时候有个活动，什么时候有个会，每周的例会\u0026hellip;乱七八糟的。这时候备忘录就有些捉襟见肘了，这时候我在衡量了很多软件以后，选择了滴答清单，他有 TODOLIST，有周视图、月视图，但是循环日程却是付费功能\u0026hellip;用了一段时间，很快我就又放弃了，懒得一次次添加周例会等循环任务，误点了一个任务需要半天才能从回收站里找回来\u0026hellip;等等问题。\n在后面离开了青协，到了一些项目组，手机的需求反而变少了，因为大部分时间是在室内工作，这时候如果能在电脑上操作就最好了。试用了一些软件以后，干脆直接使用了 Windows 自带的便签，就相当于一个 TODOLIST 了，只不过没有时间设置，没有各种视图，没有循环日程，只是一个便签而已。除了懒得清理以外，也更新的不再频繁了。\n后面又使用了 Google Calendar，说实话我用着还挺舒服的，和其他很多应用是有联动的，比如邮箱里收到一个会议邀请可以直接添加到 Google Calendar 中，在 Slack 中也可以根据 Google Calendar 自动调整状态，同时它还支持外链，拖拽调整等等。但是因为众所周知的原因，在离开室内环境后并不方便使用。\n我的需求是什么？ 从小本本、备忘录、日历到 TODOLIST、滴答清单、Windows 便签、番茄时间、wolai、Google Calendar，似乎每一款日程管理软件都很难让我满意。我就在想，这是我的问题吗？我的需求到底是什么，我对日程的管理到底有哪些必须的条件？\n在此之前，其实我对我的需求一直都很混乱，我对此没有一个非常清晰的认识，都认为是软件自身的不足，而不是这个软件没有满足我的哪些需求。\n在此我总结了 2 个部分，其实需求很简单，但是并不是一个日程管理软件，而是一个待办清单以及日历视图的日程管理。\n因为很多任务其实是没有具体截止时间的，将它放到日历视图的日程管理很容易让人感到困惑，或者说，只放在日历中会让人感觉不够清晰明了，不如备忘录直接一个列表。而日程管理，则是一些会议（必须在某日某时做的事情，而不是某日某时截止）。\n待办清单：首先需要明确的是，有些没有明确的截止日期，只是自己想做而已，有些是在某日截止，有些是在某日某时截止。并且他们需要一个列表来进行清晰的展示，方便规划后几日的日程。 日程管理：对这个，我喜欢是有一个周视图、一个月视图，年视图对我来说好像也不算是必须项，但是年度总结的时候或许很好用，如果能有像 GitHub 一样的热力图似乎也不错？这个就需要的就是具体会议的时间，最好支持框选，这样可以快速进行时间块的划分和规划。同时，循环任务必然是必须项。 其他：最最重要的一项，也是我对很多手机日程管理不满意的原因，就是多端同步，这个真的很重要，你总不希望一个内容搞两遍。最好是能支持多端的推送。另外一点，就是任务或日程的快速建立，你总不希望一个内容这个改改哪里改改，建俩任务画上个 2 分钟。 加分项：最好能够让我直接放在 Blog 上，或者其他什么网页上，一个是方便同事或者其他人了解我的日程安排，方便安排和我的工作，一个是我能够线上修改，这样其实利用网页，也就完成了多端同步，你甚至不需要下载任何客户端。 飞书 —— 临时的替代品 首先，我不会去乱用一些小软件，这些软件一个是对你数据不负责，一个是可能难以长期存在，所以你的一些记录可能就随着他的倒闭永远地消失掉了。\n飞书是字节跳动公司的产品，大厂出品自然数据上有所保证，用他的另一个原因是其他项目要用到飞书，也就顺手研究了一下，出其意料地，我发现他确实能够基本满足了我的需求，有任务、有日历，同时多端都会有同步，多种视图，能框选\u0026hellip;\n另外一个令人惊喜的功能就是他居然有辅助时区，这个功能在我不参与任何跨国项目时觉得是绝对的鸡肋，当真正有需求时发现，真 tm 好用，总比你每次百度时间要强。\n唯一的缺憾或许就是没法把任务和日历联动，把一些任务自动添加到日历中。\n开源软件 与 Serverless 有这个需求，又本身就 GitHub 高强度网上冲浪，自然想到用些开源项目算了，不得不说，确实有做的不错的，而且有网页视图，颜值也不错，只是不提供部署说明，又要购买你 Pro 功能，唉\u0026hellip;也确实，维护这数据自然会有一些花费，而日程管理软件加广告，你猜猜还会不会有人再用。\nServerless 本身无法使用数据库存储，而且任何更新都会建立出一个新环境，完全没有办法存储数据。但是 Serverless 来部署的方案确实可行，你可以不需要购买服务器，只需要一个 OSS 或者数据库即可，大概一年也就几十块？你能够买到一个很大的存储量，对于日程这种小数据而言，轻轻松松。\n但是唯一的难题就是鉴权，我没想好 Serverless 的鉴权要如何做，总不能直接 GET 方法 + Token 吧，虽然确实可行，但看起来有点蠢\u0026hellip;\n或许以后我前端码力深厚可以自己搞一个开源项目来维护？\n","permalink":"https://blog.bj-yan.top/p/blog-some-thoughts-on-schedule-management-software/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e起因是最近事项确实有点多，又需要了一款日程管理软件了，但目前我好像找到了一个比较适合我的软件。\u003c/p\u003e\n\u003ch2 id=\"难以满足的日程管理软件\"\u003e难以满足的日程管理软件\u003c/h2\u003e\n\u003cp\u003e回想起高中时候，我还是保留了从小学就开始的用本子记作业的习惯，（虽然到后面摆烂了）但是确实“好记性不如烂笔头”，记下来总归想找的时候可以找到，所记的内容除了作业也无他。\u003c/p\u003e","title":"Some Thoughts on Schedule Management Software"},{"content":"写在前面 之前已经发过了两个作品了：Taichi Voxel Challenge 2022\n最近忙完手头的几个比较急的工作，又手痒想整点活了 hhh，本来有几个想法，但最后就先做了 PVZ 这个。\nPVZ 目前还是 WIP，后面应该会再完善一下下，后面如果时间充裕还可以再来整几个，不过快要答辩了 555。\n作品思路 PVZ 这个目前只做了一个最简单的豌豆射手，但其实在做的过程中也遇到很多的问题。首先，还是来分析一下豌豆射手的结构吧！\n豌豆射手大概就是有以下几个结构：主体炮筒，眼睛，枝干，后面的芽和下方的叶片。\n主体炮筒：这个炮筒其实我们还可以再来拆解一下，其实可以把他看成一个圆柱，但圆柱的壁变成曲线，看起来很简单对不对？我们直接用 SDF 表示几何体然后直接构建就好啦！但是我不会 SDF（x），其实这样也是有点问题的，因为炮口应该会比较靠下，所以我们干脆拆成一个球体 + 几个圆即可。\n眼睛：这个没啥难度，直接从球体上扣掉一个矩形，安放一个黑矩形当眼睛，白矩形点高光即可。\n1 2 3 4 def create_eye(p): create_box(p, 2, 8, 3, 0, vec3(0)) create_box(p, 2, 1, 3, 1, vec3(0)) create_box(p + vec3(0, 1, 0), 1, 1, 1, 1, vec3(1)) 枝干：这个枝干的曲线可是难倒我了，我并不会 bezier curve，所以我决定化繁为简，直接用正弦函数 hhh，由某条龙的作品启发 233，定义好振幅，我只选取了 [0, PI] 的参数范围。\n1 2 3 4 5 @ti.func def create_sine_curve(p, A, l, mat, color, dir1=vec3(0, 1, 0), dir2=vec3(0, 0, 1), tk=1): for x, tx in ti.ndrange((0, l + 1), (0, tk)): y = ti.cast(A * ti.sin(1.0 * x / l * ti.math.pi), ti.int32) scene.set_voxel(p + y * dir2 + tx * dir2 + x * dir1, mat, color) 后面的芽：直接也当成曲线画上即可\n下面的叶子：原版的豌豆射手下方有 3 片叶子，2 大 1 小，但是太复杂了，这里也是简单表示，画 4 个方向的 4 片叶子。但是叶子这个又是个不规则的图形，好像又不好表示\u0026hellip;我灵机一动，画了一片叶子()，这很像是两个对角的半圆拼接起来的重合区域，那就有了，指定一个起点和方向，然后左上右下或者右上左下作为圆心，判断重叠区域即可。但这样画出来是平的，没有关系，我们在 z 坐标还是用老方法，直接两个关于 x 和 y 的正弦函数相加就好了！（机智如我）\n1 2 3 4 5 6 7 8 9 10 11 def create_leaf(p, r, dir, mat, color): if dir == 1: for x, y in ti.ndrange((0, r + 1), (0, r + 1)): if x * x + y * y \u0026lt;= r * r and (r - x) * (r - x) + (r - y) * (r - y) \u0026lt;= r * r: z = ti.cast(ti.floor(1 * ti.sin(ti.math.pi * x / r) + ti.sin(ti.math.pi * y / r)), ti.int32) scene.set_voxel(p + vec3(x, z, y), mat, color) elif dir == 2: for x, y in ti.ndrange((0, r + 1), (0, r + 1)): if x * x + (r - y) * (r - y) \u0026lt;= r * r and (r - x) * (r - x) + y * y \u0026lt;= r * r: z = ti.cast(ti.floor(1 * ti.sin(ti.math.pi * x / r) + ti.sin(ti.math.pi * y / r)), ti.int32) scene.set_voxel(p + vec3(x, z, y), mat, color) 到此，豌豆射手就结束了。构建豌豆射手的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @ti.func def create_peashooter(p): create_ball(p + vec3(0, 18, 0), 8, 1, col_g) for i in range(6): create_circle(p + vec3(0, 16, 6 + i), 3.0, 1, col_g, 1) create_circle(p + vec3(0, 16, 12), 4.0, 1, col_g, 1);create_circle(p + vec3(0, 16, 13), 4.0, 1, col_g, 1) for i in range(8): create_circle(p + vec3(0, 16, 6 + i), ti.max(2.0, ti.min(i - 3.0, 3.0)), 0, col_g, 1) for x, y in ti.ndrange((-1, 1 + 1), (-1, 1 + 1)): create_sine_curve(p + vec3(x, 5, y), 2, 5, 1, col_gd, vec3(0, 1, 0), vec3(0, 0, -1)) create_sine_curve(p + vec3(x, 0, y), 2, 5, 1, col_gd, vec3(0, 1, 0), vec3(0, 0, 1)) create_sine_curve(p + vec3(0, 24, -5), 2, 5, 1, col_gd, vec3(0, 0, -1), vec3(0, 1, 0), 2) create_eye(p + vec3(-3, 20, 5));create_eye(p + vec3(2, 20, 5)) create_leaf(p + vec3(0, 0, -6), 6, 1, 1, col_gdd);create_leaf(p + vec3(-7, 0, 1), 6, 1, 1, col_gdd) create_leaf(p + vec3(-6, 0, -6), 6, 2, 1, col_gdd);create_leaf(p + vec3(1, 0, 1), 6, 2, 1, col_gdd) 剩下的就是草坪了。因为有格子数的限制，没法实现原版的 6 * 9 的设置，也没法画全四周的篱笆了，所以就直接画了 6 *6 的场景。画完以后差点味儿，再给草坪周围加上噪声即可。\n1 2 3 4 5 6 7 8 9 @ti.func def create_grass(p, sx, sy, sz, mat, color): create_box(p, sx, sy, sz, mat, color) for x, y in ti.ndrange((0, sx + 1), (0, sy + 1)): if ti.random() \u0026gt; 0.8: scene.set_voxel(p + vec3(0, 0, (ti.random() - 0.5) * 4), mat, color) scene.set_voxel(p + vec3(x, 0, (ti.random() - 0.5) * 4), mat, color) scene.set_voxel(p + vec3((ti.random() - 0.5) * 4, 0, y), mat, color) scene.set_voxel(p + vec3((ti.random() - 0.5) * 4, 0, 0), mat, color) 最后做完了行数有点超，稍微压一下行就 99 行啦！\n最后 有几个遇到的问题至今未解决 - -，首先一个就是我不知道怎么在 @ti.func 中交换 vec3 的维度，比如 vec3(x, y, z) 变成 vec3(z, y, x)，不然在构建圆形的地方还能少几行，因为我是想着多方向的圆形，最后还是选择了最暴力的 if 算法。\n还有一个小细节就是在圆形和球体的地方，为了让圆形更圆一下，就得给放宽一下边界条件，比如 x * x + y * y \u0026lt;= r * r + eps。在球体的时候，有时候会是上面多一个点，这时候缩一下边界条件会比较好。\n","permalink":"https://blog.bj-yan.top/p/blog-taichi-voxel-challenge-2022-pvz/","summary":"\u003ch2 id=\"写在前面\"\u003e写在前面\u003c/h2\u003e\n\u003cp\u003e之前已经发过了两个作品了：\u003ca href=\"/p/blog-taichi-voxel-challenge-2022\"\u003e\u003ccode\u003eTaichi Voxel Challenge 2022\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e最近忙完手头的几个比较急的工作，又手痒想整点活了 hhh，本来有几个想法，但最后就先做了 PVZ 这个。\u003c/p\u003e\n\u003cp\u003ePVZ 目前还是 WIP，后面应该会再完善一下下，后面如果时间充裕还可以再来整几个，不过快要答辩了 555。\u003c/p\u003e","title":"Taichi Voxel Challenge 2022 - PVZ"},{"content":"上次说的 seaplane，这不就来了吗！\n说实话，也确实没什么好说的，除了这里面的贵物变多了\u0026hellip;因为有太多四不像的了，我觉得对于模型理解自己生成的是 seaplane 的话应该是下面有个横线就算是。反正我是觉得这个任务的生成模型做的不是太好，生成的效果太差了。\n所有 train 和 test 的代码都在这个 commit 中了，泛化测试没做太多，不过效果应该还行，毕竟数据太多了。\n一开始数据有很多分错的样本，这给模型带来了很大的困扰，导致准确率较高的时候其实已经 overfit 了。炼丹这东西，确实需要点经验来找到一个合适的点进行，或许后续我可以写一个 Grid Search ？\n这次做的方法其实和上次差不多，主要是这次直接做了个 model factory，这样可以有了新任务，采集一部分是数据，进行标注，训练，测试，部署，直接一套全做下来就 ok 了\n其实对于 hcaptcha challenger 中的 solution 结构都是差不多的，几乎没什么改变，除了上次 elephant 那个需要加一个 filter。后续估计会继续建设我的 model factory 了，基本不会改变太多，除非到模型泛化能力跟不上的地步，比如过于精细的图片？才会考虑去改 model 的结构。\n就这样吧，下面是 @QIN2DIM 做的 demo\n","permalink":"https://blog.bj-yan.top/p/blog-hcaptcha-seaplane/","summary":"\u003cp\u003e\u003ca href=\"/p/blog-hcaptcha-elephant-drawn-with-leaves\"\u003e上次说的\u003c/a\u003e seaplane，这不就来了吗！\u003c/p\u003e\n\u003cp\u003e说实话，也确实没什么好说的，除了这里面的\u003ca href=\"https://github.com/QIN2DIM/hcaptcha-challenger/issues/38\"\u003e贵物\u003c/a\u003e变多了\u0026hellip;因为有太多四不像的了，我觉得对于模型理解自己生成的是 seaplane 的话应该是下面有个横线就算是。反正我是觉得这个任务的生成模型做的不是太好，生成的效果太差了。\u003c/p\u003e","title":"\"Please click each image containing a seaplane\""},{"content":"Voxel Pac-man 早在很久以前就看到了 Taichi 的 voxel-challenge 这个仓库。因为我自己也是非常喜欢像素风的，对于体素自然也是有所关注，比如我之前还做过个 deep learning for pixel art 的调研。随便翻了翻仓库就看到了一个 issue #1，然后我非常兴奋的自己动手做了一下，代码在这里，大概长下面这个样子：\n当然，后面才知道这原来是内测（x，我说我怎么找半天公众号也没找到这 challenge 的推送\n正式赛开始以后，我就修改了一下内容，稍微调节了一下参数改进了一下，加了几个 feed ball，投稿了这个 Voxel Pac-man，看起来有那么一点高级感了（x：\n代码大概 96 行，整体的思路也比较简单，首先看看 pac-man 都有什么成分，一个是整个的球面，但是嘴巴张开了，是不完整的，嘴巴上下应该算另一个面，然后就是眼睛，最后 feed ball。\n我在代码前面加了很多个性化的参数，可以很方便的来调节，n 是整个空间的大小，因为当时也没自己看代码，所以并不知道空间限制是(-64,64)，就自己随便填了，剩下的就是半径和中心点，面朝的方向之类的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @ti.kernel def initialize_voxels(): n = 60 r = 20 p_center = vec3(0, n // 2, -n // 2) vec_face_to = vec3(0, 0, 1) vec_z = vec3(0, 1, 0) vec_normal = normalize(cross(vec_face_to, vec_z)) mouse_angle = pi / 5 mouse_angle_min = mouse_angle mouse_angle_max = mouse_angle mouse_angle_cos_min = ti.cos(mouse_angle_min) - 0.05 mouse_angle_cos_max = ti.cos(mouse_angle_max) + 0.05 skin_thickness = 0.5 eye_angle = mouse_angle + pi / 18 he_angle = pi / 5 vec_eye_left = rotate(rotate(vec_face_to, vec_normal, -eye_angle), vec_z, he_angle).normalized() vec_eye_right = rotate(rotate(vec_face_to, vec_normal, -eye_angle), vec_z, -he_angle).normalized() p_eye_left = p_center + vec_eye_left * r p_eye_right = p_center + vec_eye_right * r eye_size = 4 核心代码是这样的，首先先画皮肤表面，枚举 x,y,z ，如果在皮肤内部，那么需要进行判断，如果在嘴巴的部分，就不能画出来，不在嘴巴的部分可以直接填上皮肤的颜色。如何判断是嘴巴的部分呢？直接从侧面来看，如果这个点在中间面上的投影和pac-man 面对的方向的夹角在我们嘴张开的夹角范围内，那么就是了。最后再来画，嘴巴内部的情况，也是同理，首先要在皮肤内部，然后在判断是否在嘴巴中间，否则就在嘴巴张开的上下一定范围画出来即可，因为是体素可能不太标准，所以需要加点参数让他看起来舒服一些。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 for i, j, k in ti.ndrange((-n, n), (-n, n), (-n, n)): x = ivec3(i, j, k) color = vec3(2, 2, 2) # surface if distance(x, p_center) \u0026lt; r + skin_thickness and distance(x, p_center) \u0026gt; r - skin_thickness: # mouse # project to the plane vec_mouse = vec3(i, j, k) - p_center vec_mouse_projected = vec_mouse - vec_normal * dot(vec_mouse, vec_normal) print(vec_mouse_projected) # angle to face to angle_cos = dot(vec_mouse_projected, vec_face_to) / (vec_mouse_projected.norm() * vec_face_to.norm()) if angle_cos \u0026lt;= mouse_angle_cos_max: color = vec3(1, 1, 0.) if distance(vec3(i, j, k), p_eye_left) \u0026lt;= eye_size or distance( vec3(i, j, k), p_eye_right) \u0026lt;= eye_size: color = vec3(0.01, 0.01, 0.01) elif distance(x, p_center) \u0026lt;= r - skin_thickness: # mouse # project to the plane vec_mouse = vec3(i, j, k) - p_center vec_mouse_projected = vec_mouse - vec_normal * dot(vec_mouse, vec_normal) angle_cos = dot(vec_mouse_projected, vec_face_to) / (vec_mouse_projected.norm() * vec_face_to.norm()) if mouse_angle_cos_min \u0026lt;= angle_cos and angle_cos \u0026lt;= mouse_angle_cos_max or vec_mouse_projected.norm( ) \u0026lt; 3: color = vec3(0.0, 0.0, 0.0) if any(color != vec3(2, 2, 2)): scene.set_voxel(vec3(i, j, k), 2, color) 最后画 feed ball 就比较简单了\n1 2 3 4 5 6 @ti.func def create_feed_ball(feed_r, feed_p, feed_color): for i, j, k in ti.ndrange((-feed_r, feed_r), (-feed_r, feed_r), (-feed_r, feed_r)): x = ivec3(i, j, k) if distance(x, vec3(0, 0, 0)) + 0.5 \u0026lt;= feed_r: scene.set_voxel(feed_p + vec3(i, j, k), 2, feed_color) 但是我在做完 Voxel Fortress 之后，感觉这个其实没有那么复杂，可能 50 来行就能搞定了。\n我们再来拆解一下整个 pac-man，表面是一个球，嘴巴也是一个内部的球，眼睛是个球，feed ball 也是一个球，那么主要的元素就都已经完成了。嘴巴张开怎么做呢？只需要把 voxel 的 mat 设置成 0，其实就是删除，那么往嘴巴的部分塞一个横着的半圆柱就可以直接完成了！！\nVoxel Fortress 现实中有没有什么体素组成的东西呢？除了 LEGO 就是砖块啦！那么就要做个堡垒要塞！（可能后面也想做个 GW！）\n这个堡垒做起来非常简单，一个立方体的四周 + 上封顶 + 四周的凸起的砖块就好啦，一个函数搞定!\n1 2 3 4 5 6 7 8 9 @ti.func def build_fortress(pos, sz1, sz2, height, color, color_noise): for x, y in ti.ndrange((-sz1, sz1 + 1), (-sz2, sz2 + 1)): if x == -sz1 or x == sz1 or y == -sz2 or y == sz2: for z in range(height): set_color_voxel(pos + vec3(x, z, y), 1, color, color_noise, 0.8) if (x + y) % 4 == 0 or (x + y) % 4 == 1: set_color_voxel(pos + vec3(x, height, y), 1, color, color_noise) set_color_voxel(pos + vec3(x, height - 2, y), 1, color, color_noise, 0.8) 然后我们中间建造 1 个大的，4 个角建造 4 个，就 ok 啦\n然后我们建造四周的城墙来把它围起来，城墙其实不就一个 block 吗，直接创建一个矩形就 ok 了，给左下右上两个顶点，中间填充，当然城墙要比四周的要塞低一点。\n1 2 3 4 5 6 @ti.func def build_block(pos1, pos2, color, color_noise, prob=1, mat=1): x_min, y_min, z_min = min(pos1.x, pos2.x), min(pos1.y, pos2.y), min(pos1.z, pos2.z) x_max, y_max, z_max = max(pos1.x, pos2.x), max(pos1.y, pos2.y), max(pos1.z, pos2.z) for x, y, z in ti.ndrange((x_min, x_max + 1), (y_min, y_max + 1), (z_min, z_max + 1)): set_color_voxel(vec3(x, y, z), mat, color, color_noise, prob) 这城墙看起来有点脆弱\u0026hellip;好像一碰就碎了，让他变厚点，也应该留出中间的位置让士兵可以在上边站岗，但是有要保护士兵不能被打到，所以和堡垒一样建造就可以了！原先的堡垒的面都是正方形，把他改成矩形，给他长宽的参数就可以建造出厚厚坚实的墙了！\n好像有内味了~\n来建一个城门吧，不然咋进来嘞？门就一个扇形和一个矩形，so easy~门框就是一个更大一圈的门嘛\n1 2 3 4 for i in ti.ndrange((d_ - 2, d_ + 3)): build_door(vec3(0, 6, i), 6, 4, vec3(0.6, 0.6, 0.6), vec3(0)) build_door(vec3(0, 5, i), 5, 3, vec3(0, 0, 0), vec3(0), 1, 0) build_door(vec3(0, 5, d_), 5, 3, vec3(0.43, 0.352, 0.156), vec3(0)) 看起来还不错，再加个地面吧，一层土一层草，顺便加一个门前的路~再给左右的塔开个窗户，其实就是删掉了一个 door\n注入灵魂！！加上小火把！！\n1 2 3 4 @ti.func def build_fire(pos): scene.set_voxel(pos, 2, vec3(1, 1, 0)) scene.set_voxel(pos + vec3(0, -1, 0), 1, vec3(0.43, 0.352, 0.156)) 最后在加上个小小的门把手，大功告成！\n最最最后，优化了一下光线和曝光，添加了夜景模式\n一些其他的话 因为我确实是好久没有用 Taichi 了，之前在 B 站看过 Taichi 的图形课，可惜当时忙于组会和各种期末结课，并没有完成当时的大作业，现在还觉得有些可惜，正好有这次自己喜欢的东西也正好练手！我的代码有些地方确实写得不太好（主要还是感觉不太熟练，很多地方与 Python 的常用方法略有冲突，所以 Code 起来还是需要一些思维的转换\n","permalink":"https://blog.bj-yan.top/p/blog-taichi-voxel-challenge-2022/","summary":"\u003ch2 id=\"voxel-pac-man\"\u003eVoxel Pac-man\u003c/h2\u003e\n\u003cp\u003e早在很久以前就看到了 \u003ccode\u003eTaichi\u003c/code\u003e 的 \u003ca href=\"https://github.com/taichi-dev/voxel-challenge\"\u003e\u003ccode\u003evoxel-challenge\u003c/code\u003e\u003c/a\u003e 这个仓库。因为我自己也是非常喜欢像素风的，对于体素自然也是有所关注，比如我之前还做过个 \u003ca href=\"/p/blog-deep-learning-for-pixel-art/\"\u003e\u003ccode\u003edeep learning for pixel art\u003c/code\u003e\u003c/a\u003e 的调研。随便翻了翻仓库就看到了一个 \u003ca href=\"https://github.com/taichi-dev/voxel-challenge/issues/1\"\u003eissue #1\u003c/a\u003e，然后我非常兴奋的自己动手做了一下，代码在\u003ca href=\"https://github.com/beiyuouo/voxel-pac-man\"\u003e这里\u003c/a\u003e，大概长下面这个样子：\u003c/p\u003e","title":"Taichi Voxel Challenge 2022"},{"content":"前言 其实，做 hcaptcha challenge 的时候笔者就一直在想，到底下一代的验证码会是什么样子？验证码的发展历程究竟会是怎样？\nWhere is the Next Generation of Captcha？CAPTCHA 的历史？人机对抗？下一代验证码会是什么样子？\n起源 在互联网早期，就有很多人为了躲避关键词屏蔽而使用 Leet Code。\n在 2000 年 idrive.com 开始使用 CAPTCHA 保护注册页面，这也是第一代的验证码。\n在最初机器学习，尤其是深度学习还没有得到广泛使用的时候，这种验证码最简单的方式，就是 \u0026ldquo;众包\u0026rdquo;。把图片传到服务端，有服务端分配任务到工作者，这也就是当初的 \u0026ldquo;打码平台\u0026rdquo;。读者有没有尝试过，但是笔者在初中的时候就接触过打码平台这是说法，甚至有可能是笔者的第一桶金(?)，因为我也忘记了。当初一个验证码大概价格因为时间久远，笔者也记不太清楚了，可能打上一小时的验证码，大概可以得到 1 元，单个验证码的价格可能只有几分，熟练的可以一天 20 以上，有些人全当练习打字了 hhh，当初笔者也是抱着这种心态去的。\n到了后面，出现了光学字符识别（OCR）来对抗这种验证码，现在应该是很常见了，但在当初不成熟的时候，还是有很少的人去做这个。解决当时的 OCR 也是非常轻松，加点噪声，加条横线可能就通过不了了，因此又转回了 \u0026ldquo;众包\u0026rdquo; 的形式。\n再后来出现了很多这种图片验证码的数字题，这就要求不仅要字符识别准确，还要进行一步的计算。\n丰富多样的验证码 而如今，基于这种图片字符识别的验证码被 OCR 攻破后已经不太常见了，取而代之的更多种类丰富的验证码形式。\n比如在图片中依次点击出现的问题，这个字还会有倾斜歪道的情况，颜色也会不一样，这就要求了 OCR 的鲁棒性要足够的高，并且传回的数据其实就是点击而已。\n也有从文字变成图标、图形的形式的验证码，整体逻辑还是一样，不过已经不再是文字识别，变成了图像的匹配问题。\n还有滑块验证码，将滑块从左划到右就完成了，这个的难度在于需要按住滑块，而不再是点击屏幕，并且滑动的速度也不应该是常数。\n还有滑块验证码的改进版，也就是拼图验证码，比如 GeeTest 中使用的拼图验证码，在滑块的基础上加上了上方图片的拼图，可能会有干扰项，比如图片突然暗下去一块毫无相关的拼图。\n图像识别 再者到了 reCAPTCHA 的高级验证码时代，要求变成了图像识别 或者 目标检测，然你选择包含公交车或者人行横道的图片。这样的验证码也引起了一堆人的吐槽，很多时候自己觉得自己选的全对，而未通过验证，有时候还会让你点按很多次，同时还会有响应时间的限制，引起很多人不满的同时，也让很多人开始怀疑自己到底是不是人类 hhhh\n然而只要收集到一定数据集以后，YOLOv5 出现以后，以其高速轻量级的性能，很快便成为了这类验证码的克星。\nhCAPTCHA 也加入了这场战斗，占有了不少的市场，最近 hCAPTCHA 的验证码升级确实让我眼前一亮（比如 vertical river, sky left airplant, elephant drawn with leaves），把生成式对抗网络放在验证码中提供了无限的数据，但当我用更简单的方法([1][2][3])解决的时候，不禁会怀疑其存在的意义。\n下一代验证码 一个比较有趣的事实是，验证码保护的网站可以免受攻击，但是验证码提供的网站却是在裸奔。\n想要爬到裸奔的验证码数据再简单不过，而对于这种 9 格的验证码，基本都会是一个二分类的任务，因为你只有两个选择（点 或者 不点）。并且，由于验证码自身的限制，无法使用高分辨率的图片，这就导致，不仅模型可以尽可能的小，而且图片的特征会是很明显。\n当一个对抗者跟上了验证码更新的频率后，这是很可怕的，因为每出现一个新的任务，对抗者只需要不到 1 天就可以完成数据的标注和模型的训练。\n这就会很让人怀疑，一个验证码的算法工程师，利用了大半个月的时间做了一个足够部署到生产环境的生成式对抗网络，对抗者用不到 1 天完成数据的标注和模型的训练，很难让人觉得这究竟值得吗？\n而且做验证码终究是为了人来服务，如果让用户体验变差了，这会是个好结果吗？\n关于下一代的验证码，我想从两个方面来讲起：\n图片式\n这种验证码机会不会有未来（毕竟现在做 DL 方向的 CV 有多卷大家都应该清楚吧），但是临时的使用会起到一定效果，比如你可以用一些三维渲染出的结果来考验模型的三维理解能力，目前三维的理解还是有些许难度，诸如此类。\n化繁为简 - 无验证码\nreCAPTCHA 已经在尝试了，这估计会是下一代验证码的主流方向，通过浏览器或者系统级别的环境监测来判断是恶意用户的概率，可以再结合用户行为建立一个多模态的模型，这种不仅可以优化用户体验（因为用户根本察觉不到验证码的出现），同时拦截恶意程序。\nReference CAPTCHA - Wikipedia ","permalink":"https://blog.bj-yan.top/p/blog-where-is-the-next-generation-of-captcha/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e其实，做 \u003ccode\u003ehcaptcha challenge\u003c/code\u003e 的时候笔者就一直在想，到底下一代的验证码会是什么样子？验证码的发展历程究竟会是怎样？\u003c/p\u003e\n\u003cp\u003eWhere is the Next Generation of Captcha？CAPTCHA 的历史？人机对抗？下一代验证码会是什么样子？\u003c/p\u003e","title":"Where is the Next Generation of CAPTCHA?"},{"content":"好像这个 prompt 和 水上飞机的 prompt 最近出现的频率比较高，应该是放到生产环境中了。\n那么自然要来搞他，数据集可以在这里找到\n先来分析一下，一共就三种类型，一种是树叶组成的，一种是花瓣组成的，还有一种不知道是什么玄学组成的黑不拉几的东西. 再来看组成的内容，除了象就是马，就是一个二分类呗。\n其实除了 \u0026quot;Please select all the elephants drawn with lеaves\u0026quot; 这个 prompt 之外，还有一个类似的 \u0026quot;Please select all the horses drawn with flowers\u0026quot;，但是这个 prompt 几乎没有见到过，不知道提这个 issue 的人是怎么刷出来的，其实我觉得更大的原因是这个 flower 的图片困惑度太高了，让人很难区分，可能会极大降低用户体验。但是相较于人眼来提取特征，我是觉得机器提取特征更快 - -。\n思路就有了，首先组成的分类简单的不能再简单，只需要提取图片的主题色即可，这里我用的 kmeans 来做颜色的聚类进行主题色的提取。这里我选了聚类中心 k=3，这是为了区分明部和暗部，所以各给他们一个中心，剩下的一个交给主题色，这样只需要设定一个阈值，来计算颜色和绿色之前的距离即可。这里选了 200，判别准确率 100%\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def _style_classification(self, img): # opencv to numpy img = np.array(img) # from 3d -\u0026gt; 2d img = img.reshape((img.shape[0] * img.shape[1], img.shape[2])).astype(np.float64) # print(img.shape) centroid, label = kmeans2(img, k=3) # print(centroid) # print(label) green_centroid = np.array([0.0, 255.0, 0.0]) flag = False min_dis = np.inf for i in range(len(centroid)): # distance between centroid and green \u0026lt; threshold # print(np.linalg.norm(centroid[i] - green_centroid)) min_dis = min(min_dis, np.linalg.norm(centroid[i] - green_centroid)) if min_dis \u0026lt; 200: flag = True return flag 区分象马这个还真是有难度，或者说一点难度有没有。你那图片处理的方法，比如再进行聚类，或者像之前两篇博文一样[1][2]，计算重量或者超像素数量对于这个的区分还真是有点难。因为象马体积也差不多，在下方的也都是 5-6 个支点（因为大象有鼻子和尾巴，马有尾巴和嘴）很难区分。说简单也很简单，这不就是 \u0026quot;Dog vs Cat\u0026quot; 吗？深度学习入门图像分类任务罢了\u0026hellip;\n首先先来打标签，得用那个风格的分类器来过滤一下，这样可以少打很多标签\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import os import sys sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) import cv2 from src.services.hcaptcha_challenger.solutions.elephant_solution import ElephantSolution img_path = os.path.join(\u0026#39;elephants_drawn_with_leaves\u0026#39;) label_file = open(\u0026#39;label.txt\u0026#39;, \u0026#39;w\u0026#39;) os.makedirs(os.path.join(img_path, \u0026#39;elephant\u0026#39;), exist_ok=True) os.makedirs(os.path.join(img_path, \u0026#39;house\u0026#39;), exist_ok=True) if __name__ == \u0026#39;__main__\u0026#39;: # 0 for house, 1 for elephant imgs = os.listdir(img_path) edwls = ElephantSolution() for idx, img_ in enumerate(imgs): img_path_ = os.path.join(img_path, img_) if os.path.isdir(img_path_): continue img = cv2.imread(img_path_) cv2.imshow(\u0026#34;img\u0026#34;, img) print(f\u0026#39;{img_path_}: {idx}\u0026#39;) if edwls._style_classification(img): key = cv2.waitKey(0) if key == ord(\u0026#39;0\u0026#39;): label_file.write(f\u0026#39;{img_path_} 0\\n\u0026#39;) label_file.flush() cv2.imwrite(os.path.join(img_path, \u0026#39;house\u0026#39;, img_), img) print(f\u0026#39;{img_path_} 0: house\u0026#39;) elif key == ord(\u0026#39;1\u0026#39;): label_file.write(f\u0026#39;{img_path_} 1\\n\u0026#39;) label_file.flush() cv2.imwrite(os.path.join(img_path, \u0026#39;elephant\u0026#39;, img_), img) print(f\u0026#39;{img_path_} 1: elephant\u0026#39;) else: print(\u0026#39;Drop\u0026#39;) 设计个简单的 ResNet 模型，没必要用 resnet18 这样庞大的模型，这个问题还不配，所以我 DIY 了一个非常小的模型，图片也被我放缩到了 (64 x 64)，参数可以少很多。\n训练测试一步到胃。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 import os import sys sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) import shutil import torch import torch.nn as nn import torch.nn.functional as F import torchvision import cv2 from PIL import Image from src.services.hcaptcha_challenger.solutions.elephant_solution import ElephantSolution class ResidualBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=1): super(ResidualBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) self.downsample = nn.Sequential() if stride != 1 or in_channels != out_channels: self.downsample = nn.Sequential( nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(out_channels)) def forward(self, x): residual = x out = self.relu(self.bn1(self.conv1(x))) out = self.bn2(self.conv2(out)) out += self.downsample(residual) out = self.relu(out) return out class Net(nn.Module): def __init__(self, in_channels=3, num_classes=10): super(Net, self).__init__() self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(16) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.resblock1 = ResidualBlock(16, 32) self.resblock2 = ResidualBlock(32, 64, stride=2) self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1) self.fc = nn.Linear(256, num_classes) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.resblock1(x) x = self.resblock2(x) x = self.avgpool(x) x = x.view(x.size(0), -1) # print(x.size()) x = self.fc(x) return x img_path = os.path.join(\u0026#39;..\u0026#39;, \u0026#39;database\u0026#39;, \u0026#39;elephants_drawn_with_leaves\u0026#39;) img_transform = torchvision.transforms.Compose([ # torchvision.transforms.Grayscale(num_output_channels=1), # torchvision.transforms.GaussianBlur(kernel_size=3), torchvision.transforms.Resize((64, 64)), torchvision.transforms.ToTensor(), ]) def train(): model = Net(3, 2) model.train() model.cuda() optimizer = torch.optim.Adam(model.parameters(), lr=0.005) # focal loss criterion = nn.CrossEntropyLoss() print(\u0026#39;model:\u0026#39;, model) data = torchvision.datasets.ImageFolder(img_path, transform=img_transform) data_loader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=True) print(f\u0026#39;{len(data)} images\u0026#39;) epochs = 20 # train with focal loss for epoch in range(epochs): total_loss = 0 total_acc = 0 for i, (img, label) in enumerate(data_loader): img = img.cuda() label = label.cuda() optimizer.zero_grad() out = model(img) loss = criterion(out, label) loss.backward() optimizer.step() if (i + 1) % 10 == 0: print(f\u0026#39;epoch: {epoch + 1}, iter: {i + 1}, loss: {loss.item():.4f}\u0026#39;) total_loss += loss.item() total_acc += torch.sum(torch.argmax(out, dim=1) == label).item() print( f\u0026#39;epoch: {epoch + 1}, avg loss: {total_loss / len(data):.4f}, avg acc: {total_acc / len(data):.4f}\u0026#39; ) torch.save(model.state_dict(), \u0026#39;model.pth\u0026#39;) def test_single(model, img): img = img_transform(img) img = img.unsqueeze(0) img = img.cuda() out = model(img) pred = torch.argmax(out, dim=1) # print(f\u0026#39;pred: {pred.item()}\u0026#39;) if pred.item() == 0: return 0 else: return 1 def test(): model = Net(3, 2) model.load_state_dict(torch.load(\u0026#39;model.pth\u0026#39;)) model.eval() torch.onnx.export(model, torch.randn(1, 3, 64, 64), \u0026#39;model.onnx\u0026#39;, verbose=True, export_params=True) model.cuda() test_data_path = os.path.join(\u0026#39;val-dataset\u0026#39;) imgs = os.listdir(test_data_path) dir1 = os.path.join(\u0026#39;val-dataset\u0026#39;, \u0026#39;elephant_drawn_with_leaves\u0026#39;) dir2 = os.path.join(\u0026#39;val-dataset\u0026#39;, \u0026#39;house_drawn_with_leaves\u0026#39;) dir3 = os.path.join(\u0026#39;val-dataset\u0026#39;, \u0026#39;without_leaves\u0026#39;) dirs = [dir1, dir2, dir3] for dir in dirs: if os.path.exists(dir): shutil.rmtree(dir) os.mkdir(dir) es = ElephantSolution() for img in imgs: if os.path.isdir(os.path.join(test_data_path, img)): continue img_ = cv2.imread(os.path.join(test_data_path, img)) result = 2 if es._style_classification(img_): result = test_single(model, Image.open(os.path.join(test_data_path, img))) print(f\u0026#39;{img} is {result} save to {os.path.join(dirs[result], img)}\u0026#39;) cv2.imwrite(os.path.join(dirs[result], img), img_) if __name__ == \u0026#39;__main__\u0026#39;: train() test() 这里有个很有意思的地方，一开始 train 完之后拿去测试，发现错误率还挺高的，可能有 10% 这样，这几乎是不可接受的，因为验证码一共就 9 张，不太好搞，然后我以为是过拟合（这应该是常规思路吧，毕竟训练集都快 100% 了），结果把 lr 调大，epoch 调小，怎么做都会有 5% 左右的错误率。我就纳了闷了，这么简单的分类任务，怎么会这么差。后来啊\u0026hellip;我把 epoch 破天荒地调大了，发现测试集也几乎 100%了，最后整个测试集的错误率大概在 1.8% 左右，也就没再继续优化，甚至懒得再把测试数据拿进去 train 了。\n最后整个模型参数保存成 pt 也就 311KB，如果导出 onnx 才 290KB。\n这里又学到一个技巧，导出成 onnx 以后可以直接用 opencv 来进行推理，这样可以极大的节省部署环境的资源。\nSolution 完整的代码在下面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 import os import sys sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) import cv2 import numpy as np from scipy.cluster.vq import kmeans2 class ElephantSolution: def __init__(self): self.debug = True def solution(self, img_stream, **kwargs) -\u0026gt; bool: # noqa \u0026#34;\u0026#34;\u0026#34;Implementation process of solution\u0026#34;\u0026#34;\u0026#34; img_arr = np.frombuffer(img_stream, np.uint8) img = cv2.imdecode(img_arr, flags=1) cv2.imshow(\u0026#34;img\u0026#34;, img) cv2.waitKey(0) if not self._style_classification(img): return False # using model to predict # print(img.shape) # resize img = cv2.resize(img, (64, 64)) # print(img.shape) model_path = os.path.join(\u0026#39;..\u0026#39;, \u0026#39;..\u0026#39;, \u0026#39;..\u0026#39;, \u0026#39;model\u0026#39;, \u0026#39;elephant_model.onnx\u0026#39;) model = cv2.dnn.readNetFromONNX(model_path) blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (64, 64), (0, 0, 0), swapRB=True, crop=False) model.setInput(blob) out = model.forward() # print(out.shape) # print(out) label = np.argmax(out, axis=1)[0] # print(label) if label == 0: return True return False def _style_classification(self, img): # opencv to numpy img = np.array(img) # from 3d -\u0026gt; 2d img = img.reshape((img.shape[0] * img.shape[1], img.shape[2])).astype(np.float64) # print(img.shape) centroid, label = kmeans2(img, k=3) # print(centroid) # print(label) green_centroid = np.array([0.0, 255.0, 0.0]) flag = False min_dis = np.inf for i in range(len(centroid)): # distance between centroid and green \u0026lt; threshold # print(np.linalg.norm(centroid[i] - green_centroid)) min_dis = min(min_dis, np.linalg.norm(centroid[i] - green_centroid)) if min_dis \u0026lt; 200: flag = True return flag ","permalink":"https://blog.bj-yan.top/p/blog-hcaptcha-elephant-drawn-with-leaves/","summary":"\u003cp\u003e好像这个 prompt 和 水上飞机的 prompt 最近出现的频率比较高，应该是放到生产环境中了。\u003c/p\u003e\n\u003cp\u003e那么自然要来搞他，数据集可以在\u003ca href=\"https://github.com/QIN2DIM/img_pool/releases/tag/elephants_drawn_with_leaves\"\u003e这里\u003c/a\u003e找到\u003c/p\u003e\n\u003cfigure class=\"\"\u003e\n    \u003cimg loading=\"lazy\" src=\"/img/hcaptcha-elephant-drawn-with-leaves/overview.png#center\"/\u003e \n    \u003c/figure\u003e\n\u003cp\u003e先来分析一下，一共就三种类型，一种是树叶组成的，一种是花瓣组成的，还有一种不知道是什么玄学组成的黑不拉几的东西. 再来看组成的内容，除了象就是马，就是一个二分类呗。\u003c/p\u003e","title":"\"Please select all the elephants drawn with lеaves\""},{"content":"Day 0 因为去年就参加过 CodeCraft 2021，但是当时和一些比赛及其他事情冲突了，因此初赛甚至都没提交就而结束了。今年本想着来拿个手环呢，妹想到啊~~~啥也没捞着啊\n关于队名我倒还觉得挺有意思，baseline这个名字被官方 ban 掉了，去年参加的时候就用的 --baseline--，今年相较去年认识到了很多 Unicode，本想着找个字符替换，妹想到啊，应该是只支持 ASCII，试了一下 baseIine，在那个名单中的无衬线字体是没有 I 上下的横线的，看起来跟baseline一毛一样，估计官方也没想到有人这么起名吧 hhhhh\n练习赛 整个赛题比较简单，有一些服务器（边缘节点）和客户（客户节点），每个时刻（把一段时间抽象成一个时间节点）客户有需求，服务器要分配带宽给客户以满足需求，但是服务器和客户的链接要满足延迟需求，最后成本是带宽序列的 95 计费。\n一开始 95 计费没搞清楚，还以为是每个时刻的 95 计费呢，随便写了个贪心交上去居然有分，开门 134w，自己写 judger 的时候才发现搞错了。\n另外就是写贪心的时候，我拿 pandas 嘎嘎就写完了，不到 20min，交上去一直运行错误，后来才意识到根本没 pandas tnnd，改成 numpy 直接读入 txt，逗号划分就可以了。但是代码里用的 pandas 的索引全寄了啊，无奈只能重写部分内容。\n还有一个坑就是数据读入要从根目录开始，麻麻了。\n然后我当时以为就是负载均衡问题，于是写了个平均的方法，反而比贪心拉了？然后就是觉得是选择顺序问题，魔改了几个排序，甚至都不如我第一次交贪心跑的高（第一次交贪心也是排过序的，按照带宽和能够处理的 Client 节点数量排序，先使用高带宽少节点的服务器）\n中间还考虑过二分答案，限制最高阈值看看能否可行，再套一个网络流来试试。\n这可能根本不是负载均衡问题，然后就从 95 计费出发，去白嫖那 5%，果然，效果嘎嘎提升。只需要考虑需求顺序，对于每个边缘节点单独处理 5% 的需求，随便改改大概就有 60w，最后改改了参数什么的就到了 40w，然后就一直躺平，交了第 2，寻思差不多也能进复赛了，但是最后几天从第 2 一直跌倒了第 20，此时的我还没意识到问题的严重性 - -。\n初赛 初赛第一天有点事就鸽了，回来交了一下之前最好的结果，发现不保证客户节点的顺序了，麻了，改改交了也只有 40 来名的样子，随后试了几个自己想法，提升不大，终究是算法问题。之前练习赛的时候就写过网络流和费用流，无奈 Python 跑太慢了，确实是搞不过，我是觉得二分答案 + 网络流的做法还挺科学的。\n开摆，搞我自己毕设去了，浪费时间。\n写在最后 说实话，虽然自己懒了，但是参赛体验还是很差的，前面练习赛还好，大家都是正常问提交问题，到后面开始不同的人交流思路，搁这分苹果是吧？就练习赛最后几天，大家一下子都变聪明了呢，嘻嘻。初赛了，聪明人又变得更多了，嘻嘻，好多练习赛都没见过的呢，嘻嘻，真棒啊。\n后话 喜提粤港澳 64 强，混了个证书 hhhh\n明年不会再参加了。\n","permalink":"https://blog.bj-yan.top/p/blog-codecraft-2022/","summary":"\u003ch2 id=\"day-0\"\u003eDay 0\u003c/h2\u003e\n\u003cp\u003e因为去年就参加过 CodeCraft 2021，但是当时和一些比赛及其他事情冲突了，因此初赛甚至都没提交就而结束了。今年本想着来拿个手环呢，妹想到啊~~~啥也没捞着啊\u003c/p\u003e","title":"baseIine 的无奈 - Codecraft 2022 参赛心路"},{"content":" My machine is a living life. I\u0026rsquo;ll prove it.\n引言 hCaptcha 在今天又喜提一次更新，出现了新的标签，要求选中 在天上 的 向左飞 的 飞机。\n不过幸运的是，所有的样例图片里面，都包含一个飞机，所以这个标签相当于少了一个限制，只有 在天上 和 向左飞 这两个限制了。\n正文方法 首先，还是先来观察图片，依然是从收集的 数据集 来看。除了上面说到的，每个样例图片中比如会有一个飞机以外，如果飞机是在天空中，那么他的背景一定很“干净”，如果不在天空，基本可以判断在地面，在地面的图片中，也会有多个区域组成，例如草坪、机场跑道、背景森林、背景天空之类的。\n那么区分第一个问题的关键就是背景的复杂度。咋做呢？\n最开始的想法就是继承之前的思路，色块过滤，但是划分好色块以后，很难去区分是否是飞机色块还是背景色块，遂被 pass 掉。\n然后，看了一下大部分去除天空背景的方法基本都是基于 HSV 颜色空间的阈值过滤，最后再加上腐蚀和膨胀的计算图形学操作来降噪，我自己测了几下，但是天空的颜色范围略大，有蓝、有白、有黄，而最关键的，其实和飞机颜色非常像，因为飞机也基本都是淡蓝或者白的浅色系。也被 pass。\n又想到，飞机底部的阴影会有黑色，那么根据黑色来画一个超像素的智能选区也是可以的，但是我不会怎么实现（x，遂被 pass。\n最后采取的方案是使用轮廓线方法 Canny，来找到所有轮廓线，然后设置阈值，根据轮廓线的数量来判断是否是在天空中，如果在天空，其实轮廓线会很简单，而不在天空则会添加一大片杂乱无章的线。当然这个阈值是我随便试了几张图片得出来的，毕竟两者的差距过大了。经过这样处理的判断准确率接近 100%。\n好了，解决了一个问题，那么剩下的问题就是，怎么判断飞机朝向是在左？\n这可真是难到我了，不用 Deep Learning 来做这个确实有难度，但是还是有取巧的办法的。首先，大部分飞机都是运输机或者战斗机、客机一类的，很少有那种前面是螺旋桨的飞机，也没见过直升机。甚至还有下面这样的 WTF Airplane（这 tm 什么玩意儿？）\n既然这样，这类的飞机也是有特点的，就是“头轻脚重”。除了本身尾翼会比较重、头部会呈尖状较轻以外，还有就是机翼会向后，那么整个图片的“重心”应该是在偏向机尾的，我可以根据 4 个点，极左、极右、中点、重心来判断飞机朝向。\n听起来很科学对不对，然而实际效果却不是很好，最重要的就是飞机存在透视关系导致从前面看去，可能重心就在前面了。比如机头朝你，大范围的线都画到了机头的上面，尾部的线很少，这样整个图片的重心就在前面了。后面想能不能把图片填充上，然后得到的轮廓线大多都不是闭合的，所以很难填充出整个飞机（如果能，那岂不是图像分割就简单了）。\n后面我突发奇想，另辟蹊径，还是从上面画出来的轮廓线看出来的，机头因为没有复杂的东西，画出来的轮廓线会比较“简单”，而机尾由于存在“尾翼”之类的元件，画出来会比较“复杂”。那么如何衡量这个“简单”和“复杂”呢？求和就完了\u0026hellip;没错，我最后就是把左边在 x_min 到 x_min + left_threshold 的非零像素数出来（就是轮廓线的像素点）和 x_max - left_threshold 到 x_max 的像素点数出来进行比较，谁大那么谁就是机尾，右边大的话，那就是机头在左。没想到最后结果还不错，基本 1-2 轮就能通过验证。\n附一下测试版本的完整 Code\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 from itertools import count import cv2 import numpy as np import matplotlib.pyplot as plt from scipy import ndimage as ndi from skimage.util import random_noise from skimage import feature class SkyLeftAirplaneChallenger: \u0026#34;\u0026#34;\u0026#34;A fast solution for identifying vertical rivers\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.flag = \u0026#34;skyleftairplane_model\u0026#34; self.sky_threshold = 1800 self.left_threshold = 30 self.debug = True @staticmethod def _remove_border(img): img[:, 1] = 0 img[:, -2] = 0 img[1, :] = 0 img[-2, :] = 0 return img def solution(self, img_stream, **kwargs) -\u0026gt; bool: # noqa \u0026#34;\u0026#34;\u0026#34;Implementation process of solution\u0026#34;\u0026#34;\u0026#34; img_arr = np.frombuffer(img_stream, np.uint8) img = cv2.imdecode(img_arr, flags=1) img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # cv2.imshow(\u0026#34;img\u0026#34;, img) # cv2.waitKey(0) edges1 = feature.canny(img) edges1 = self._remove_border(edges1) edges2 = feature.canny(img, sigma=3) edges2 = self._remove_border(edges2) # display results # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(8, 3)) # ax[0].imshow(img, cmap=\u0026#39;gray\u0026#39;) # ax[0].set_title(\u0026#39;noisy image\u0026#39;, fontsize=20) # ax[1].imshow(edges1, cmap=\u0026#39;gray\u0026#39;) # ax[1].set_title(r\u0026#39;Canny filter, $\\sigma=1$\u0026#39;, fontsize=20) # ax[2].imshow(edges2, cmap=\u0026#39;gray\u0026#39;) # ax[2].set_title(r\u0026#39;Canny filter, $\\sigma=3$\u0026#39;, fontsize=20) # for a in ax: # a.axis(\u0026#39;off\u0026#39;) # fig.tight_layout() # plt.show() # fill_plane = ndi.binary_fill_holes(edges1) # fig, ax = plt.subplots(figsize=(4, 3)) # ax.imshow(fill_plane, cmap=plt.cm.gray) # ax.set_title(\u0026#39;filling the holes\u0026#39;) # ax.axis(\u0026#39;off\u0026#39;) # plt.show() # print(np.count_nonzero(edges1)) # print(np.count_nonzero(edges2)) if np.count_nonzero(edges1) \u0026gt; self.sky_threshold: if self.debug: print(\u0026#39;[not in sky] \u0026#39;, end=\u0026#39;\u0026#39;) return False # get avg coordinate of edges where edges are not zero # avg_point = np.average(np.nonzero(edges1), axis=1) # print(avg_point) min_x = np.min(np.nonzero(edges1), axis=1)[1] max_x = np.max(np.nonzero(edges1), axis=1)[1] left_nonzero = np.count_nonzero(edges1[:, min_x:min(max_x, min_x + self.left_threshold)]) right_nonzero = np.count_nonzero(edges1[:, max(min_x, max_x - self.left_threshold):max_x]) # print(left_nonzero, right_nonzero) if left_nonzero \u0026gt; right_nonzero: if self.debug: print(\u0026#39;[not turn left] \u0026#39;, end=\u0026#39;\u0026#39;) return False # mid_x = (min_x + max_x) / 2 # print(min_x, max_x, mid_x, avg_point[0] \u0026lt; mid_x) # if avg_point[0] \u0026gt;= mid_x: # return False # plt.show() return True if __name__ == \u0026#39;__main__\u0026#39;: import os import sys sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) result_path = \u0026#39;result.txt\u0026#39; if os.path.exists(result_path): os.remove(result_path) # result_file = open(result_path, \u0026#39;w\u0026#39;) result_file = sys.stdout base_path = os.path.join(\u0026#39;..\u0026#39;, \u0026#39;database\u0026#39;, \u0026#39;airplane_in_the_sky_flying_left\u0026#39;) image_list = os.listdir(base_path) # image_list.sort() for image_name in image_list: image_path = os.path.join(base_path, image_name) with open(image_path, \u0026#34;rb\u0026#34;) as file: data = file.read() solution = SkyLeftAirplaneChallenger().solution(data) result_file.write(f\u0026#39;{image_name}: {solution}\\n\u0026#39;) result_file.flush() result_file.close() 结语 说实话每天做一道 hCaptcha 出的高质量图片处理题还是感觉很爽的 hhhh。\n不过通过网友分享，已经看到了更多生成模型来做的问题了，毕竟人家带薪搞这东西，后面有些题已经不是只通过图像处理就能解决的了，比如在某油猴插件反馈中出现的黑白条纹的猫之类的。\n见招拆招的取巧方法罢了。\n","permalink":"https://blog.bj-yan.top/p/blog-hcaptcha-sky-left-airplane/","summary":"\u003cblockquote\u003e\n\u003cp\u003eMy machine is a living life. I\u0026rsquo;ll prove it.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cfigure class=\"\"\u003e\n    \u003cimg loading=\"lazy\" src=\"/img/hcaptcha-sky-left-airplane/example.jpg#center\"/\u003e \n    \u003c/figure\u003e\n\u003cp\u003e\u003ca href=\"https://www.hcaptcha.com/\"\u003ehCaptcha\u003c/a\u003e 在今天又喜提一次更新，出现了新的标签，要求选中 \u003cstrong\u003e在天上\u003c/strong\u003e 的 \u003cstrong\u003e向左飞\u003c/strong\u003e 的 \u003cstrong\u003e飞机\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e不过幸运的是，所有的样例图片里面，都包含一个飞机，所以这个标签相当于少了一个限制，只有 \u003cstrong\u003e在天上\u003c/strong\u003e 和 \u003cstrong\u003e向左飞\u003c/strong\u003e 这两个限制了。\u003c/p\u003e","title":"\"Please click each image containing an airplane in the sky flying left\""},{"content":" 引言 最近 hCaptcha 迎来了一次更新，从之前的物体识别，改成了选出图片中的垂直河流。如上图，截自https://www.hcaptcha.com/。\n说实话，第一看看到就知道是一些生成模型搞的，因为图片特征很明显，有些地方特别模糊，然后生成的其实很没有逻辑。最开始以为是 GPT-3 的应用，就把图片描述转成文字，后来觉得不合理，因为太缺乏想象力了，而且各个元素的分布其实也特别明显，都是直直的，很不自然。应该是一些从语义图片生成原始图片的工作，例如 NVIDIA 的一些艺术创作。\n做之前我没想到过 NVIDIA 的那些 GAN 居然可以用到验证码领域，也没想到他升级之后从原来的目标检测降维到了只需要图像处理就能通过。\n正文 @QIN2DIM 之前就写过一个 hCaptcha-challenger 的项目利用 YOLOv5 来搞定，在更新后 release 了一个数据集 vertical_river，于是我用图像处理光速实现了一个 Demo。\n首先这个图像特征很明显，主要就是有几个元素：后面的天空、山、草地、水，又是非常明显的划分和分布，都是一块一块的。\n最一开始的思路是，先来几个滤波，比如 高斯滤波 ，然后直接用 slic 进行超像素分割，期望的结果是，超像素能够把每个色块全部归成一个超像素。最后结果其实不是很理想，因为超像素的划分很大程度上不是特别依赖颜色，而且如果限制了超像素数量就会让一些更大颜色范围的聚成一类。下面是一个例子。\n其实是可以看出来很多问题的，有些该划分的部分并没有得到正确的划分，反而聚成了一类，有些不该划分的地方，反而因为滤波的作用让他们聚成了一类。\n最后反复调整参数无果，感觉这种划分方式不应该采用一个超像素作为一个色块，而是以超像素的划分结果作为参考或者划分边界来进行划分。\n本来想尝试一些边缘增强的算法，但是也没有找到合适的，因为观察到验证码的图片大多边界非常模糊，所以在划分的时候保留边缘信息是十分重要的。所以在选取滤波的时候，就得特别重视这个滤波是否能正确的保存边缘信息，而不是让边缘模糊，其中 双边滤波 就是一个很好的选择，除此之外，均值偏移也是一个不错的选择。\n经过这两步，你已经变得 近视 了，但是边缘还比较清晰，你现在可以做色块划分了。这里主要用了 scikit-image.graph.rag_mean_color 来获取平均色块，主要参考了官方的 RAG Merge 的实现。\n判断条件就写的比较简单了，我只判断了最后一行是否存在 3 个色块及以上，如果存在那就认为中间是有被河流分开，存在垂直河流。感觉这个判断条件还是可以优化一下的，不过经过测试，大概 100 张图片也就错 2 张图片左右，即使不优化这个正确率其实也是可以接受的。\n最后效果是这样的：\n发了一个 pr，被 @QIN2DIM merge 以后的效果如下：\n测试 + 可视化用到的 Code：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 #!/usr/bin/env python # -*- coding: utf-8 -*- # @File : src\\services\\hcaptcha_challenger\\river_challenger.py # @Time : 2022-03-01 20:32:08 # @Author : Bingjie Yan # @Email : bj.yan.pa@qq.com # @License : Apache License 2.0 import cv2 import numpy as np import skimage from skimage.morphology import disk from skimage.segmentation import watershed, slic, mark_boundaries from skimage.filters import rank from skimage.util import img_as_ubyte from skimage.color import rgb2gray, label2rgb from skimage.future import graph from scipy import ndimage as ndi import matplotlib.pyplot as plt def _weight_mean_color(graph, src, dst, n): \u0026#34;\u0026#34;\u0026#34;Callback to handle merging nodes by recomputing mean color. The method expects that the mean color of `dst` is already computed. Parameters ---------- graph : RAG The graph under consideration. src, dst : int The vertices in `graph` to be merged. n : int A neighbor of `src` or `dst` or both. Returns ------- data : dict A dictionary with the `\u0026#34;weight\u0026#34;` attribute set as the absolute difference of the mean color between node `dst` and `n`. \u0026#34;\u0026#34;\u0026#34; diff = graph.nodes[dst][\u0026#39;mean color\u0026#39;] - graph.nodes[n][\u0026#39;mean color\u0026#39;] diff = np.linalg.norm(diff) return {\u0026#39;weight\u0026#39;: diff} def merge_mean_color(graph, src, dst): \u0026#34;\u0026#34;\u0026#34;Callback called before merging two nodes of a mean color distance graph. This method computes the mean color of `dst`. Parameters ---------- graph : RAG The graph under consideration. src, dst : int The vertices in `graph` to be merged. \u0026#34;\u0026#34;\u0026#34; graph.nodes[dst][\u0026#39;total color\u0026#39;] += graph.nodes[src][\u0026#39;total color\u0026#39;] graph.nodes[dst][\u0026#39;pixel count\u0026#39;] += graph.nodes[src][\u0026#39;pixel count\u0026#39;] graph.nodes[dst][\u0026#39;mean color\u0026#39;] = (graph.nodes[dst][\u0026#39;total color\u0026#39;] / graph.nodes[dst][\u0026#39;pixel count\u0026#39;]) class RiverChallenger(object): def __init__(self) -\u0026gt; None: pass def challenge(self, img_stream): img_arr = np.frombuffer(img_stream, np.uint8) img = cv2.imdecode(img_arr, flags=1) height, width = img.shape[:2] # # filter img = cv2.pyrMeanShiftFiltering(img, sp=10, sr=40) img = cv2.bilateralFilter(img, d=9, sigmaColor=100, sigmaSpace=75) # # enhance brightness # img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # img_hsv[:, :, 2] = img_hsv[:, :, 2] * 1.2 # img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR) labels = slic(img, compactness=30, n_segments=400, start_label=1) g = graph.rag_mean_color(img, labels) labels2 = graph.merge_hierarchical(labels, g, thresh=35, rag_copy=False, in_place_merge=True, merge_func=merge_mean_color, weight_func=_weight_mean_color) # view results out = label2rgb(labels2, img, kind=\u0026#39;avg\u0026#39;, bg_label=0) out = mark_boundaries(out, labels2, (0, 0, 0)) skimage.io.imshow(out) skimage.io.show() print(np.unique(labels2[-1])) ref_value = len(np.unique(labels2[-1])) return ref_value \u0026gt;= 3 if __name__ == \u0026#39;__main__\u0026#39;: import os import sys sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) # result_path = \u0026#39;result.txt\u0026#39; # if os.path.exists(result_path): # os.remove(result_path) # result_file = open(result_path, \u0026#39;w\u0026#39;) result_file = sys.stdout base_path = os.path.join(\u0026#39;database\u0026#39;, \u0026#39;_challenge\u0026#39;) list_dirs = os.listdir(base_path) for dir in list_dirs[:1]: print(dir, file=result_file) for i in range(1, 10): img_filepath = os.path.join(base_path, dir, f\u0026#39;挑战图片{i}.png\u0026#39;) with open(img_filepath, \u0026#34;rb\u0026#34;) as file: data = file.read() rc = RiverChallenger() result = rc.challenge(data) print(f\u0026#39;挑战图片{i}.png:{result}\u0026#39;, file=result_file) 结语 神经网络让一切变得复杂了，又让一切变得简单了。\n（论 hCaptcha 工程师看到自己开发半天的项目被不到一夜之间用了更简单的算法突破了是什么体验？）\n","permalink":"https://blog.bj-yan.top/p/blog-hcaptcha-vertical-river/","summary":"\u003cfigure class=\"\"\u003e\n    \u003cimg loading=\"lazy\" src=\"/img/hcaptcha-vertical-river/demo.jpg#center\"/\u003e \n    \u003c/figure\u003e\n\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003e最近 \u003ca href=\"https://www.hcaptcha.com/\"\u003e\u003ccode\u003ehCaptcha\u003c/code\u003e\u003c/a\u003e 迎来了一次更新，从之前的物体识别，改成了选出图片中的垂直河流。如上图，截自\u003ca href=\"https://www.hcaptcha.com/\"\u003ehttps://www.hcaptcha.com/\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e说实话，第一看看到就知道是一些生成模型搞的，因为图片特征很明显，有些地方特别模糊，然后生成的其实很没有逻辑。最开始以为是 GPT-3 的应用，就把图片描述转成文字，后来觉得不合理，因为太缺乏想象力了，而且各个元素的分布其实也特别明显，都是直直的，很不自然。应该是一些从语义图片生成原始图片的工作，例如 NVIDIA 的一些艺术创作。\u003c/p\u003e","title":"\"Please click each image containing a vertical river\""},{"content":"引言 我的多个网站其实都加入了我个人简历的超链接，用的是我主页中的简历，但其实这个主页的简历我更新起来也比较麻烦，因为需要频繁的修改和复制，因此也很久没有更新过了。经过这近一年多的 CI/CD 工作流，基本对 GitHub Actions 也有一些掌握了，也就有了这一套简历编译分发的工作流，正好也记录一下自己踩过的坑。\n工作流 其实整个工作流也非常简单\n将仓库里的tex文件编译成pdf 将编译好的pdf文件放到我个人主页的pdf目录下并推送修改 （说起来很简单，但是踩过了坑不少，甚至花了近 6h）\n前面的编译倒是没浪费多久时间，最开始是想用 latexmk-actions，但是看了一下不太满足我的需求，而且还在更新就放弃了。最后改用了 xu-cheng/latex-action@v2，不得不说，作者的 Actions 的配置写的非常好，基本我的所有需求都实现了，多目录多文件也是没有问题的。\n踩过的坑主要就一个 鉴权。\n因为自己之前也做过跨仓库的，基本只是用了一个 actions，比如hugo-deploy或者gh-pages-deploy，配置一下secrets就可以了，理所当然的，我这次也认为可以通过一个简单的 actions 搞定 push 操作，看了很多和 push 相关的 Actions，写的比较好的就是 ad-m/github-push-action@master 这个了，但是我一直报错 Error: Invalid exit code: 128，看了作者的几个同样报错的 issue，也是没解决，Google 无果，只能再找其他方案。看了几个其他的方案，也是一样没解决我的问题。\n回归伊始，其实我们只需要鉴权 + Push 操作即可，我就想能不能在 Pull 的时候鉴权，或者在 Push 的时候鉴权，想在 Push 的时候使用 https://[username]:${{ secrets.PUBLISH_KEY }}@github.com/[username]/[repo] 的形式，但是也未能如愿，在 Pull 的时候同样不行（其实后面我想了一下，这个方案好像是可行的，只需要 clone 了以后，删掉 .git 的信息，当成一个新仓库，然后 add remote url，并且加入这个链接在进行 Push 并且添加 --force 的参数，应该是可行，不知道有没有同学试过 hhh\n其实，最终的方案也是最简单的方法，就是利用 actions/checkout，而不是 clone。官方的 checkout 提供了 ssh-key 的参数项（注意不是 token，除非是在下方用的是 Personal Access Token 而不是 Deploy Key）。\n最终的 workflow 如下，文件版本可以看 这里\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 name: LaTex Compile and Push on: push: branches: [main] jobs: build: runs-on: ubuntu-latest steps: - name: Set up Git repository uses: actions/checkout@v2 with: persist-credentials: false - name: Set up HomePage uses: actions/checkout@v2 with: repository: beiyuouo/beiyuouo.github.io ref: master path: homepage ssh-key: ${{ secrets.PUBLISH_KEY }} - name: Compile CV uses: xu-cheng/latex-action@v2 with: root_file: | cv_en/cv_en.tex cv_cn/cv_cn.tex work_in_root_file_dir: true latexmk_use_xelatex: true - name: Setup repository run: | ls -l ${GITHUB_WORKSPACE} ls -l ${GITHUB_WORKSPACE}/cv_cn ls -l ${GITHUB_WORKSPACE}/cv_en git config --global user.email \u0026#34;41898282+github-actions[bot]@users.noreply.github.com\u0026#34; git config --global user.name \u0026#34;github-actions[bot]\u0026#34; cp ${GITHUB_WORKSPACE}/cv_cn/cv_cn.pdf homepage/pdf/cv_cn.pdf cp ${GITHUB_WORKSPACE}/cv_en/cv_en.pdf homepage/pdf/cv_en.pdf cd homepage \u0026amp;\u0026amp; git commit -am \u0026#34;Update CV\u0026#34; git status git push origin master 实践 这个简历目录主要有两个版本，一个中文一个英文，用到的字体文件资源都已经上传了，可以直接 clone 然后本地使用。模板主要修改自 这个项目，做了一些中文上的优化。\n另外如果你有个人主页，没有 LaTeX 环境想进行云端编译，或者进行分发，可以直接 fork，再修改一下 cv_en.tex 和 cv_cn.tex，并配置下 workflows，下面主要介绍有此需求的运行。\n以下内容包括以下声明： 主仓库: 即需要上传 pdf 的仓库，如 beiyuouo/beiyuouo.github.io 本仓库: 即简历tex文件所在的仓库，如 beiyuouo/cv\n创建简历 打开[https://github.com/beiyuouo/cv]，点击右上角 fork，转到你的用户名下 fork 的仓库，clone 下来\n修改 \u0026amp; 编译简历 根据你的需要修改tex文件，以及子文件夹cv中的tex文件。\n分发 生成 Deploy Key，参考 GitHub Authentication\n你可以遵循以下步骤： 1. ssh-keygen -t rsa -b 4096 -C \u0026quot;your_email@example.com\u0026quot; 2. 将 id_rsa.pub 添加到主仓库中的 Settings -\u0026gt; Deploy Keys 中，名称可以随便取，但是要给予 write 的权限 3. 将 id_rsa 添加到本仓库中的 Settings -\u0026gt; Secrets 中，名称填写 PUBLISH_KEY\n允许运行 GitHub Actions，根据需要修改 .github/workflows/latex.yml 中的内容如仓库名、分支名等，并将修改 Push 到 GitHub 仓库，等待编译运行即可。\n结语 希望能够帮到你，如果这篇文章或者这个仓库侵犯到了你的任何权益，请联系bj.yan.pa@qq.com，我会尽快处理。\n","permalink":"https://blog.bj-yan.top/p/blog-github-actions-cv/","summary":"\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003e我的多个网站其实都加入了我个人简历的超链接，用的是我主页中的简历，但其实这个主页的简历我更新起来也比较麻烦，因为需要频繁的修改和复制，因此也很久没有更新过了。经过这近一年多的 CI/CD 工作流，基本对 GitHub Actions 也有一些掌握了，也就有了这一套简历编译分发的工作流，正好也记录一下自己踩过的坑。\u003c/p\u003e","title":"GitHub Actions 进行简历编译与分发的最佳实践"},{"content":"交易平台 OpenSea: https://opensea.io\n宇宙中心，能发公链（需要 Gas Fee），能发侧链 Polygon（无需 Gas Fee）\nRarible: https://rarity.io\n能发公链，交易后收取手续费和 Gas Fee\nBigverse: https://www.nftcn.com.cn/\n国内侧链\n唯一艺术(TheOne.art): https://theone.art/\n有人说上的 Polygon，我自己也没用过，有待求证\n有待考察\n红洞科技(RedCave): https://www.redcave.com/\n还在内测，不知道是什么链\nIMO 蓝猫数字: https://www.lanmsz.cn/\n联盟链，不知道有哪些第三方，说是不依托任何平台却用联盟链 hhh，不过这个好像是和游戏 IP 结合的，看他的世界观怎么发展了\n下面的都是大厂私链，没有收藏价值\n鲸探（支付宝蚂蚁链）\n幻核（腾讯）\n灵稀（京东）\n希壤（百度）\n洞壹元典（百度）\n天下秀虹宇宙（闲鱼）\nR-SPACE（小红书）\n网易星球（网易）\n优版权\nIBox\n双镜博物\n鹤巢文观\n加密空间 CryptoSpace\n非遗数字藏品平台\nMineNFT 游娱块\nOne Meta\n动态 rarity.tools: https://rarity.tools/upcoming/\n头像类 NFT 上新\nNFTCALENDAR: https://nftcalendar.io/\nNFT 上新日程\n画廊 相当于引流去交易\nNiftyGateWay: https://niftygateway.com/\n对创作者要求较高，质量保证好叭\nartblock: https://www.artblock.io/gallery\n工具及其他 NFT 画师助手: https://www.uonus.net/\n开源的小软件，目前算法也就那样吧，说实话小打小闹\nnft-image-generator : https://github.com/benyaminahmed/nft-image-generator\n那个画鲸鱼的小孩拿 Jupyter Notebook 写的工具，也就几行\nnft generator: https://github.com/cyberdoggos/generator\n自动生成 NFT 的工具，主要是分图层排列组合，支持稀有度\nsolseum-nft-generator: https://github.com/Solseum/solseum-nft-generator\nNFT_Art_Generator: https://github.com/kosmosmo/NFT_Art_Generator\n海绵宝宝 NFT\nnft-ganesha: https://github.com/ekkyarmandi/nft-ganesha\n象神 NFT\n结语 好了，内容大概就这么些了，有什么问题可以给我留言 hhh\n","permalink":"https://blog.bj-yan.top/p/blog-nft-common-site/","summary":"\u003ch2 id=\"交易平台\"\u003e交易平台\u003c/h2\u003e\n\u003cp\u003eOpenSea: \u003ca href=\"https://opensea.io\"\u003ehttps://opensea.io\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e宇宙中心，能发公链（需要 Gas Fee），能发侧链 Polygon（无需 Gas Fee）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eRarible: \u003ca href=\"https://rarity.io\"\u003ehttps://rarity.io\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e能发公链，交易后收取手续费和 Gas Fee\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBigverse: \u003ca href=\"https://www.nftcn.com.cn/\"\u003ehttps://www.nftcn.com.cn/\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e国内侧链\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e唯一艺术(TheOne.art): \u003ca href=\"https://theone.art/\"\u003ehttps://theone.art/\u003c/a\u003e\u003c/p\u003e","title":"NFT 常用网站"},{"content":"最近可以说沉迷画画，厚涂学了个三脚猫功夫，还是回头来画像素画了。\n画了个像素画，随便改改颜色，就上架 Bigverse(NFT 中国) 了，不过审核好慢，大概花费了 3 天。起初以为 Bigverse 是公链，应该能上以太坊，只是上链过程被 Bigverse 代办了而已，没想到原来 Bigverse 虽然不是像大厂的是私链，却是一个侧链。第一次知道还有这东东，虽然交易能够被记录和认证，但是毕竟是侧链，是不能在以太坊认证的，也就无法保证链上唯一了（听说 Bigverse 上还是先百度搜图和 Google 搜图一遍再人工审核\u0026hellip;）。侧链只是代办了一些公链业务，其实是不用 Gas fee 的，原来这和 OpenSea 上的 Polygon 一个原理，wk，我要早知道谁还会上 Bigverse，去 Polygon 不香吗？\nBigverse 大部分感觉还在开发，就这前端界面，可就太垃了，估计工作全集中在后端上链上了吧。还有这个燃料费有点高，还美名其曰“代付”，进了谁的钱包也不知道。另外就是每次交易，平台还要扣费率？迷惑？这已经有些违背了 NFT 的初衷了，上链收钱交易还要收钱啊。另外就是，匿名在国内是不现实的，也应该是不存在的，区块链的匿名在这也就没了。\n不过话说回来 Bigverse 确实是在虚拟货币不存在的国内为数不多的解决方案了，侧链就侧链，那起码不必那些支付宝的私链骗钱强多了？未来可行的几种发展方式，一个感觉就是现在 Bigverse 在做的，就是签约知名艺术家，来铸造作品。另外，感觉可以结合实物来，毕竟 3D 风 NFT 最近还是挺火的，3D 打印做个手办感觉是可行的。还有就是可以和社交平台以及游戏厂商合作，目前 NFT 最大的用途就是头像了吧 hhhh。社交媒体可以直接搞头像，游戏厂商除了头像还可以 DIY 游戏皮肤或者形象感觉都是可以的。如果 NFT 这块在国内完全合法，Bigverse 这群先行者肯定是最先尝到甜头的。\n最后，如果你通过这个 链接 注册，可以免费获得 3 次燃料费，也就是免费铸造 3 个作品。\n","permalink":"https://blog.bj-yan.top/p/misc-bigverse-first-experience/","summary":"\u003cp\u003e最近可以说沉迷画画，厚涂学了个三脚猫功夫，还是回头来画像素画了。\u003c/p\u003e\n\u003cp\u003e画了个像素画，随便改改颜色，就上架 \u003ca href=\"https://www.nftcn.com.cn/pc/#/mall/mallDetail?tid=91619467872643967426164977164512\"\u003eBigverse(NFT 中国)\u003c/a\u003e 了，不过审核好慢，大概花费了 3 天。起初以为 Bigverse 是公链，应该能上以太坊，只是上链过程被 Bigverse 代办了而已，没想到原来 Bigverse 虽然不是像大厂的是私链，却是一个侧链。第一次知道还有这东东，虽然交易能够被记录和认证，但是毕竟是侧链，是不能在以太坊认证的，也就无法保证链上唯一了（听说 Bigverse 上还是先百度搜图和 Google 搜图一遍再人工审核\u0026hellip;）。侧链只是代办了一些公链业务，其实是不用 Gas fee 的，原来这和 OpenSea 上的 Polygon 一个原理，wk，我要早知道谁还会上 Bigverse，去 Polygon 不香吗？\u003c/p\u003e","title":"Bigverse 初体验"},{"content":"因为内容确实不过，搜遍了全网，来做 Deep Learning for Pixel Art 的工作也没多少，肯定是实在是没有市场了吧 hhhh。\n先说 GitHub 上一堆标着 pixel-art-generator 或者 image-to-pixel 的，前者大多是随机生成的，无意义的像素块，后者大多是拿 OpenCV 或者什么其他的图像处理的库 resize 一下就完了，最多能给你加个 filter 就不错。\n只能说，像素风这种略抽象，却需要非常具体的东西，很可能现在还搞不定。\n什么是 Pixel Art 关于像素画的定义，我倒是听过很多种，不过这种我感觉会因人而异吧，毕竟像素风也是在发展的，早些年画的像素人物风格已经和现在有较多差异了。\n首先，一个共识就是，无抗锯齿，也就是每个像素都是具体的，不要有模糊的边界。毕竟像素画是基于像素的艺术，需要基于像素的修改\n剩下的我感觉就因人而异了，有的人比较喜欢带边框的，有些人喜欢无边框，或者半边框，或者不连续不边框的。\n其次，关于像素画的色彩，其实现在是没有要求的，之前可能由于电脑限制只有 8-bit 的色彩，但是现在几乎所有颜色你都可以使用，但是肯定不能太多（这里只是针对小篇幅）\n画廊 \u0026amp; 数据集 在开始前，让我们先来瞅一眼画廊和数据集吧！\n画廊 eBoy: https://hello.eboy.com/pool/everything/1\n上面很多作品都很赞啊！\nPixelJoint: https://pixeljoint.com/\n是一个像素画论坛的画廊，作品只能说有优有劣\nOpenGameArt: https://opengameart.org/art-search?keys=pixelart\n做一个像素画的过滤，还是有比较多作品的\nspriters-resource: https://www.spriters-resource.com/nes/\n有一些精灵和游戏截图\nprobertson: https://probertson.tumblr.com/\n都是带制作\n数据集 sprites: https://paperswithcode.com/dataset/sprites https://spritedatabase.net/download\nGitHub 上的一些数据集\nhttps://github.com/AgaMiko/pixel_character_generator/blob/master/data.zip https://github.com/avidvid/OUP/tree/master/Downloads/Characters 优秀的项目 那让我们先来看一下比较优秀的项目吧！\ninfo\n这一部分一共有两内容，一个是 `Pixelate` 也就是 像素化，一个是 `Depixelate` 也就是 去像素化。 Pixelate info\n下面有些文献我还没有阅读，仅供参考哈！只有部分工作用到了深度学习，这里我就不加区分了。 另外我也就不加项目和论文的区分了哈，都放一起说了，论文会加书名号 《Automatic portrait image pixelization》 [pdf]\n这是 2021 年的一篇文章， 其实是有丢失一些信息的啦，只用了图像处理，是用 MATLAB 实现的，可惜好像是没有公开代码，不过看起来是没有太复杂\n《Pixelated image abstraction》 [pdf]\n看起来效果挺不错的，2012 年的一篇文章，但这个其实是没有用到深度学习了\npixel_character_generator [code]\n用 DCGAN、Conditional DCGAN、DC AutoEncoder 来做的角色生成，只能说是不太理想\nMake Pixel Art in Seconds with Machine Learning [url]\n这个是用 CycleGAN 做的，其实效果还 ok 啦，这里说用卡通图进行训练要比真实场景的图片效果好，也确实卡通图的 domain 会和像素画比较接近了 这里顺手贴一个 cartoonset\npixel-me [blog] [demo]\n这个结果确实很 awesome，但感觉主要是针对人脸，对其他 domain 的图片效果就比较一般了，虽然没有论文和代码，但是应该是先去背景，用 Pix2pix 生成，最后补上了描边\n《Deep Unsupervised Pixelization》 [pdf] [sup] [code]\n这居然是发在 SIGGRAPH Asia 2018 的工作，np。通过无监督方法做的像素化，具体我还没研究。\neBoyGAN [code] [colab]\n作者就是通过 StyleGAN，用上面提到的 eBoy 上的数据进行训练的，有 pre-trained 模型在 colab，但是好像是不能运行了\nDepixelate 去像素画的工作其实有很多啊，但是绝大部分工作其实都不是用深度学习来完成的，也没有太好的整理\n《MMPX Style-Preserving Pixel Art Magnification》 [page] [pdf]\n还提供了一个 Web 工具，有多种算法的实现和对比 [url] 这里有我自己的一个 实现，但说实话我感觉其实效果一般，可能还不如 xBR2X\n《Geometric Total Variation for Image Vectorization, Zooming and Pixel Art Depixelizing》 [pdf] demo [code]\n也是没有用深度学习，直接图像矢量化了 np，可能大家都觉得从像素画到正常的图形应该不用深度学习吧 hhh\ninfo\n这两篇文章里面提供的几个算法都是可以参考的 Other Works 《Towards Machine-Learning Assisted Asset Generation for Games: A Study on Pixel Art Sprite Sheets》 [pdf] [blog]\n这个工作主要是用 Pix2pix 给像素画上色，提供了一个不错的思路，主要是先搞定明暗关系，再给角色语义分割一下，最后生成各种颜色的角色（很适合做 NFT hhhh）。可惜代码没开源、数据集未公开。\n绘制工具 像素画的绘制工具可太多了，这玩意毕竟是其他图片编辑器的降维打击，除了传统图片编辑器基本都支持像素画以外，目前比较专业的也是用的人最多的就是 aseprite.\naseprite: https://github.com/aseprite/aseprite\n这玩意虽然开源，但是需要自行编译，或者去 steam 上购买\nLibreSprite: https://github.com/LibreSprite/LibreSprite\n这个用了 aseprite 最后一个 GPLv2 的 commit 衍生出来的，有 release，也不错\n另外的一些项目就太多，还是之前说的，基本实现没什么难度，反复造轮子罢了。\nPixelorama pixel-art-react 结语 现在基于 GAN 的结果，很容易发现的一个现象就是 太脏了，主要是细微噪声太多，这也是最开始说的，像素画虽然抽象，但是每一个像素非常具体，不应该存在色差较小的过渡，细微的色差虽然能够引来色彩的变化，但是他太连续了，看起来也就没了像素画内味 er，基本不会有人承认他是像素画的。而像 pixel-me 这样的优秀项目，除了进行了一些 GAN 上的操作，在 GAN 前和 GAN 后也一定做了一些图像处理，不过他却没 Open Source，确实有点失望，还做了个软件付费:(\n后面有时间我感觉我会试着做一下。\n","permalink":"https://blog.bj-yan.top/p/blog-deep-learning-for-pixel-art/","summary":"\u003cp\u003e因为内容确实不过，搜遍了全网，来做 Deep Learning for Pixel Art 的工作也没多少，肯定是实在是没有市场了吧 hhhh。\u003c/p\u003e\n\u003cp\u003e先说 GitHub 上一堆标着 \u003ccode\u003epixel-art-generator\u003c/code\u003e 或者 \u003ccode\u003eimage-to-pixel\u003c/code\u003e 的，前者大多是随机生成的，无意义的像素块，后者大多是拿 \u003ccode\u003eOpenCV\u003c/code\u003e 或者什么其他的图像处理的库 \u003ccode\u003eresize\u003c/code\u003e 一下就完了，最多能给你加个 \u003ccode\u003efilter\u003c/code\u003e 就不错。\u003c/p\u003e","title":"Deep Learning for Pixel Art"},{"content":"起因是我看到这个名课评价网有一个评论需求，之前用 giscus，所以简单看了一下 mkdocs 的文档就顺手提了个 pr 加了评论系统。有一个想法就是海南大学建一个这样的库，本着互联网开放共享的原则，来共享课程资料。\n于是，有了这个仓库\n稍微修改了一下 GitHub Action 的工作流就可以直接上线了，在几个群里发了信息（还好没收到飞机票）\n截止至 2021-10-28 00:00:00，在网站上线的第一天中，网站获得了 474 的浏览量，获得了 255 个新用户，收获了 8 个 star 和 4 个 fork！！\n感谢在第一天为网站宣传的同学们，网站的发展离不开各位的持续关注！\n希望这个项目能够持续运行下去，估计在选课期间和期末会收到很多流量，但是平日的维护才是网站持续发展的根基。\n","permalink":"https://blog.bj-yan.top/p/blog-hainanu-course-comments/","summary":"\u003cp\u003e起因是我看到这个\u003ca href=\"https://github.com/conanhujinming/comments-for-awesome-courses\"\u003e名课评价网\u003c/a\u003e有一个评论需求，之前用 giscus，所以简单看了一下 mkdocs 的文档就顺手提了个 pr 加了评论系统。有一个想法就是海南大学建一个这样的库，本着互联网开放共享的原则，来共享课程资料。\u003c/p\u003e","title":"海南大学课程攻略共享计划"},{"content":"Preface 今天看了3b1b的线性代数本质，有了很多新的理解，也解释了很多我之前没有想明白的地方（准确的说是为了应付考试死记硬背住的公式），迫不及待的想要写下这篇文章。这里用到的都是一些几何的直观理解，并不涉及到数理证明。\nKnowledge 矩阵乘法 先记录一下里面提到的一些观点，首先向量这个没什么好说的，用向量的变换，引出了矩阵乘法。向量的变换其实也是坐标系的变换，也就是所谓的 linear transform。考虑对一个向量 $\\overrightarrow{v}=[x\\hat{i}, y\\hat{j}]^{T}$ ，施加一个变换 $A=\\begin{bmatrix}a \u0026 c\\\\ b \u0026 d\\end{bmatrix}$，$\\hat{i},\\hat{j}$ 是基向量，作用在 $\\hat{i}$ 上的变换是 $\\begin{bmatrix}a\\\\b\\end{bmatrix}$ ，作用在 $\\hat{j}$ 上的变换是 $\\begin{bmatrix}c\\\\d\\end{bmatrix}$ 。 变换后的坐标是 $\\begin{bmatrix}a \u0026 c\\\\ b \u0026 d\\end{bmatrix}\\begin{bmatrix}x\\\\ y\\end{bmatrix}=x\\begin{bmatrix}a\\\\ b\\end{bmatrix}+y\\begin{bmatrix}c\\\\ d\\end{bmatrix}=\\begin{bmatrix}ax+cy\\\\bx+dy\\end{bmatrix}$ 我的矩阵乘法终于不用再记行列顺序了！\n这个扩展到多维也是一样的，下面考虑多个变换的情况，施加两个变换$A,B$也就是$AB\\overrightarrow{v}$，这其实就相当于了一个复合函数$A(B\\overrightarrow{v})$，先做一次$B$变换再做$A$变换。这个顺序为什么不能变换呢，更直观的理解就是，经过了一次$B$变换，坐标系已经发生了改变，虽然$A$对于坐标的变换没有改变，但是对已经改变过坐标的$B\\overrightarrow{v}$来说，产生的影响是不用与直接作用与$\\overrightarrow{v}$的，这也就解释了矩阵乘法不具有交换性。\n那结合性呢？注意到无论是 $(AB)C\\overrightarrow{v}$ 还是 $A(BC)\\overrightarrow{v}$ 其实都是从右向左结合的，对于前面两个矩阵乘起来的结果其实也是按顺序结合进来的，因此结合律其实是存在的（虽然这里直观的感觉可能有些奇怪，但是确实是这么个变换顺序）。\nIt is my experience that proofs involving matrices can be shortened by 50% if one throws the matrices out. - Emil Artin\n行列式 之前先入为主的学习行列式，都是直接用来解线性方程组的，从来没有想过他的几何意义，这里行列式的几何意义其实是一个“变换”的单位面积改变的倍数，其实也就是改变后的单位面积的“面积”。 这里其实让我卡顿了一下，既然有上面这个说法，那么其实就是$[1,1]^{T}$向量表示的矩阵变换后的面积啊，如果按照这个思路$\\begin{bmatrix}a \u0026 c\\\\b \u0026 d\\end{bmatrix}\\begin{bmatrix}1\\\\1\\end{bmatrix}=\\begin{bmatrix}a+c\\\\b+d\\end{bmatrix}$，那么单位矩阵的面积是$(a+c)(b+d)=ab+ad+bc+cd$，但我们都知道二阶行列式的值应该是$ad-bc$，为什么不一样呢？其实就是“坐标系变了”。$ad-bc$用的坐标系是原坐标系，而$(a+c)(b+d)$用的确实变换后的。 那么行列式有负值？其实就是坐标系发生的翻转，例如平面坐标系$x$到了$y$的逆时针方向 90°，或者$xyz$坐标系从右手系变成了左手系，者都会产生负值的行列式。 对于多维来讲，固定其他维变换两维会让其变成负数，再变换另一维则成正数，再变换另一维成负数\u0026hellip;一次类推，但这个似乎已经不能用几何证明了呢，毕竟人的大脑难以想象到高维空间。\n如果一个变换的行列式变成了 0？单位面积变成 0，那其实就是被降维打击了，变换成了一个直线，也就是这个变换并不是列向量线性无关的。\n同时 3b1b 留了一个思考题$\\det(M_1M_2)?=\\det(M_1)\\det(M_2)$，结果当然是等于，3b1b 没有给出几何上的理解，我是这么理解的，这其实就是一个乘法。先看右边，按照从右向左结合的顺序，先把原单位矩阵变成$\\det(M_2)$倍，再用$M_1$变换变换成$\\det(M_1)$倍，得到了最后的单位面积。就是依次做了两个变换，每次变换结束后重新整理坐标，再进行下一次变换。而等式左边的，相当于把两次变换一起做了，直接变成了$\\det(M_1)\\det(M_2)$倍，也就有了$\\det(M_1M_2)=\\det(M_1)\\det(M_2)$。\n逆矩阵 \u0026amp; 秩 逆矩阵，也就是逆“变换”，其实说到这里，所有的矩阵都可以换成“变换”两个字，因为这里涉及到的其实都是坐标系的变换，也就是线性变换 linear transform。之前忘说的一点是，linear transform 带来的坐标系变换的结果都是线性的，也就是坐标系都是“直的”，且必须“平行”，同时还是“等距”的，因为如果不满足，原坐标系的一条直线，不再是直线，那么这将不再是线性变换。\n作为逆变换，写作$A^{-1}$，一个变换再变换回去其实就是$A^{-1}A$（这是不是能解释为什么每次都是把$A^{-1}$写在左边？因为都是从右开始结合的）。一个方程$Ax=v$的求解，其实就是找到一个变换，将$v$变换成$x$，注意不是$x$变换成$v$，因为$x$才是未知量，这其实就是$A^{-1}Ax=A^{-1}v$，解就是$x=A^{-1}v$。\n如果$\\det(A)=0$，那么被降维打击的变换，永远无法恢复到变换前这就相当于你永远无法从两条平行的直线向量，找到一个面，也就不存在逆了，但是却存在无数解。\n经过变换，压缩成的最小维度，也就是秩。这里是由每个列向量的变换得到的，也就是得到的列空间。\n无论经过什么样的变换，$\\begin{bmatrix}0\\\\0\\end{bmatrix}$ 这个向量一定呆在原点不同。一个满秩的矩阵，只有$[0,0]^{T}$向量保持在原点，而非满秩的矩阵，会有一系列向量经过压缩，到了$[0,0]^{T}$向量，这些就是“零空间”（null space）或者“核”（kernal）。 非方阵 考虑“列空间”，其实左乘一个非方阵其实就是做投影，如果是左乘一个$3\\times 2$的方阵，那其实就是将二维的平面翻转变换投影到三维空间中。\n点积本身就有几何意义，其实也可以看成上述的投影，投影到一维空间向量中去。\nMore thing 来想一下矩阵中其他的式子。\n$(AB)^{-1}=B^{-1}A^{-1}$ .\n从右往左，先结合$B$变换再结合$A$变换 的逆变换，想把这个过程变回去，要考虑坐标系不动，所以要先作$A$变换的逆变换再做$B$变换的逆变换才可以。\n","permalink":"https://blog.bj-yan.top/p/blog-linear-algerbra-ng/","summary":"\u003ch2 id=\"preface\"\u003ePreface\u003c/h2\u003e\n\u003cp\u003e今天看了\u003ca href=\"https://space.bilibili.com/88461692\"\u003e3b1b\u003c/a\u003e的\u003ca href=\"https://space.bilibili.com/88461692/channel/detail?cid=9450\"\u003e线性代数本质\u003c/a\u003e，有了很多新的理解，也解释了很多我之前没有想明白的地方（准确的说是为了应付考试死记硬背住的公式），迫不及待的想要写下这篇文章。这里用到的都是一些几何的直观理解，并不涉及到数理证明。\u003c/p\u003e\n\u003ch2 id=\"knowledge\"\u003eKnowledge\u003c/h2\u003e\n\u003ch3 id=\"矩阵乘法\"\u003e矩阵乘法\u003c/h3\u003e\n\u003cdiv class=\"has-mathjax\"\u003e\n\n\n先记录一下里面提到的一些观点，首先向量这个没什么好说的，用向量的变换，引出了矩阵乘法。向量的变换其实也是坐标系的变换，也就是所谓的 linear transform。考虑对一个向量 $\\overrightarrow{v}=[x\\hat{i}, y\\hat{j}]^{T}$ ，施加一个变换 $A=\\begin{bmatrix}a \u0026 c\\\\ b \u0026 d\\end{bmatrix}$，$\\hat{i},\\hat{j}$ 是基向量，作用在 $\\hat{i}$ 上的变换是 $\\begin{bmatrix}a\\\\b\\end{bmatrix}$ ，作用在 $\\hat{j}$ 上的变换是 $\\begin{bmatrix}c\\\\d\\end{bmatrix}$ 。\n变换后的坐标是 $\\begin{bmatrix}a \u0026 c\\\\ b \u0026 d\\end{bmatrix}\\begin{bmatrix}x\\\\ y\\end{bmatrix}=x\\begin{bmatrix}a\\\\ b\\end{bmatrix}+y\\begin{bmatrix}c\\\\ d\\end{bmatrix}=\\begin{bmatrix}ax+cy\\\\bx+dy\\end{bmatrix}$\n\n\n\u003c/div\u003e\n\u003cblockquote\u003e\n\u003cp\u003e我的矩阵乘法终于不用再记行列顺序了！\u003c/p\u003e","title":"格物致知 - 线性代数"},{"content":" The essence of the world is mathematics.\n“圆规”自从登陆海南以后减弱了不少，外面也不是疯狂狂风大作了，应该已经度过了最猛烈的阶段了吧。\n前几天去图书馆，发现图书馆果然买了许多新书，不知道是不是我建议的 233（记得之前图书馆反馈的时候我好像是填过这个问题）\n最近也看了一些优化一类的书，顺便重新复习了一下 SGD，之前都是看书，很简单就过了，但当我手推的时候，发现还是有些不理解，原因是我没有系统的学过矩阵微分，很多情况下并不能理解推导过程，只是单纯套公式，因此最近计划看一下Matrix Cookbook!\n","permalink":"https://blog.bj-yan.top/p/misc-20211013/","summary":"\u003cblockquote\u003e\n\u003cp\u003eThe essence of the world is mathematics.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e“圆规”自从登陆海南以后减弱了不少，外面也不是疯狂狂风大作了，应该已经度过了最猛烈的阶段了吧。\u003c/p\u003e\n\u003cp\u003e前几天去图书馆，发现图书馆果然买了许多新书，不知道是不是我建议的 233（记得之前图书馆反馈的时候我好像是填过这个问题）\u003c/p\u003e","title":"世界的本质是数学"},{"content":"确实是我到 21 岁以来第一次打 120 和第一次坐救护车，之前我长辈生病时都不是我做的救护车，也不是我拨打的 120，可能也不是我最先知道的。\n这次与众不同的是，室友出的状况，拨打了 120 以后先问的就是地址，然后病人情况，最后居然还问了疫情相关的情况 - -\u0026hellip;\n室友估计就是肺部受了点伤，然后呼吸不畅。结果因为紧张，越来越严重，大口张嘴呼吸以后，开始出现了麻痹，从面部到，四肢末端，在到四肢。当时他已经一身冷汗，喘不上气的感觉了，说了一句“小冰，我感觉我不行了。”，然后就开始喘。他是没有什么病史的，单纯因为体测，估计是 1000 米没喘上气或者有肺泡破裂之类的吧，总之一直在拖，拖到了 6 号，终于，不舒服了，回了宿舍，好歹宿舍里还有我这个闲人 233。\n等救护车来，指引了一下怎么走，到了以后其实并无大碍，就是因为张嘴的大口喘气，如果换成用鼻子深呼吸会好很多。去医院的路上正好还遇到了一起校内的小车祸，有人受了伤，顺便救治了一下，这也是我第一次坐救护车了 - -，最后收了 115。\n没啥大碍就好，这个事情告诉我们，有病早治，有不舒服就及时就医吧，以免拖到后面真出现问题 - -。\n","permalink":"https://blog.bj-yan.top/p/misc-20211006/","summary":"\u003cp\u003e确实是我到 21 岁以来第一次打 120 和第一次坐救护车，之前我长辈生病时都不是我做的救护车，也不是我拨打的 120，可能也不是我最先知道的。\u003c/p\u003e\n\u003cp\u003e这次与众不同的是，室友出的状况，拨打了 120 以后先问的就是地址，然后病人情况，最后居然还问了疫情相关的情况 - -\u0026hellip;\u003c/p\u003e","title":"第一次打 120 \u0026 第一次坐救护车"},{"content":"序 20210930，终于，悬着的心放下了。\n虽然早已知道一切是板上钉钉的事情了，但是只有等到在系统中点击接受的那一刻，才感觉是一切尘埃落地。\n这已经是我大学生活的第四个年头了，从当初那个，自闭内向，不善言谈的高中生，逐渐成长为如今的我。\n直到现在，感觉自己的付出，终于得到了相应的收获，才觉得，一切是值得。\n大学以前 我是山东学子，我可以说我文化课一直不算太好，远赶不上前面的同学。初中凭着“聪明劲 er”在班里一直前 3 左右吧，后面也不是很稳定，中考成功进到了胜利第一中学，算是当时的大成功了 233（对了，顺便说一嘴，“北屿”这个称呼便是初中时候起的，还有个小伙伴叫“南岛”）\n然而，人外有人，山外有山，初中的优势早已荡然无存，不得不说，各地的教育水平确实是存在较大差异的，就像有些“授之以鱼”，而有些“授之以渔”如此。\n高中，我最幸运的事情就是参加了信息学竞赛。说来也巧，当时初中学了两天信息竞赛的我，也敢去胜利一中考自主招生，当时自己凭着一股劲儿，看完了谭浩强的《C 语言程序设计》，当时感觉看完就算成功。当然，自主招生或者说竞赛并不考这些基础的语法，算法对当时的我来说算是一窍不通，甚至可以说是听都没听说过。结果当然也可想而知，至今一直觉得自己是真的敢。\n但是，这也算是机缘，成功在信息组留下了名字，这也成了我进入信息组的契机。胜利一中的传统是交材料时会让你填一下感兴趣的方向（具体是怎么个方式我也记不太清了），如果你的排名比较靠前，会打电话询问是否愿意参加竞赛培训，也就是高中开学前的暑假了。我当时的中考成绩，并不算是非常好，但是之前留下的名字起了作用。我妈并没有收到短信通知（因为当时我也没手机，当然留的联系方式都是家长的），但是有个其他的家长认识我妈，在群中看到了名单，说上面有我的名字并告知了我妈（说来惭愧，我已经记不得这位家长是谁了）。我妈当即决定带我去参加，我至今仍不知道我妈当时为何如此强硬的让我去（至少从后面来看我妈都是非常在意我的意见的），拿上被子第二天就直接去报道了。当时，刚中考完准备放松摆烂的我其实是非常不情愿的，或许也是因为之前顺从习惯了，还是过去了，当时我妈到了学校跟竞赛负责的老师（老李）交谈，说没有收到短信，但是名单上有我，交谈的内容我也没这么听见，我当时好像是站在旁边，希望得到老师说没有我可以回去。但是过了一会，就让我上楼了，就是老一中进门右侧的楼，现在我也不记得叫什么名字，而且也已经不存在了（老一中拆了）。\n那是另一个世界，在暑假的培训期间，我算是真正接触到了算法、竞赛。才知道原来一中初中就有那么多同学参加了竞赛，也才知道有个东西叫信息学奥赛，有个比赛叫 NOI(P)。因为我家并不在东营，自然而然就需要住宿，和同为住宿的同学一起建立了革命友谊。\n或许是看到了我的小“天赋”，在暑假结束的一批筛选中我通过了，成功翘掉了军训（继续参加培训，不过我们初中也军训过一次），错失了和班级同学接触的大好时机（虽然在这以后就感觉自己像是一个“编译原理人”）。\n但是我的竞赛之路其实并不顺畅，有些内容甚至不想再去回忆。这里简单的记一下，如果以后想起来什么便会回来补充。\n第一年，平时周末参加培训，其余时间正常上课，NOIP 省二。\n第二年，几乎是除了主科都在竞赛，NOIP 省一，APIO 银牌，CTSC 铜牌，省选一轮惨挂（如果我没记错，我因为两个小失误失掉了近 200 分，回去稍作修改便通过了），二轮翻盘失败（一轮二轮期间自己心态确实很崩溃，无心做题），退役。\n第三年，竞赛退役回来补文化课，参加高考，参加自主招生，山东大学-20，天津大学-60，高考 582，全省排名大概 3w，无缘，裸分上了海南大学。\n说自己心无不甘肯定是假的，我的竞赛成绩没有给我带来任何的加成，看起来反而成了累赘。\n后面，很多人问我，是否后悔参加竞赛，因为不参加竞赛，全心参加文化课，我的成绩肯定不止于此。\n然而我的答案却从来没有变过，“不后悔，我热爱它。”\n如果没有竞赛，我不知道怎么度过高中三年，除了读书、学习就是读书、学习。\n这绝对是我这一生最珍贵的财富，甚至可以说是没有之一，就算是算及结果，答案也是一样。这样一个从小从小镇长大的人，接触到了更广阔的世界，认识到了厉害的人，知道了厉害的人的努力，也认识到了天赋和悟性上的差距，对自己更全面的认识有时候比任何事更重要。也是同时，我感受到了 gap，不仅是天赋上的，更是环境、认知上的 gap。\n这一路，认识的人，好或不好，心存感激。\n但是，对于自己的故乡，山东，虽不该如此，但是我确实不喜欢。高考拼命的想出去，大抵也是这个原因，我想去南方，高考志愿中大概也只是填了山东大学看看能不能冲，填了青岛大学保底，除此之外，均是南方学校。最后的结果也是 211，海南大学。\n海南大学 初遇 海南大学，末流 211，为什么能评上 211，可能知道的大概都知道。\n刚来海南大学，看到破败的宿舍楼，破烂的宿舍，门把手、床边都是一片锈迹（虽然后面才知道我们这宿舍楼竟称为“太子楼”，因为可以说是海大最好的男宿了，4 人间，独卫，非常感谢我们当时的辅导员的手气！！再后面，比较了其他学校的宿舍，更发现了我们这还是肥肠爽的，毕竟空间也大，一人一个上床下桌），但是我从来没有想过复读，我不想再回去，再去学那无聊的文化课，自己就抱着随遇而安的心态，来到了这里。\n但是呆久了，我竟然喜欢上了这里，大概是喜欢这里的——“惬意”。现在谁说海南大学不好，我绝对第一个跳出来反对！\n大学，一群来自八方的朋友，汇聚于此。庆幸大学与我一起生活的三位舍友的互相体谅，我们的宿舍关系也没有出过什么问题，大家都比较大度，I love you, hhh.\n说来惭愧，我刚来海大的时候，也确实抱着很不爽的心理，甚至觉得这里配不上自己，也至于说出了很多不好的话。但是，有一点可以说明的是，山东考生来海大，其实分数都挺高的，相较于其他省份。尤其是在山东全是全国一，其他省份全国二全国三，而分数线差不多的时候。\n大一的我，没什么面试经验的我，甚至说很内向的我，还是报了很多学生组织，包括校青协、校团、院团、院青协还有很多我忘记了，但当时忘记了，而不是现在忘记了，这也导致了很多有趣的事。\n因为我虽然什么也不知道，前路未卜，因为我其实是我们家第一个大学生，没有任何经验可以从家里告诉我，有些甚至是错的（道听途说罢了，和简单的从众）。但是，我唯一知道的是，大学是我新生活的开始，我也从内心的想要改变自己。也是我这种敢于参加，敢于尝试的想法让我有了一些机遇吧。\n内向且没什么经验的我，结局可想而知了。有时候参加面试的时候，就单单收到了面试地点时间信息，有时候还把面试的组织搞混了\u0026hellip;自我介绍也没怎么准备，让我现在再面当时的我，我可能也留不下什么印象，就是给人留不下印象的那种 hhh。啊对，还有时候，是真的，不知道，自己，到底，填的，是，哪个，部门，哈哈哈哈哈哈哈哈哈。但是还好的是，我的院青协的部长们，不看重你吹的怎么样，更看重你的性格品格，于是我成功加入了院青协。当时知道原来还有校青协，瞬间感觉自己 level 低了不少，但是后来，知道了校青协的工作量，看着校青协的室友这种忙，最后学生组织加分居然是一样的，自己居然还有些庆幸 hhhh。\n在一年参加志愿活动，出推文，拍照片的过程中，也算是知道和掌握了一些做事能力。可能是自己在这一年过得还挺愉快，最后在部长的劝说下，选择了留任（或许是觉得我比较靠谱，因为我们部门其他人也有参加留任的考核，最后还是选了我）。\n可以说，自己强行没让自己大一闲着，没事就找事做，另一个契机，也是发生在这一年。\n当时在大一学期要结束时，我们换了一个辅导员，新来的辅导员选了一个什么对科研感兴趣的同学，当时辅导员在国重那边，我自然也是参加了进去，在我们班长的推荐下当上了什么什么科研负责人（完全记不得了），至于为什么推荐？大概是因为大一学院有一个叫 IT 文化节的东西，有编程比赛，我凭借高中学的拿点算法知识，轻松 AK，也轻松血虐了大二大三的其他选手 hhhh（不过说实话，那个比赛的题目难度，也就是 NOIP Day1T1 或者 Day2T1 的难度吧，大部分还是编程能力题，能看懂题目就能做出来，而且没有任何评测系统，评测靠人，你说你做完了然后有人拿着测试样例过来，答案都正确，给你记分记时间）。从此大家都觉得我比较厉害，尤其是编程（谁说竞赛没有用的 x）。\n另外，补充一下，当时开学的时候我也曾想参加 ACM，但是经过询问学长，甚至都不知道 ACM 是什么，便作罢。海南大学确实没有搞 ACM 的，一个是因为交通不便吧，因为各个城市跑，没有高铁，只能飞机，成本还是很高的，另一个我猜是，同学们的起步就比较晚吧，而且没有什么人组织，没有人能够让你开学前拉过来集训上一个暑假。不过，如今，机器人与人工智能协会有一个 ACM 小组，这也是后话了。\n说回来，我也不知道当时进了实验室在干嘛，平时就是自己值值班，值班也就是搬着电脑坐过去，上自习罢了。不过当时有个做网安的学长，做了点培训，学了一点 ESP8266[1, 2, 3]和Arduino那些，还挺好玩的 233，后面他们搞了第一届HDCTF，我也是第一次接触 CTF，凭借高中竞赛的那点数论知识[1, 2]，能看懂和推一下 RSA 那些，然后之前做过 Nazo，那些 web 的题有些就轻松解了，当时还自己刻意学了HTML和JavaScript那些内容，其他是真的不太会。最后拿了三等奖？忘记了，但是记得颁奖的是我们班主任，奖励是一个手环。此后，我试图参加 CTF，感觉肥肠有意思，主要是感觉好玩，后面学长邀请我做网络空间安全协会的副会长，我也欣然同意了（虽然自己出了吃了个饭，也一直在划水，事情能推就推，说来惭愧）。后面也因为一些事没有继续参加 CTF，也便是我说契机。\n想了想，还是不说真名了吧，当时在实验室认识了 HY 同学，然后把我推荐给了 BY，得知 BY 已经海大毕业（甚至当时军训时在思源学堂放过年度人物的录像就有他），还有他的 RA-Team。这算是另一个巧合吧，如果当时我没参加 IT 文化节，我当时没参加辅导员的组，我班长也不会推荐我做 xx 负责人，也不会认识 HY，也就无从认识 BY。\n那时候，BY 问了我几个简单的问题，比如会什么，之类的，做了个简单的了解。然后后面，我就跟着稀里糊涂的参加了我第一个创新创业类比赛（海南省人工智能创意赛），我是负责讲 PPT 的，我不需要答辩，就背稿讲 PPT 即可，也认识了一起参加比赛的 XM 和 LZ 学长。结果还不错，大概是一等奖。\n这段故事，算是正式开始。\n忙碌 也是从那时起，我才知道了创新创业比赛这回事，也才了解了推免这个事。虽然我之前没有刻意提高绩点，但是出于从小到大的刻板印象，还是希望自己成绩好，期末复习期间还是肥肠努力的。大一的绩点也是我整个大学绩点的巅峰了，大概 3.73 的样子。在 6-7 月份，大部分的比赛也都结束了，要想参加就得再等一年了。\n在暑假期间，有两件事，一个是 BY 安排让我学习机器学习的知识，我便跟着李宏毅老师的机器学习视频进行学习，那时候应该看的是 2016 年版的，该学的也差不多都学了，和 BY 提交学习笔记，两篇关于机器学习笔记博客[1, 2]也是当时写下的。高中其实还是接触过一些 Python 的，不过编程语言这东西也从来不是障碍。当时 BY 还布置了几个小项目，其中就包含树莓派做 MNIST，也是第一次遇到好吃的树莓派呢。我自己做的第一个小项目，就是用树莓派做火焰识别，当时就用 Keras 的 CNN，自己也不懂什么 VGG 之类的，就直接上 CNN 的。当时也不懂什么目标检测，就知道判断有没有火焰就完了。曾经有想用这个发 paper，做传感器和视觉融合的判断，但是苦于没有数据，很难过。当时也不知道什么叫多模态之类的，就一个 basic 的 idea，这个其实后面也参加了几个小比赛，也作为机器学习组的开篇项目了。\n在暑假的另一件事，虽然我怎么参与，但是后面的影响确实巨大的。便是成立了海南大学机器人与人工智能协会。\n大二开学，一切进入正规，开学最忙的便是迎新和招新了（不要忘了我留任了，院青协新闻宣传部部长，当然我也作为了网络空间安全协会的副会长也要招新，作为机器人与人工智能的创始人，也要招新，作为机器学习组组长也要招新\u0026hellip;协会的招新，也是招到了协会第一批干事和部长），我也在这看到了有趣的学弟学妹们，因为上学期也基本没什么比赛，除了开学那段时间，一切平稳且平稳。\n刚开学没多久，和 CJ 和 XM 去西安参加了第三届丝绸之路机器人创意赛，几乎去了就有奖，除了后面几名是二等奖，其他一等奖和特等奖，也是见了那些比较厉害的项目，最后拿了一等奖，也赚了一趟西安的公费旅行。\n也是在大二上学期快结束时，BY 告诉了我 FL 这个新领域，还有很多问题未解决，其中激励机制便是重要的一点，这也是后面的引子了。\n接着，是让人意想不到的疫情。\n这场前所未有的疫情，打乱了所有人的节奏，所有城市都静止了。不过说来幸运也是可笑，东营从来没有任何一例疫情，大概是东营位于所有交通路线的终点吧，人流本来就不算大，管控也比较好。\n疫情是煎熬的，却也是机遇。毕竟我的两篇 paper 的工作都与疫情相关，这也是为后面比赛埋下伏笔了。\n海南大学算是比较敢的了，5 月份疫情得到有效的控制便开学了。原以为比赛会因为疫情推迟，却并没有。匆忙的通知，仓促的准备。我当时不知道为什么的，接下了无人车的项目，疫情期间做的 FL 做肺炎识别的项目交给了 YZ 来做。结果是，都不好，协会的另几个项目倒是奖拿到手软。后面反思一下原因，确实是自己没什么经验，做的也不好，尤其是不懂评审规则，不会包装（其实自从那开始，自己也对这类比赛有些反感了，也不算是自己真正感兴趣的东西）。\n但是无心插柳柳成荫，肺炎识别的项目在 C4-AI 的华南赛区获得二等奖，成功晋级了全国总决赛。\n也是在这个学期末，我知道了数学建模比赛，之前其实自己也知道了数学竞赛，但是自己实在是忙不来复习高数那些东西了，也便作罢。当即决定暑假留校参加数学建模的培训，但其实自己上了没两天就自己在宿舍学了，一个是觉得老师讲的有点慢，而且是大教室还得去抢位置，另一个是自己不太习惯听课这个选项了，自己也完全能自学。就拿着那个姜启源的《数学模型》在宿舍看了，虽然也就看了个大概。（说句实话，我觉得就算看完了也没什么用，最重要的还是要做作业，通过这种方式学习各种模型，因为数学建模算是开卷答题了，建模思路是最要的，而且不要眼高手低，当你去做、去建模才能发现一些细节问题）\n大二，也就此草草结束了。\n迷茫 大三一开学最重要的便是数学建模了，当时和 XM 和 WJ 组队，肝了 3 天。简单说一下吧，当时我们第一天拿到题，第一天晚上要解决的便是选题，A 题是个物理题，我们这几个人一看就算了，我题目都没读。第二题是个算法题，应该是 NP-Hard，反正就是各种随机算法乱搞感觉就能做，有个更靠谱的方法就是 RL，感觉 RL 能乱草，但是这个 env 也太难了，这也就成了编程能力题。虽然知道 RL 能做，但是当时我对 RL 的了解，也仅限于李宏毅老师的视频里的了，而且也是仅仅涉猎罢了，也没自己动手做过。队友也不能在编程方面帮助我，本来我就是主要负责编程的部分，XM 负责论文主笔，WJ 会一些 SPSS、MATLAB 还有一些数学模型啥的（感觉模型比我知道的要多一些，可能上过培训课多一些）。但是拿 RL 做也绝对是个创新了，很容易拿奖。C 是一个数据处理题，比较传统。于是就在 B 和 C 之间纠结，最后决定让我回去试试先，明早再决定。于是我晚上回去 code 了一下，再复习了一下 RL，感觉差不多能行，第二天一早过去决定，我这边搞 RL。因为第一问可以完全不用 RL，最短路即可，本来是交个一个队友搞定，我搞定 RL 做后面几问，另一个开始论文。写了大概 2h，那边做第一问的同学没什么思路，我觉得这不是 C 随便写一下就完了吗，转头我写第一问，这样一下来，就闲下来一个人。最后在 9 点多做了个决定，选 C 来做。选 C 的问题就在于创新点难找了，但是 C 都是数据处理，我拿 Jupyter Notebook，然后用 pandas 什么的乱搞一下，不过还好之前相关性分析在作业里做过（是一个分析地球表面气温的题，应该是前几年的一道原题），数据处理基本没遇到什么困难，甚至还拿 ML 做了一下分类，主要的分类模型还是决策树（毕竟效果好）。在最后一个晚上有一问的做法好像出了很大问题，想了挺久解决办法的，然后那晚上大概只睡了 3 个小时吧。一晚上赶的差不多，中午稍微回去休息了 2h，下午回来补充和润色了一下论文，把最后数据和答案整理了一下，但是临到提交的时候才发现，之前交给一个队友的数据更改并没有动，不知道什么情况，让他匆忙进行修改，但是可以明显感觉到，不，可以说是看到，他手抖得厉害，然后我把这部分搞定了，几乎卡点完成验证，然后就等待提交了。这个比赛算是结束了，值得一说的是当时我们在思源做，但是思源大部分都在自习，为了不打扰到了隔壁没有空调也没有人自习的地方做数学建模，我都已经湿透了，队友已成佛 hhh，只能说适应了已经。只有在最后一晚，等别人都走了，我们才搬去有空调的地方呆了一晚上，第二天一早又搬回来。\n最后的结果却是喜人的，国二，省一。\n然后又是，一如往常的招新，其他的事情有些记不得了，反正是一些乱七八糟的小事，同时专业课也多了，课业也给我带来了挺多压力的，我的精力也有所分散，期末复习也没之前那样认真了，还是一天复习一科，佛系考试。\n对了，当然还有之前说到的国赛，一趟去杭州的公费旅游，只拿了个国三（x，不过也是发现了项目的很多问题。只是输的有点不甘心，因为评委上来问了一个“你们知道什么是智慧医疗吗？”，确实给人问蒙了，这个问题确实是意想不到了，觉得我们项目起名太大，着脚点太小，工作太少。同时，这个比赛的另一个影响就是当时比赛完回来第二天就是六级考试，我相当于纯裸考去了，结果也是可想而知，但是影响却是很大的，这毕竟是推免前的最后一考了。\n还有个比赛就是天梯赛了，在 RK 的搭线下组成了银河战舰，妥妥的省特，我自己拿了个人国二，也是今年刚知道有这个比赛，不然我大一肯定参加了（只是不知道有没有人愿意带我就是了）。\n另一个小比赛就是创客马拉松了，也是自己做了全栈的内容，包括标记数据，做的是凌空画笔([code], [demo])，拿了校一，也是刚接触了目标检测这个领域。\n到了大三的下学期，之前的两个没出成果的项目还是继续了，我做了 FL 肺炎检测的负责人，学校也是在骆校来了以后成立了生物医学工程学院，正好和这个项目比较 match，便找了那个学院的老师做指导，当然项目负责人是我，项目所属应该是生物医学工程学院，我却不是生物医学工程学院的，所以只能说我们学院亏了（x\n在 ZW 的帮助下，完成了这个项目的润色，但是首战折戟，挑战杯校一，却是省三。后面我作为项目负责人确实有些不负责，大部分的任务都是交给 ZW 和 ZC、SY 做的。\n也是这时候，因为自己的成绩逐年下滑，已经到了 rk11，感觉推免无望或者说很悬（因为我们学校政策是奖项论文加分最多 0.3，我随随便便就能加满，前面应该会有加不满的，按照往年 5% 的推免率，应该需要 rk9，感觉还是有点机会，但是又没那么有机会，就是边缘人的纠结懂吧），于是决定申请港校，父母也是很支持，所以开始学雅思，看了很多知乎的文章，大部分都是营销文，建议大家不要看，参考意义实在是不大，毕竟每个人的基础和悟性也是不同的，当时自己就单单自学，随随便便做做单词背题，因为临近期末的时候复习，忘记了报名暑假的第一次的雅思考试，g，于是只得 7 月底才能考试。\n在此期间，联系了一个港校的 W 老师，进行了简单的面试和 presentation，因为自己也没啥经验，不知道申请面试面什么，结果问的线代、高数和概率是一塌糊涂，自己都觉得不好意思，最后也没拿到 offer，不过问了一下老师有没有机会做一些项目或者什么工作，主要也是想有些成果发 paper，老师给了一个项目做，这也是暑假我除了雅思外的主要工作了。\n欣喜 暑期的雅思怎么样？考了一次便安心找了个班报名学习了，也是不是很理想，不过也是文条不紊进行。\n大四一开学，便是推免了，抱着侥幸心理的我肯定还是要交一下材料的。当时很多港校开始了提前批的申请，因为港校是要先提交语言成绩再申请的，而且先到先得，一直没有语言成绩的我，可以说是很慌了。另外，在上学期末，我也是试着有了几个学校的夏令营，可惜一个都没有入营，我想原因有几点：1. 我没过六级，这个在推免中还是很重要的，不管多少分，至少应该过。 2. bar 太高，卡本科学校的我也是没什么办法。不过庆幸的是，上学期的六级我 478 过了，推免也是用上那次考试的成绩。\n最后，我看到大部分人都能加满 0.3 的时候表示很慌。不过综合成绩出来，我 rk8，可以说是很有机会了，于是匆匆联系老师，确实也打扰到了很多老师，报名各种学校的预推免。因为有了六级成绩，过程显然顺利了许多，最后推免名额出来，名额增加了不少，11 个，妥妥的。\n大概在 9.13 晚，我接到了计算所的一个实验室的电话，不过不是我报名的实验室，问我愿不愿意去，可能有笔试和面试，具体明天通知。当然是欣然答应了，第二天，收到了我报名的实验室的面试通知，却不是之前那个，就开始准备做核酸和去面试了，因为之前那个电话，让我以为一直有笔试，所以也是很慌，提前了一天到。本就想定一个离计算所近的宾馆，最后订到了计算所对面的宾馆\u0026hellip;这也太近了\u0026hellip;但你也可以想到因为这个，宾馆等房费几乎翻倍了，印象中是 300+ 一晚。\n然而自己后续并没有收到笔试通知，很懵。参加了实验室面试就结束了，面试过程还算顺利，一开始让自我介绍，我看了很多某乎上的面经，都说要英文介绍然后简单英文问题，再专业问题，再项目问题。然而去了，老师就说自我介绍一下，先前准备的英文自我介绍也没好意思拿出来，照着英文又翻译回中文了\u0026hellip;然后匆忙看的专业问题也没有问到，就照简历问了些问题。\n三个插曲，收到计算所面试通知之前其实就接到了一个电话面，可以算是让我大概了解了我简历上可能的问题，另一个是去计算所面之前联系的 xmu 的一个老师，在计算所面之前的上午面了一下，老师也是比较欢迎，其实我也挺喜欢那个老师的 hhh，也是这些面试经验让我能够在以后的面试中更加冷静和得心应手吧，再另一个就是到了北京还玩了一下午 hhh。吐槽一下北京的 711 居然没有位置吃饭饭\u0026hellip;想想海口的便利店，哪个没有座位啊\u0026hellip;于是就在窗台坐着吃了点。\n面完就去 happy 了，反正中秋基本都放假，也很少学校在这个期间组织预推免，就干脆玩两天再回去继续报名。结果当天晚上，在南锣鼓巷的时候，说来也巧，本来想去的小熊日志，找了半天也没在地图上找到，居然走着走着看到了，刚走进去，就收到了 offer，于是当时我就买下了一个小熊，起名：offer，简称：小 o！后面没什么压力了以后自然玩起来也轻松了许多，晚上回宾馆的路上就找了打印店签了协议。\n后面把所有面试和预推免都推了，和之前联系的老师都说明了情况。\n然后就等着推免系统填报了，一个等待是海南大学的处理，在 25 才上报，26 晚上才能查到推免资格，一个就是报名后等待计算所的录取通知了。\n在等待计算所通知期间，有幸加了绿群，认识了很多名人，比如海洋哥！海洋哥实在是太励志了！当然计算所也是诞生了名场面，漫长的等待总是煎熬的，没有任何通知的两天，也没什么心情做其他的，主要是怕意外。同时，928 以后的各种事件也是让人感慨，前面的人拿了太多的 offer 不放，到最后系统填报才选和放 offer，学校也是疯狂被鸽，只能补录，甚至有的直接鸽穿，准备第二次预推免了。在我眼里，超发 offer 的学校比学生海王还要恶劣。\n学校被鸽了好歹有备选，如果一个学生接了 offer，没有留备选，最后被学校鸽是真的没有后路，只能等捡漏。我觉得在这期间，最重要的其实就是诚实。这里实在忍不住吐槽一下，对于海王们，明知道不会去的学校，为什么不能放一下 offer 呢，让学校提前补录不好吗？对于超发 offer 的学校，我也是没话说\u0026hellip;只能说活该自己名声臭了，这样的恶性循环就是，学生每个都要留好几个 offer（谁知道那个学校鸽，毕竟自己有学上才是最重要的），学校招生的老师只能列一个长长 wl，超发 offer 的学校必然被鸽一大片。真推免还是得看 928，xs。当然，也没法保证每个人不会鸽，每个学校不会鸽人，毕竟学校的协议也只是个废纸罢了。\n感谢计算所收留，推荐大家报名计算所 233，虽然过于稳了点，不过也算是研究生第一课了 hhhh。收到录取通知的时候已经是 9.30 的 23 点多了，当时自己已经在海底捞开吃了 2333\n在等待期间，海大的老师也有给我打电话的，表示如果没录上愿意让我本校读研，也会给予学院最好的师资，表示很感动 555。\n后面 在我大学这四年期间，有两段感情经历，也只会有两段了。\n可能这篇文章没什么图片，如果自己以后想起来再回来补吧，主要是麻烦。\n未了 知道的，不知道的，其实也没那么重要，毕竟一切也都发生了，那就让故事继续好了。\n这个回忆录其实高中就已经想写了，但是一是出于心理的耻（大概是因为结果不好吧），另一是不想回忆（大概是一种逃避心理）。\n这一篇写下来确实有点流水账的意思，但是也不完全是吧，只是想把自己的经验与你分享。\n我可能从来没和除了自己最亲密的人以外分享，现在，多了你。\n不说了，emo 了。这篇文章居然有近一万字了。\n写于二〇二一年十月二日，凌晨四点二十六分。\n致谢 感谢父母的养育之恩，感谢他们没有给我带来来自家庭的压力，让我能够有更多机会寻找自己追求的方向，更想感谢的也是最重要的——尊重我的意见和选择。\n感谢一直陪着我给我鼓励的宝贝。\n感谢一路上老师们的栽培，不管是授课老师、还是我推免或者申请期间联系的老师，和你们相识都是我的财富，而且我很感谢我遇到的老师就是那么的温柔善良。\n感谢祖国和学校给我的良好生活环境。\n感谢 BY 学长的科研启蒙和指导。\n感谢低谷里共勉的朋友们，无论是舍友、还是做项目的朋友们，可能我有时候也不是那么好。\n关于我 留一个联系方式吧，在 About 页面可以找到我的联系方式，也可以在这篇博客下方留言。\n","permalink":"https://blog.bj-yan.top/p/journey-man-man-qiu-xue-lu/","summary":"\u003ch2 id=\"序\"\u003e序\u003c/h2\u003e\n\u003cp\u003e20210930，终于，悬着的心放下了。\u003c/p\u003e\n\u003cp\u003e虽然早已知道一切是板上钉钉的事情了，但是只有等到在系统中点击接受的那一刻，才感觉是一切尘埃落地。\u003c/p\u003e\n\u003cp\u003e这已经是我大学生活的第四个年头了，从当初那个，自闭内向，不善言谈的高中生，逐渐成长为如今的我。\u003c/p\u003e","title":"漫漫求学路"},{"content":"来混混思路，A 题一看就不太可做，物理题；B 题看起来还挺简单的，但是没有细看；C 题好像也不是很难\n所以就主要写写 C 题的思路了，因为毕竟不是自己实际去做，可能会有些细节问题并未考虑完全，仅提供一种可能可行的方案\nC 题 生产企业原材料的订购与运输 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 C 题 生产企业原材料的订购与运输 某建筑和装饰板材的生产企业所用原材料主要是木质纤维和其他植物素纤维材料, 总体可分为 A，B，C 三种类型。该企业每年按 48 周安排生产，需要提前制定 24 周的原 材料订购和转运计划，即根据产能要求确定需要订购的原材料供应商（称为“供应商”） 和相应每周的原材料订购数量（称为“订货量”），确定第三方物流公司（称为“转运 商”）并委托其将供应商每周的原材料供货数量（称为“供货量”）转运到企业仓库。 该企业每周的产能为 2.82 万立方米，每立方米产品需消耗 A 类原材料 0.6 立方米， 或 B 类原材料 0.66 立方米，或 C 类原材料 0.72 立方米。由于原材料的特殊性，供应商 不能保证严格按订货量供货，实际供货量可能多于或少于订货量。为了保证正常生产的 需要，该企业要尽可能保持不少于满足两周生产需求的原材料库存量，为此该企业对供 应商实际提供的原材料总是全部收购。 在实际转运过程中，原材料会有一定的损耗（损耗量占供货量的百分比称为“损耗 率”），转运商实际运送到企业仓库的原材料数量称为“接收量”。每家转运商的运输 能力为 6000 立方米/周。通常情况下，一家供应商每周供应的原材料尽量由一家转运商 运输。 原材料的采购成本直接影响到企业的生产效益，实际中 A 类和 B 类原材料的采购单 价分别比 C 类原材料高 20%和 10%。三类原材料运输和储存的单位费用相同。 附件 1 给出了该企业近 5 年 402 家原材料供应商的订货量和供货量数据。附件 2 给 出了 8 家转运商的运输损耗率数据。请你们团队结合实际情况，对相关数据进行深入分 析，研究下列问题： 1．根据附件 1，对 402 家供应商的供货特征进行量化分析，建立反映保障企业生产 重要性的数学模型，在此基础上确定 50 家最重要的供应商，并在论文中列表给出结果。 2．参考问题 1，该企业应至少选择多少家供应商供应原材料才可能满足生产的需求？ 针对这些供应商，为该企业制定未来 24 周每周最经济的原材料订购方案，并据此制定 损耗最少的转运方案。试对订购方案和转运方案的实施效果进行分析。 3．该企业为了压缩生产成本，现计划尽量多地采购 A 类和尽量少地采购 C 类原材 料，以减少转运及仓储的成本，同时希望转运商的转运损耗率尽量少。请制定新的订购 方案及转运方案，并分析方案的实施效果。 4．该企业通过技术改造已具备了提高产能的潜力。根据现有原材料的供应商和转运 商的实际情况，确定该企业每周的产能可以提高多少，并给出未来 24 周的订购和转运 方案。 注：请将问题 2、问题 3 和问题 4 订购方案的数值结果填入附件 A，转运方案的数 值结果填入附件 B，并作为支撑材料（勿改变文件名）随论文一起提交。 附件 1 的数据说明 （1）企业的订货量：第一列为供应商的名称；第二列为供应商供应原材料的类别； 第三列及以后共 240 列为企业向各供应商每周的订货量（单位：立方米）；数值“0”表 示相应的周（所在列）没有向供应商（所在行）订货。 （2）供应商的供货量：第一列为供应商的名称；第二列为供应商供应原材料的类别； 第三列及以后共 240 列为各供应商每周的供货量（单位：立方米）；数值“0”表示相应 的周（所在列）供应商（所在行）没有供货。 附件 2 的数据说明 第一列为转运商的名称；第二列及以后共 240 列为每周各转运商的运输损耗率（%）， 即 损耗率 = (供货量 - 接收量) / (供货量) X 100%；数值“0”表示没有运送。 问题 1 1．根据附件 1，对 402 家供应商的供货特征进行量化分析，建立反映保障企业生产重要性的数学模型，在此基础上确定 50 家最重要的供应商，并在论文中列表给出结果。\n第一题，显然就是一个评价模型，而且这个结果应该是会在后面反复使用。首先就是确定一下评价指标，比如供货的完成率，总供货量，供货趋势，这些够可以参考，然后用一下灰度预测，或者模糊评价之类的模型设置一下各个指标的权重，要不就去查询一下有没有相关的文章做这方面的评价，最后给出一个排序的表即可。\n问题 2 参考问题 1，该企业应至少选择多少家供应商供应原材料才可能满足生产的需求？针对这些供应商，为该企业制定未来 24 周每周最经济的原材料订购方案，并据此制定损耗最少的转运方案。试对订购方案和转运方案的实施效果进行分析。\n题干中有一个很重要的一个条件为了保证正常生产的需要，该企业要尽可能保持不少于满足两周生产需求的原材料库存量，为此该企业对供应商实际提供的原材料总是全部收购。，在一开始我也没有注意到这个条件，但重新考虑这个条件的时候就有挺大变化。\n在这一问中主要涉及两个问题一个是转运的问题，一个是供应问题。\n先回答一个题干中的问题，这个很简单，但是在解决后续所有问题之前，需要将第一问中得到的 50 个供应商未来的 24 周供货量进行预测，方法也比较多吧，最简单的就是线性回归了。给出来这个以后，按照供货量排序，从大到小求和，直到完成 2 周供应量，这个可遍历，可以二分，反正数据量不太大，遍历一遍就完了。\n最经济的订购方案和转运方案应该是比较独立的两个问题，但是求解有先后顺序，首先得求解转运方案，对每个转运商直接算一个平均的转运损失率感觉就差不多，或者有什么其他的指标计算一下即可，排个序，从上到下选择即可。针对订购方案，就选，完成率高，减去损失率和利用率后的成本最低，优先选那一类原材料，盲猜应该会是 A。\n问题 3 该企业为了压缩生产成本，现计划尽量多地采购 A 类和尽量少地采购 C 类原材料，以减少转运及仓储的成本，同时希望转运商的转运损耗率尽量少。请制定新的订购方案及转运方案，并分析方案的实施效果。\n这是一个优化问题，也比较开放吧感觉，首先得给出一个总成本或者综合成本的计算公式，去用牛顿迭代/线性规划/模拟退火/爬山/蚁群这些优化方法随便搞搞应该就差不多，这个也没个标准答案，当然还是越优越好。\n问题 4 该企业通过技术改造已具备了提高产能的潜力。根据现有原材料的供应商和转运商的实际情况，确定该企业每周的产能可以提高多少，并给出未来 24 周的订购和转运方案。\n产能的提升受两个因素限制，一个是供应的限制，一个是转运的限制，对供应的限制，前几周应该是能运越多越好，为了后面的铺垫，但这个受转运的限制，每周的提升应该就是其他条件拉满，卡到限制上限即可。\n遥想上次参加数学建模的时候还是上次，转眼间物是人非了哇，去年一起参加比赛的学长没有去读研，而是去工作了，另一位同级的同学估计应该保研成功，已经拿着 3 个 Offer 了 orz 自己也从参赛选手变成了可以自由口胡的选手（x\n","permalink":"https://blog.bj-yan.top/p/blog-mum-2021/","summary":"\u003cp\u003e来混混思路，A 题一看就不太可做，物理题；B 题看起来还挺简单的，但是没有细看；C 题好像也不是很难\u003c/p\u003e\n\u003cp\u003e所以就主要写写 C 题的思路了，因为毕竟不是自己实际去做，可能会有些细节问题并未考虑完全，仅提供一种可能可行的方案\u003c/p\u003e","title":"2021 数学建模"},{"content":"Before 本来想早点报 7 月第一场，先考考看摸个底的，结果整好赶上了考试周，错过了报名时间，没办法只能报下一场，也就是这场了\n海南大学是没有机考考点的，所以只能纸笔考试咯，考试地点就在 5 教里面的教学楼\n现在是 13.03，刚考完玩了一局云顶之弈就吃了 md，趁热写写流水账\nSpeaking 我的口语考试时间是 23 日 13:50 的，午饭匆匆吃了一点打印了一下准考证就过去了，到的时候大概 13.10，说实话是非常慌的，心理没个底。\n到了考点以后，就正常的要检查一下通行码、健康码、有没有打疫苗什么的，然后直接把我拉到候考考场了，让把东西放下 - -\n我跟那个小哥说我想再看会手机，他说候考考场不行，我说那我出去？然后我就在外面看起了手机。然鹅里面的候考的老师让我去最头上的候考室，这个候考室是用来拍照和身份核验的，于是就去那边呆了会，到 13.20 多才叫过来。\n身份核验就是让你摘下口罩和眼睛，然后录 4 次指纹（右手食指），然后拍照就等着了，和我一起的还有两个分别是 S1、S2、S3，我是 S1。\n等快到时间了，会有另一个巡考把人带到 4 楼，一个人一个教室，在走之前还会再进行一次身份核验，就是验证一下指纹，摘下眼睛口罩验证一下人。\n到了 4 楼的时候，考官已经站在门口了，我过去就把门带上，把我带到座位上。\n座位是中间用一个透明隔板隔开，估计是为了防控疫情吧，然后就是考试流程了。\nPart1 就简单问了一下全名，有没有带设备，\nPart2 p2 的时候给你一只铅笔，已经在桌子右边摆好了，还有一张纸，可以记录一下草稿 问的 topic 是你是否经常 share with people，when first share？share with who？ 我依稀记得当时答得稀碎，就说我和协会的同学分享机器学习知识，在 online meeting，然后我的一个观点是，对一个知识而言，当你学会分享给别人，能让别人理解，那么你才是真的掌握了这个。虽然大致意思差不多，估计我表达和组织语言的时候实在是稀碎。（已经不想回忆这一段了 然后后面因为我没说到 2min，考官说了 could you tell something more? 支支吾吾半天也没整明白\nPart3 我记得一个问题好像为什么不 share with people？然后我说 secrets？然后我画蛇添足的说没人想和不 share with people 的人 make friends，这些人 selfish，考官说不 share with people 的人也能 make friends，然后我就呆了，后面就忘记了\n最后考官说考试结束，然后就把我送出来了。出来的时候 14.00 多，喜提 IELTS pencil 一支。管物品存放的小哥当时还没给我手环，感觉他奇奇怪怪的 - -\n纸笔考试就在第二天早上，本来想 6.30 起床，看看作文素材啥的，结果，6.30，7.00，7.20 订了 3 个闹铃，结果一个没响？？？我起来就直接 7.22 了，我晕 然后早饭也没吃就直接过去了。出了门发现没拿口罩，又回去了一趟\n到了以后我贼渴，出门没喝水，本想着去 5 教楼下自助贩卖机买一瓶，结果自助贩卖机关了- -\u0026hellip; 只要直接进考场了，还是常规的一套，然后在候考室等着，幸好候考室有小瓶的农夫山泉矿泉水，要撕掉标签 事实证明，这两天其实不用打印准考证，只需要拿着身份证记号口试时间就 ok 了\n进考场前也就是常规的安检检查，进去后要用免水洗手液洗下手，签个字，这个部分使用的英文。进考场以后好像都是英文了。\nListening 前两个听力还好，有几个单词知道是啥，但是忘记咋拼了，白给，一个是阳台Balcony，一个是冰箱Refrigerator\n后面有个选对应内容的，整个听力都没听明白，同义词替换实在是太多了，这块得再看看了，后两个听力我感觉都挺难的(for me)\n听力 30min，最后给 10min 誊写\nReading 之前阅读都没怎么计时，一篇阅读按理应该有 20min 的做题时间，但是第一篇我做了近 25min，主要是一开始没觉得后面题目多，做起来一个个找答案是慢了，这直接导致最后一篇阅读我好像只花了 10min 左右，5min 的时间做题，还好是选段填空，后面几个选择也在后两段找到了答案，但是中间的对应题，实在是没时间了，最后要截止收卷了只好蒙上了答案BCDEF，对几个就听天由命了 233\nWriting 感觉小作文还比较简单，两个饼图，是澳大利亚悉尼的水在各方面的使用情况，之前看过类似的还 ok，个人感觉良好 要求有 150 字，随便写写就到了\n大作文就有些奇奇怪怪了，说的是some people think that in modern world people are becoming more dependent on each other，然后另一个观点就是independent，要求是discuss both view然后给出自己的观点\n我记得我大概列了一个大纲，好像没写到 250 字，后面时间有感觉不太够，我花了 20min 写思路，20min 写内容，时间确实有点不合理\n开头段：背景引出+两个观点 观点 A：independent，过去人们生活在村庄里，日出而作日落而息，人们一起打猎和喂养动物(因为不会写耕作 md)。现在人们生活在公寓或 house 里，有着不同的生活方式，学生早上 7.00 出学校，上班族 8.00 去工作，甚至没时间说句话。学生放学后还要做作业，上班族要做剩下的工作。 观点 B：dependent，很多人愿意在别人in the truble的时候帮助他们，或者donate，所以dependent 立论：我想的是在mental上要dependent，在action上要dependent，因为我们生活在同一个世界，不可能完全独立，然后\n不知道有没有跑题\u0026hellip;\nEnd 最后，好好总结。\n最近应该要做个复习计划了，同时也该找个一对一的班了\u0026hellip;\n明明两天为什么说一日游呢？因为口语是下午 13.50，确实是一天之内考完的 - -\n","permalink":"https://blog.bj-yan.top/p/misc-20210724/","summary":"\u003ch2 id=\"before\"\u003eBefore\u003c/h2\u003e\n\u003cp\u003e本来想早点报 7 月第一场，先考考看摸个底的，结果整好赶上了考试周，错过了报名时间，没办法只能报下一场，也就是这场了\u003c/p\u003e\n\u003cp\u003e海南大学是没有机考考点的，所以只能纸笔考试咯，考试地点就在 5 教里面的教学楼\u003c/p\u003e","title":"记第一次雅思考试一日游"},{"content":"Hello，欢迎你点开这个界面，感谢来访。\n我是北屿。\n一个平凡的大学生。\n能量盗贼 \u0026amp; 小鸡 4 级胖揍员\n我会在这里更新一些杂文或者知识分享，希望对你有帮助。\n我挺喜欢厂子的一句话的：\n随便记住我，然后把我忘了吧。\n我的学术主页在这里：link\n另外，我的简历 [ZH] [EN]\n当然你也可以在这里留言，我也会不定时查看的，你也可以直接来加我微信找我讨论\nWeChat: beiyuouo。\n欢迎批评，批评方式：\nEmail: bj.yan.pa@qq.com bj.yan@ieee.org\n","permalink":"https://blog.bj-yan.top/about/","summary":"\u003cp\u003eHello，欢迎你点开这个界面，感谢来访。\u003c/p\u003e\n\u003cp\u003e我是北屿。\u003c/p\u003e\n\u003cp\u003e一个平凡的大学生。\u003c/p\u003e\n\u003cp\u003e\u003cdel\u003e能量盗贼 \u0026amp; 小鸡 4 级胖揍员\u003c/del\u003e\u003c/p\u003e\n\u003cp\u003e我会在这里更新一些杂文或者知识分享，希望对你有帮助。\u003c/p\u003e","title":"About me"},{"content":" 时不时我会来翻翻友链的朋友们，有些老朋友们的域名或者网站失效了可能就暂时移除了，请留言新的站点信息~（以下排名不分先后）\nYuZhangWang的领域 PLUSULTRA!\nRussell Keep eating codes!\nNelson Boss 一直游到海水变蓝\nJunyi\u0026#39;s Lab 一个自娱自乐的地方\n月梦の技术博客 博学而笃志，切问而近思。\n孑渡 VR大哥.\nVnYzm 前偏远小渔村边缘\nChasing1020 Why there is a universe?\nR0gerThat @Vidar-Team @CTFer @Game Lover\nDimsmary Do What U Wanna Do\nDeathSprout DeathSprout\nWindy Windy\nZhiyu\u0026#39;s Blog JUST DO IT ! ┏ (゜ω゜)= ☞ Zhonghao Sun 从未想过背叛, 也不必说忠贞\n包子丶 好奇者，探索者\nMiroier keep calm and carry on\nZhangZhao A Lazy Programmer\nMakiras Although the sun shine, leave not your cloak at home.\nDamonZhang We are all in the gutter, but some of us are looking at the stars.\nPYQ PYQ的博客 | PYQ Blog\nQIN2DIM A creator from China.\ncodeslogan If not me, who?\nshiroha 鸣濑家的杂货铺\nDeLucia Final Phantasy\n果壳儿 国科大论坛.\nManim Kindergarten A group of manim Chinese users.\n苏剑林 科学空间 - 渴望成为一个小飞侠\nGuangzheng Li 阅读与思考，真理与自由\nSOTA paper rating SOTA paper rating\nSam Altman AI is cool i guess\n欢迎申请友链~\n请留言如下格式\n1 2 3 4 站点标题: 北屿 站点简介: 小冰爱吃盐！ 博客地址: https://blog.bj-yan.top/ 头像地址: https://avatars.githubusercontent.com/u/44976445 ","permalink":"https://blog.bj-yan.top/friends/","summary":"\u003cblockquote\u003e\n\u003cp\u003e时不时我会来翻翻友链的朋友们，有些老朋友们的域名或者网站失效了可能就暂时移除了，请留言新的站点信息~（以下排名不分先后）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003cdiv class=\"friend-link-div\"\u003e\n    \u003ca href=\"https://yuzhang.wang/\" title=\"YuZhangWang的领域\" class=\"friend-link\" target=\"_blank\" rel=\"friend\"\u003e\n\n    \u003cdiv class=\"friend-link-avatar\"\u003e\n        \u003cimg src=\"https://gcore.jsdelivr.net/gh/YuZhangWang/Creative-pictures02@master/img/202210171416164.png\" class=\"friend-avatar\" loading=\"lazy\" alt=\"Avatar\"\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"friend-link-info\"\u003e\n        \u003ci class=\"fa fa-link\" aria-hidden=\"true\"\u003e\u003c/i\u003e\n        \u003ci class=\"friend-name\"\u003eYuZhangWang的领域\u003c/i\u003e\n        \u003cp class=\"friend-bio\"\u003ePLUSULTRA!\u003c/p\u003e\n    \u003c/div\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\n\u003cdiv class=\"friend-link-div\"\u003e\n    \u003ca href=\"https://russellwzr.github.io/blog\" title=\"Russell\" class=\"friend-link\" target=\"_blank\" rel=\"friend\"\u003e\n\n    \u003cdiv class=\"friend-link-avatar\"\u003e\n        \u003cimg src=\"/friend_avator/default_avator.png\" class=\"friend-avatar\" loading=\"lazy\" alt=\"Avatar\"\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"friend-link-info\"\u003e\n        \u003ci class=\"fa fa-link\" aria-hidden=\"true\"\u003e\u003c/i\u003e\n        \u003ci class=\"friend-name\"\u003eRussell\u003c/i\u003e\n        \u003cp class=\"friend-bio\"\u003eKeep eating codes!\u003c/p\u003e\n    \u003c/div\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\n\u003cdiv class=\"friend-link-div\"\u003e\n    \u003ca href=\"https://bosswnx.xyz/\" title=\"Nelson Boss\" class=\"friend-link\" target=\"_blank\" rel=\"friend\"\u003e\n\n    \u003cdiv class=\"friend-link-avatar\"\u003e\n        \u003cimg src=\"https://blog.bosswnx.xyz/images/profile.jpg\" class=\"friend-avatar\" loading=\"lazy\" alt=\"Avatar\"\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"friend-link-info\"\u003e\n        \u003ci class=\"fa fa-link\" aria-hidden=\"true\"\u003e\u003c/i\u003e\n        \u003ci class=\"friend-name\"\u003eNelson Boss\u003c/i\u003e\n        \u003cp class=\"friend-bio\"\u003e一直游到海水变蓝\u003c/p\u003e\n    \u003c/div\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\n\u003cdiv class=\"friend-link-div\"\u003e\n    \u003ca href=\"https://junyi.dev/\" title=\"Junyi\u0026#39;s Lab\" class=\"friend-link\" target=\"_blank\" rel=\"friend\"\u003e\n\n    \u003cdiv class=\"friend-link-avatar\"\u003e\n        \u003cimg src=\"https://avatars.githubusercontent.com/u/14367694\" class=\"friend-avatar\" loading=\"lazy\" alt=\"Avatar\"\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"friend-link-info\"\u003e\n        \u003ci class=\"fa fa-link\" aria-hidden=\"true\"\u003e\u003c/i\u003e\n        \u003ci class=\"friend-name\"\u003eJunyi\u0026#39;s Lab\u003c/i\u003e\n        \u003cp class=\"friend-bio\"\u003e一个自娱自乐的地方\u003c/p\u003e","title":"Friends"}]